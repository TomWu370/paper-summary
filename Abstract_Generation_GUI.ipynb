{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomwu\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from simplet5 import SimpleT5\n",
    "from transformers import T5Config\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "import random\n",
    "import fasttext\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "import fitz\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "DATASET = \"./Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect which device (CPU/GPU) to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_let(string):\n",
    "    return any(char.isalpha() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_num(string):\n",
    "    return any(char.isdigit() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_special(string, allowed):\n",
    "    '''\n",
    "    allowed is a list containing allowed symbols to pass detection\n",
    "    '''\n",
    "    return any(not(char.isalpha() or char.isdigit()) and (char not in allowed) for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLine(line, text=True):\n",
    "    \"Text parameter is to indicate whether the line is from text or abstract\"\n",
    "\n",
    "    symbols = [\"'\", \"â€™\"]\n",
    "    stop_words = list(ENGLISH_STOP_WORDS)\n",
    "    \n",
    "    clean_line = line.lower()\n",
    "    clean_line = clean_line.strip()\n",
    "    \n",
    "    # fix apostrophes in line by removing apostrophe with no following alphabet character\n",
    "    clean_line = clean_line.replace(\"' \", \" \")\n",
    "    if clean_line and clean_line[-1] == \"'\":\n",
    "        clean_line = clean_line[0:len(clean_line)-1]\n",
    "    # fix apostrophes in line by removing space before single quote\n",
    "    clean_line = clean_line.replace(\" '\", \"'\")\n",
    "    #remove punctuation\n",
    "\n",
    "    \n",
    "    # clean line = clean line remove forms\n",
    "    words = clean_line.split()\n",
    "\n",
    "    #  remove forms\n",
    "    words = [x.replace(x, \"\") if (contain_let(x) and contain_num(x))\n",
    "             or contain_special(x, symbols)\n",
    "             else x for x in words]\n",
    "    # remove empty strings\n",
    "    words = filter(None, words)\n",
    "\n",
    "    # stop words from sklearn, remove stop words\n",
    "    if text:\n",
    "        words = [x for x in words if not x in stop_words]\n",
    "\n",
    "    # combine the items into 1 string\n",
    "    clean_line = ' '.join(words)\n",
    "    return clean_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# model = fasttext.train_unsupervised('data/fil9')\n",
    "# model.save_model(\"result/fil9.bin\")\n",
    "fastmodel = fasttext.load_model(\"fastText_full_NoStop.bin\")\n",
    "# EXPECTS TEXT FILE FORMAT WHERE 1 TEXT PER ROW\n",
    "# IMPORTANT, NEED TO REDESIGN CLEANING PROCESS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Finalisation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLOUR = \"Black\"\n",
    "doc_len = 0\n",
    "def get_colour(text):\n",
    "    return r'\\(\\color{'+TEXT_COLOUR+'} {' + text  + '}\\)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file):\n",
    "    file_content = list(file)[0]\n",
    "    content = file_content[\"content\"].tobytes()\n",
    "    return fitz.open(stream=content, filetype=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04861ff912204b5b95f916cf9a359bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploader = widgets.FileUpload(multiple=False, accept='.pdf')\n",
    "def on_upload(change):\n",
    "    #ch = change.value.values()\n",
    "    # to obtain information regarding the pdf when the pdf is uploaded, buttonless design, will impact perf\n",
    "    global doc_len\n",
    "    print(uploader.value[0].content)\n",
    "    doc_len = len(load_pdf(uploader.value))-1\n",
    "    \n",
    "    uploader.value.clear()\n",
    "    uploader._counter=1\n",
    "\n",
    "#uploader.observe(on_upload, 'value')\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Generation tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio = widgets.RadioButtons(\n",
    "    options=['Base'],\n",
    "    description=get_colour(\"Model:\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Length\n",
    "length = widgets.IntText(\n",
    "    value=512,\n",
    "    description=get_colour(\"Max length\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam number\n",
    "beam = widgets.IntText(\n",
    "    value=5,\n",
    "    min=2,\n",
    "    description=get_colour(\"Beam Number\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tok K\n",
    "topk = widgets.IntText(\n",
    "    value=50,\n",
    "    description=get_colour(\"TopK\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetition penalty\n",
    "repetition = widgets.FloatText(\n",
    "    value=2.5,\n",
    "    description=get_colour(\"Repetition Pen\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length penalty\n",
    "length_pen = widgets.FloatText(\n",
    "    value=1.0,\n",
    "    description=get_colour(\"Length Pen\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "temperature = widgets.BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0.1,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description=get_colour(\"Temperature\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF start and end\n",
    "pdf_range = widgets.IntRangeSlider(\n",
    "    value=[0, doc_len],\n",
    "    min=0,\n",
    "    max=doc_len,\n",
    "    step=1,\n",
    "\n",
    "    description=get_colour(\"Page Range\"),\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = widgets.Button(\n",
    "    description='Click me',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "#button.style.button_color=\"green\"\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        #print(i,\" Button clicked.\")\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = [radio, length, beam, topk, repetition, length_pen, temperature, pdf_range, button]\n",
    "grid = widgets.GridBox(widget, layout=widgets.Layout(grid_template_columns=\"repeat(2, 300px)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance Query tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description=get_colour(\"Query\"),\n",
    "    disabled=False   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_range_q = widgets.IntRangeSlider(\n",
    "    value=[0, doc_len],\n",
    "    min=0,\n",
    "    max=doc_len,\n",
    "    step=1,\n",
    "\n",
    "    description=get_colour(\"Page Range\"),\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_q = widgets.Button(\n",
    "    description='Click me',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "#button.style.button_color=\"green\"\n",
    "out_q = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with out_q:\n",
    "        out_q.clear_output()\n",
    "        print(\"hi\")\n",
    "        #print(j,\" Button clicked.\")\n",
    "\n",
    "button_q.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_q = [text_box, pdf_range_q, button_q]\n",
    "grid_q = widgets.GridBox(widget_q, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final combined tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8b76f2c0ec493d8b526cacc1161ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(GridBox(children=(RadioButtons(description='\\\\(\\\\color{Black} {Model:}\\\\)', options=('Base',), vâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713cdc9a831d421d8ec4332ce41298e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grids = [grid, grid_q]\n",
    "tabs = widgets.Tab()\n",
    "tabs.children=grids\n",
    "tabs_titles = [\"Abstract Generation\", \"Relevance Query\"]\n",
    "for i, title in enumerate(tabs_titles):\n",
    "    tabs.set_title(i, title)\n",
    "display(tabs, out_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPDF(file, start_page=0, end_page=-1):\n",
    "    '''\n",
    "    Will accept input of widget pdf file\n",
    "    start_page indicates starting page to start reading default=first page\n",
    "    end_page indicate last page to read default=last page\n",
    "    '''\n",
    "    doc = load_pdf(file)\n",
    "    if end_page == -1:\n",
    "        end_page = len(doc)-1\n",
    "    \n",
    "    # extracting text from page\n",
    "    doc_text = \"\"\n",
    "    for page in doc.pages(start_page, end_page):\n",
    "        \n",
    "        text = page.get_text(\"text\")\n",
    "        text = text.split('\\n')\n",
    "        text = \" \".join(text)\n",
    "        doc_text += text \n",
    "    doc_text = doc_text.strip()\n",
    "    doc.close()\n",
    "    return doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(raw_data, stop_word=True):\n",
    "    return cleanLine(raw_data, stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetModel(path):\n",
    "    if path==\"Base\":\n",
    "        path = \"outputs/best\"\n",
    "    model = SimpleT5()\n",
    "    model.load_model(model_type=\"t5\", model_dir=path, use_gpu=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paper introduces new metric distance tween text approach leverages recent sults mikolov et introduced novel model learns semantically tionships word moverâ€™s distance measures dissimilarity text document weighted point cloud embeddings document distances compute exact provably neighbor search lower bound distances yields state art results wmd outperforms baselines'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = readPDF(uploader.value)\n",
    "clean_text = Process(text)\n",
    "model = GetModel(radio.value)\n",
    "size = length.value\n",
    "temp = 0.0#temperature.value\n",
    "beams = beam.value\n",
    "top_k = topk.value\n",
    "repetition_penalty = repetition.value\n",
    "length_penalty = length_pen.value\n",
    "abstract = Infer(model, clean_text, size, temp, beams, top_k, repetition_penalty, length_penalty)\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infer(model, data, max_size, temperature, beams, top_k, repetition_penalty, length_penalty):\n",
    "    model_config = model.model.config.to_dict()\n",
    "    # switch to beam search\n",
    "    if temperature == 0.0:\n",
    "        model_config[\"do_sample\"] = False\n",
    "    else:\n",
    "        model_config[\"do_sample\"] = True\n",
    "    model_config[\"temperature\"] = temperature #0-1, >0 for more random\n",
    "    config = T5Config(**model_config)\n",
    "    model.model.config = config\n",
    "\n",
    "    \n",
    "    output = model.predict(data, max_length=max_size, num_beams=beams, top_k=top_k, \n",
    "                            repetition_penalty=repetition_penalty,length_penalty=length_penalty)\n",
    "    \n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = readPDF(uploader.value, start_page=0, end_page=-1) # Obtain 1 long string\n",
    "data = Process(raw_data) # Clean string and convert to word_ids\n",
    "output = Infer(best_model, data, max_size=100, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevance Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get user input\n",
    "user_input = text_box.value\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input pdf as string\n",
    "raw_data = readPDF(uploader.value, start_page=0, end_page=-1) # Obtain 1 long string\n",
    "data = Process(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import insort\n",
    "# loop through pdf with context window\n",
    "# update highest score and update topk score\n",
    "def get_similarity(query, data, window=None, k=5):\n",
    "    '''\n",
    "    query: the terms to be searched\n",
    "    data: the data to be compared with the query\n",
    "    window: the size for each similarity comparison, default = query length\n",
    "    k: relates to how many good hits you want, the higher the k, requires more good similarity scores\n",
    "       default = 5\n",
    "    '''\n",
    "    query_vector = fastmodel.get_sentence_vector(query)\n",
    "    data = \"machine and learning asdilasdasdasd1234567890abcdefghi\"\n",
    "    if window == None:\n",
    "        window = len(query)\n",
    "\n",
    "    if window > len(data):\n",
    "        window = len(data)\n",
    "    print(window)\n",
    "    best = 0\n",
    "    topk = [0] * k\n",
    "    print(data)\n",
    "    for head in range(0, len(data), window):\n",
    "        print(head)\n",
    "        tail = (head+window)\n",
    "        print(tail)\n",
    "\n",
    "        chunk = data[head:tail]\n",
    "        print([chunk])\n",
    "        chunk_vector = fastmodel.get_sentence_vector(chunk)\n",
    "        temp_similarity = get_cosine(query_vector, chunk_vector)\n",
    "        print(temp_similarity)\n",
    "        if temp_similarity > best:\n",
    "            best = temp_similarity\n",
    "    \n",
    "        if temp_similarity > topk[0]:\n",
    "            # keep the list size to k elements\n",
    "            # insort method allows for more efficient insertion and sorting\n",
    "            insort(topk, temp_similarity)\n",
    "            topk = topk[-k:]\n",
    "    topk.reverse()\n",
    "    return best, topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "def get_cosine(query, key):\n",
    "    return np.dot(query,key)/(norm(query)*norm(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mixed score with alpha\n",
    "def get_mix_score(best, topk, alpha=0.5):\n",
    "    return (alpha * best) + ((1-alpha) * np.average(topk))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "machine and learning asdilasdasdasd1234567890abcdefghi\n",
      "0\n",
      "25\n",
      "['machine and learning asdi']\n",
      "0.84383076\n",
      "25\n",
      "50\n",
      "['lasdasdasd1234567890abcde']\n",
      "0.3307465\n",
      "50\n",
      "75\n",
      "['fghi']\n",
      "0.35131034\n",
      "0.84383076\n",
      "[0.84383076, 0.35131034, 0.3307465, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "best, top = get_similarity(query=\"machine learning\", data=None, window=25)\n",
    "print(best)\n",
    "print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5459473729133606"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mix_score(best, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[360], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ouput score\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241m.\u001b[39mprint(mix_score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "# Ouput score\n",
    "output.print(mix_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5623M_CW1_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
