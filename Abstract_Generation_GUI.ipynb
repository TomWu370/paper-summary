{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomwu\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from simplet5 import SimpleT5\n",
    "from transformers import T5Config\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "import random\n",
    "import fasttext\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "import fitz\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "DATASET = \"./Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect which device (CPU/GPU) to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_let(string):\n",
    "    return any(char.isalpha() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_num(string):\n",
    "    return any(char.isdigit() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_special(string, allowed):\n",
    "    '''\n",
    "    allowed is a list containing allowed symbols to pass detection\n",
    "    '''\n",
    "    return any(not(char.isalpha() or char.isdigit()) and (char not in allowed) for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLine(line, text=True):\n",
    "    \"Text parameter is to indicate whether the line is from text or abstract\"\n",
    "\n",
    "    symbols = [\"'\", \"â€™\"]\n",
    "    stop_words = list(ENGLISH_STOP_WORDS)\n",
    "    \n",
    "    clean_line = line.lower()\n",
    "    clean_line = clean_line.strip()\n",
    "    \n",
    "    # fix apostrophes in line by removing apostrophe with no following alphabet character\n",
    "    clean_line = clean_line.replace(\"' \", \" \")\n",
    "    if clean_line and clean_line[-1] == \"'\":\n",
    "        clean_line = clean_line[0:len(clean_line)-1]\n",
    "    # fix apostrophes in line by removing space before single quote\n",
    "    clean_line = clean_line.replace(\" '\", \"'\")\n",
    "    #remove punctuation\n",
    "\n",
    "    \n",
    "    # clean line = clean line remove forms\n",
    "    words = clean_line.split()\n",
    "\n",
    "    #  remove forms\n",
    "    words = [x.replace(x, \"\") if (contain_let(x) and contain_num(x))\n",
    "             or contain_special(x, symbols)\n",
    "             else x for x in words]\n",
    "    # remove empty strings\n",
    "    words = filter(None, words)\n",
    "\n",
    "    # stop words from sklearn, remove stop words\n",
    "    if text:\n",
    "        words = [x for x in words if not x in stop_words]\n",
    "\n",
    "    # combine the items into 1 string\n",
    "    clean_line = ' '.join(words)\n",
    "    return clean_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatParagraph(paragraph, text):\n",
    "    clean_paragraph = \"\"\n",
    "    for line in paragraph:\n",
    "        lines = cleanLine(line)\n",
    "        clean_paragraph += cleanLine(lines, text) + \" \"\n",
    "        #print(clean_paragraph)\n",
    "        \n",
    "    return(clean_paragraph.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatPaper(paper, text):\n",
    "    clean_paper = \"\"\n",
    "    for paragraph in paper:\n",
    "        clean_paper += concatParagraph(paragraph, text) + \" \"\n",
    "    return(clean_paper.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "result/fil9.bin cannot be opened for loading!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model = fasttext.train_unsupervised('data/fil9')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model.save_model(\"result/fil9.bin\")\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult/fil9.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\fasttext\\FastText.py:441\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[39;00m\n\u001b[0;32m    440\u001b[0m eprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FastText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\fasttext\\FastText.py:98\u001b[0m, in \u001b[0;36m_FastText.__init__\u001b[1;34m(self, model_path, args)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mfasttext()\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: result/fil9.bin cannot be opened for loading!"
     ]
    }
   ],
   "source": [
    "# model = fasttext.train_unsupervised('data/fil9')\n",
    "# model.save_model(\"result/fil9.bin\")\n",
    "model = fasttext.load_model(\"result/fil9.bin\")\n",
    "# EXPECTS TEXT FILE FORMAT WHERE 1 TEXT PER ROW\n",
    "# IMPORTANT, NEED TO REDESIGN CLEANING PROCESS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Finalisation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLOUR = \"Black\"\n",
    "doc_len = 0\n",
    "def get_colour(text):\n",
    "    return r'\\(\\color{'+TEXT_COLOUR+'} {' + text  + '}\\)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file):\n",
    "    file_content = list(file)[0]\n",
    "    content = file_content[\"content\"].tobytes()\n",
    "    return fitz.open(stream=content, filetype=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c041cd9a7aef4c32bec0eed673f4baef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploader = widgets.FileUpload(multiple=False, accept='.pdf')\n",
    "def on_upload(change):\n",
    "    #ch = change.value.values()\n",
    "    # to obtain information regarding the pdf when the pdf is uploaded, buttonless design, will impact perf\n",
    "    global doc_len\n",
    "    print(uploader.value[0].content)\n",
    "    doc_len = len(load_pdf(uploader.value))-1\n",
    "    \n",
    "    uploader.value.clear()\n",
    "    uploader._counter=1\n",
    "\n",
    "#uploader.observe(on_upload, 'value')\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Generation tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio = widgets.RadioButtons(\n",
    "    options=['Base'],\n",
    "    description=get_colour(\"Model:\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Length\n",
    "length = widgets.IntText(\n",
    "    value=512,\n",
    "    description=get_colour(\"Max length\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam number\n",
    "beam = widgets.IntText(\n",
    "    value=5,\n",
    "    min=2,\n",
    "    description=get_colour(\"Beam Number\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tok K\n",
    "topk = widgets.IntText(\n",
    "    value=50,\n",
    "    description=get_colour(\"TopK\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetition penalty\n",
    "repetition = widgets.FloatText(\n",
    "    value=2.5,\n",
    "    description=get_colour(\"Repetition Pen\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length penalty\n",
    "length_pen = widgets.FloatText(\n",
    "    value=1.0,\n",
    "    description=get_colour(\"Length Pen\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "temperature = widgets.BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0.1,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description=get_colour(\"Temperature\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF start and end\n",
    "pdf_range = widgets.IntRangeSlider(\n",
    "    value=[0, doc_len],\n",
    "    min=0,\n",
    "    max=doc_len,\n",
    "    step=1,\n",
    "\n",
    "    description=get_colour(\"Page Range\"),\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = widgets.Button(\n",
    "    description='Click me',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "#button.style.button_color=\"green\"\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        #print(i,\" Button clicked.\")\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = [radio, length, beam, topk, repetition, length_pen, temperature, pdf_range, button]\n",
    "grid = widgets.GridBox(widget, layout=widgets.Layout(grid_template_columns=\"repeat(2, 300px)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance Query tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description=get_colour(\"Query\"),\n",
    "    disabled=False   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_range_q = widgets.IntRangeSlider(\n",
    "    value=[0, doc_len],\n",
    "    min=0,\n",
    "    max=doc_len,\n",
    "    step=1,\n",
    "\n",
    "    description=get_colour(\"Page Range\"),\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_q = widgets.Button(\n",
    "    description='Click me',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "#button.style.button_color=\"green\"\n",
    "out_q = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with out_q:\n",
    "        out_q.clear_output()\n",
    "        print(\"hi\")\n",
    "        #print(j,\" Button clicked.\")\n",
    "\n",
    "button_q.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_q = [text_box, pdf_range_q, button_q]\n",
    "grid_q = widgets.GridBox(widget_q, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final combined tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3a64e0120943ba8e042e4fb0fb24c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(GridBox(children=(RadioButtons(description='\\\\(\\\\color{Black} {Model:}\\\\)', options=('Base',), vâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a545d142196a4383a3408ffe72d71644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grids = [grid, grid_q]\n",
    "tabs = widgets.Tab()\n",
    "tabs.children=grids\n",
    "tabs_titles = [\"Abstract Generation\", \"Relevance Query\"]\n",
    "for i, title in enumerate(tabs_titles):\n",
    "    tabs.set_title(i, title)\n",
    "display(tabs, out_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPDF(file, start_page=0, end_page=-1):\n",
    "    '''\n",
    "    Will accept input of widget pdf file\n",
    "    start_page indicates starting page to start reading default=first page\n",
    "    end_page indicate last page to read default=last page\n",
    "    '''\n",
    "    doc = load_pdf(file)\n",
    "    if end_page == -1:\n",
    "        end_page = len(doc)-1\n",
    "    \n",
    "    # extracting text from page\n",
    "    doc_text = \"\"\n",
    "    for page in doc.pages(start_page, end_page):\n",
    "        \n",
    "        text = page.get_text(\"text\")\n",
    "        text = text.split('\\n')\n",
    "        text = \" \".join(text)\n",
    "        doc_text += text \n",
    "    doc_text = doc_text.strip()\n",
    "    doc.close()\n",
    "    return doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(raw_data, stop_word=True):\n",
    "    return cleanLine(raw_data, stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetModel(path):\n",
    "    if path==\"Base\":\n",
    "        path = \"outputs/best\"\n",
    "    model = SimpleT5()\n",
    "    model.load_model(model_type=\"t5\", model_dir=path, use_gpu=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paper introduces new metric distance tween text approach leverages recent sults mikolov et introduced novel model learns semantically tionships word moverâ€™s distance measures dissimilarity text document weighted point cloud embeddings document distances compute exact provably neighbor search lower bound distances yields state art results wmd outperforms baselines'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = readPDF(uploader.value)\n",
    "clean_text = Process(text)\n",
    "model = GetModel(radio.value)\n",
    "size = length.value\n",
    "temp = 0.0#temperature.value\n",
    "beams = beam.value\n",
    "top_k = topk.value\n",
    "repetition_penalty = repetition.value\n",
    "length_penalty = length_pen.value\n",
    "abstract = Infer(model, clean_text, size, temp, beams, top_k, repetition_penalty, length_penalty)\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infer(model, data, max_size, temperature, beams, top_k, repetition_penalty, length_penalty):\n",
    "    model_config = model.model.config.to_dict()\n",
    "    # switch to beam search\n",
    "    if temperature == 0.0:\n",
    "        model_config[\"do_sample\"] = False\n",
    "    else:\n",
    "        model_config[\"do_sample\"] = True\n",
    "    model_config[\"temperature\"] = temperature #0-1, >0 for more random\n",
    "    config = T5Config(**model_config)\n",
    "    model.model.config = config\n",
    "\n",
    "    \n",
    "    output = model.predict(data, max_length=max_size, num_beams=beams, top_k=top_k, \n",
    "                            repetition_penalty=repetition_penalty,length_penalty=length_penalty)\n",
    "    \n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = readPDF(uploader.value.values(), start_page=0, end_page=-1) # Obtain 1 long string\n",
    "data = Process(raw_data) # Clean string and convert to word_ids\n",
    "output = Infer(best_model, data, max_size=100, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevance Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gggg'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get user input\n",
    "user_input = text_box.value\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input pdf as string\n",
    "raw_data = readPDF(uploader.value.values(), start_page=0, end_page=-1) # Obtain 1 long string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import insort\n",
    "# loop through pdf with context window\n",
    "# update highest score and update topk score\n",
    "def get_similarity(query, data, window=None, k=5):\n",
    "    '''\n",
    "    query: the terms to be searched\n",
    "    data: the data to be compared with the query\n",
    "    window: the size for each similarity comparison, default = query length\n",
    "    k: relates to how many good hits you want, the higher the k, requires more good similarity scores\n",
    "       default = 5\n",
    "    '''\n",
    "    query_vector = fastmodel.get_sentence(query)\n",
    "    data = [1,2,3,4,5,6,7,8,9,0]\n",
    "    if window == None:\n",
    "        window = len(query)\n",
    "    best = 0\n",
    "    topk = [0] * k\n",
    "    for head in range(0, len(data)-window):\n",
    "        tail = (head+window)-1\n",
    "        chunk = data[head:tail]\n",
    "        chunk_vector = fastmodel.get_sentence(chunk)\n",
    "        temp_similarity = fastmodel.get_similarity(query_vector, chunk_vector)\n",
    "        print(temp_similarity)\n",
    "        if temp_similarity > best:\n",
    "            best = temp_similarity\n",
    "        if temp_similarity > topk[-1]:\n",
    "            # keep the list size to k elements\n",
    "            # insort method allows for more efficient insertion and sorting\n",
    "            insort(topk, temp_similarity)[:k]\n",
    "    return best, topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mixed score with alpha\n",
    "def get_mix_score(best, topk, alpha=0.5):\n",
    "    return (alpha * best) + ((1-alpha) * np.average(topk))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fastmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[275], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[269], line 12\u001b[0m, in \u001b[0;36mget_similarity\u001b[1;34m(query, data, window, k)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_similarity\u001b[39m(query, data, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    query: the terms to be searched\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    data: the data to be compared with the query\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m       default = 5\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     query_vector \u001b[38;5;241m=\u001b[39m \u001b[43mfastmodel\u001b[49m\u001b[38;5;241m.\u001b[39mget_sentence(query)\n\u001b[0;32m     13\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m window \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fastmodel' is not defined"
     ]
    }
   ],
   "source": [
    "get_similarity(query=\"hi\", data=None, window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput score\n",
    "output.print(mix_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5623M_CW1_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
