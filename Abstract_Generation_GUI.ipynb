{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "import random\n",
    "import fasttext\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "import fitz\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "DATASET = \"./Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect which device (CPU/GPU) to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_let(string):\n",
    "    return any(char.isalpha() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_num(string):\n",
    "    return any(char.isdigit() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLine(line, text=True):\n",
    "    \"Text parameter is to indicate whether the line is from text or abstract\"\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    number = list(map(str, range(10)))\n",
    "    symbols = [\"'\", \"’\"]\n",
    "    valid_char = alphabet + number + symbols\n",
    "    stop_words = list(ENGLISH_STOP_WORDS)\n",
    "    \n",
    "    clean_line = line.lower()\n",
    "    clean_line = clean_line.strip()\n",
    "    \n",
    "    # fix apostrophes in line by removing apostrophe with no following alphabet character\n",
    "    clean_line = clean_line.replace(\"' \", \" \")\n",
    "    if clean_line and clean_line[-1] == \"'\":\n",
    "        clean_line = clean_line[0:len(clean_line)-1]\n",
    "    # fix apostrophes in line by removing space before single quote\n",
    "    clean_line = clean_line.replace(\" '\", \"'\")\n",
    "    #remove punctuation\n",
    "    # replace all non alphabet character with space\n",
    "    difference = list(set(clean_line).symmetric_difference(valid_char))\n",
    "\n",
    "    for dif in difference:\n",
    "        clean_line = clean_line.replace(dif, \" \")\n",
    "    \n",
    "    # clean line = clean line remove forms\n",
    "    words = clean_line.split()\n",
    "\n",
    "    #  remove forms\n",
    "    words = [x.replace(x, \"\") if contain_let(x) and contain_num(x) else x for x in words]\n",
    "    # remove empty strings\n",
    "    words = filter(None, words)\n",
    "\n",
    "    # stop words from sklearn, remove stop words\n",
    "    if text:\n",
    "        words = [x for x in words if not x in stop_words]\n",
    "\n",
    "    # combine the items into 1 string\n",
    "    clean_line = ' '.join(words)\n",
    "    return clean_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatParagraph(paragraph, text):\n",
    "    clean_paragraph = \"\"\n",
    "    for line in paragraph:\n",
    "        lines = cleanLine(line)\n",
    "        clean_paragraph += cleanLine(lines, text) + \" \"\n",
    "        #print(clean_paragraph)\n",
    "        \n",
    "    return(clean_paragraph.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatPaper(paper, text):\n",
    "    clean_paper = \"\"\n",
    "    for paragraph in paper:\n",
    "        clean_paper += concatParagraph(paragraph, text) + \" \"\n",
    "    return(clean_paper.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\" Simple vocabulary wrapper which maps every unique word to an integer ID. \"\"\"\n",
    "    def __init__(self):\n",
    "        # intially, set both the IDs and words to dictionaries with special tokens\n",
    "        self.word2idx = {'<start>': 0, '<end>': 1, '<pad>':2, '<unk>':3}\n",
    "        self.idx2word = {0: '<start>', 1: '<end>', 2: '<pad>', 3: '<unk>'}\n",
    "        self.idx = 4\n",
    "\n",
    "    def add_word(self, word):\n",
    "        # if the word does not already exist in the dictionary, add it\n",
    "        if not word in self.word2idx:\n",
    "            # this will convert each word to index and index to word as you saw in the tutorials\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            # increment the ID for the next word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        # if we try to access a word not in the dictionary, return the id for <unk>\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    ## added function for utility\n",
    "    def get_word(self,index):\n",
    "        # this returns the word when given an index\n",
    "        return self.idx2word[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "result/fil9.bin cannot be opened for loading!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model = fasttext.train_unsupervised('data/fil9')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model.save_model(\"result/fil9.bin\")\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult/fil9.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\fasttext\\FastText.py:441\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[39;00m\n\u001b[0;32m    440\u001b[0m eprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FastText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\fasttext\\FastText.py:98\u001b[0m, in \u001b[0;36m_FastText.__init__\u001b[1;34m(self, model_path, args)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mfasttext()\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: result/fil9.bin cannot be opened for loading!"
     ]
    }
   ],
   "source": [
    "# model = fasttext.train_unsupervised('data/fil9')\n",
    "# model.save_model(\"result/fil9.bin\")\n",
    "model = fasttext.load_model(\"result/fil9.bin\")\n",
    "# EXPECTS TEXT FILE FORMAT WHERE 1 TEXT PER ROW\n",
    "# IMPORTANT, NEED TO REDESIGN CLEANING PROCESS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Finalisation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "best_model_path = \"best_decoder20230719.pth\"\n",
    "# Need model class/ import from other class to reduce cell block clutter\n",
    "best_model = Model(len(text_vocab),len(abstract_vocab),2,256)\n",
    "best_model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLOUR = \"Black\"\n",
    "doc_len = 0\n",
    "def get_colour(text):\n",
    "    return r'\\(\\color{'+TEXT_COLOUR+'} {' + text  + '}\\)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file):  \n",
    "    file_content = list(file)[0]\n",
    "    content = file_content[\"content\"]\n",
    "    return fitz.open(stream=content, filetype=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uploader = widgets.FileUpload(multiple=False, accept='.pdf')\n",
    "def on_upload(change):\n",
    "    #ch = change.value.values()\n",
    "    # to obtain information regarding the pdf when the pdf is uploaded, buttonless design, will impact perf\n",
    "    global doc_len\n",
    "    doc_len = len(load_pdf(uploader.value.values()))-1\n",
    "    \n",
    "    uploader.value.clear()\n",
    "    uploader._counter=1\n",
    "\n",
    "uploader.observe(on_upload, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Generation tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d9e58d66d84d58a851c7bec312de58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='\\\\(\\\\color{Black} {Model:}\\\\)', options=('Base', '512Dim', '1024Dim', 'Base+No Stop …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "radio = widgets.RadioButtons(\n",
    "    options=['Base', '512Dim', '1024Dim', 'Base+No Stop word'],\n",
    "    description=get_colour(\"Model:\"),\n",
    "    disabled=False\n",
    ")\n",
    "display(radio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Length\n",
    "length = widgets.IntText(\n",
    "    value=100,\n",
    "    description=get_colour(\"Max length:\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "temperature = widgets.BoundedFloatText(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description=get_colour(\"Temperature:\"),\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF start and end\n",
    "pdf_range = widgets.IntRangeSlider(\n",
    "    value=[0, doc_len],\n",
    "    min=0,\n",
    "    max=doc_len,\n",
    "    step=1,\n",
    "\n",
    "    description=get_colour(\"Page Range:\"),\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = widgets.Button(\n",
    "    description='Click me',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "#button.style.button_color=\"green\"\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        #print(i,\" Button clicked.\")\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = [radio, length, pdf_range, temperature, button]\n",
    "grid = widgets.GridBox(widget, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance Query tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description=get_colour(\"Query:\"),\n",
    "    disabled=False   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_range_q = widgets.IntRangeSlider(\n",
    "    value=[0, doc_len],\n",
    "    min=0,\n",
    "    max=doc_len,\n",
    "    step=1,\n",
    "\n",
    "    description=get_colour(\"Page Range:\"),\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_q = widgets.Button(\n",
    "    description='Click me',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "#button.style.button_color=\"green\"\n",
    "out_q = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with out_q:\n",
    "        out_q.clear_output()\n",
    "        print(\"hi\")\n",
    "        #print(j,\" Button clicked.\")\n",
    "\n",
    "button_q.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_q = [text_box, pdf_range_q, button_q]\n",
    "grid_q = widgets.GridBox(widget_q, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final combined tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f2884c339547ee8aba1324bd30ab67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(GridBox(children=(RadioButtons(description='\\\\(\\\\color{Black} {Model:}\\\\)', options=('Base', '51…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed3fcf9aec548a59d97a4f9e13e18b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grids = [grid, grid_q]\n",
    "tabs = widgets.Tab()\n",
    "tabs.children=grids\n",
    "tabs_titles = [\"Abstract Generation\", \"Relevance Query\"]\n",
    "for i, title in enumerate(tabs_titles):\n",
    "    tabs.set_title(i, title)\n",
    "display(tabs, out_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPDF(file, start_page=0, end_page=-1):\n",
    "    '''\n",
    "    Will accept input of widget pdf file\n",
    "    start_page indicates starting page to start reading default=first page\n",
    "    end_page indicate last page to read default=last page\n",
    "    '''\n",
    "    doc = load_pdf(file)\n",
    "    if end_page == -1:\n",
    "        end_page = len(doc)-1\n",
    "    \n",
    "    # extracting text from page\n",
    "    doc_text = \"\"\n",
    "    for page in doc.pages(start_page, end_page):\n",
    "        \n",
    "        text = page.get_text(\"text\")\n",
    "        text = text.split('\\n')\n",
    "        text = \" \".join(text)\n",
    "        doc_text += text \n",
    "    doc_text = doc_text.strip()\n",
    "    doc.close()\n",
    "    return doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(raw_data, stop_word=True):\n",
    "    data = cleanLine(raw_data, stop_word)\n",
    "    data_id = tokenise(text_vocab, data)\n",
    "    return data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infer(model, data, max_size=100, temperature=0.5):\n",
    "    decoder_outputs = model(data, max_len=max_size, temperature=temperature)\n",
    "    decoder_outputs = torch.unbind(decoder_outputs, 1)\n",
    "    sentence = \"\"\n",
    "    for output in decoder_outputs:\n",
    "        token = output.argmax(1)\n",
    "        # if word is pad then replace with space\n",
    "        # if word is end then stop\n",
    "        if token == 2:\n",
    "            sentence += \" \"\n",
    "        elif token == 1:\n",
    "            break\n",
    "        else:\n",
    "            sentence += abstract_vocab.get_word(token.item()) + \" \"\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = readPDF(uploader.value.values(), start_page=0, end_page=-1) # Obtain 1 long string\n",
    "data = Process(raw_data) # Clean string and convert to word_ids\n",
    "output = Infer(best_model, data, max_size=100, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevance Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gggg'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get user input\n",
    "user_input = text_box.value\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input pdf as string\n",
    "raw_data = readPDF(uploader.value.values(), start_page=0, end_page=-1) # Obtain 1 long string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import insort\n",
    "# loop through pdf with context window\n",
    "# update highest score and update topk score\n",
    "def get_similarity(query, data, window=None, k=5):\n",
    "    '''\n",
    "    query: the terms to be searched\n",
    "    data: the data to be compared with the query\n",
    "    window: the size for each similarity comparison, default = query length\n",
    "    k: relates to how many good hits you want, the higher the k, requires more good similarity scores\n",
    "       default = 5\n",
    "    '''\n",
    "    query_vector = fastmodel.get_sentence(query)\n",
    "    data = [1,2,3,4,5,6,7,8,9,0]\n",
    "    if window == None:\n",
    "        window = len(query)\n",
    "    best = 0\n",
    "    topk = [0] * k\n",
    "    for head in range(0, len(data)-window):\n",
    "        tail = (head+window)-1\n",
    "        chunk = data[head:tail]\n",
    "        chunk_vector = fastmodel.get_sentence(chunk)\n",
    "        temp_similarity = fastmodel.get_similarity(query_vector, chunk_vector)\n",
    "        if temp_similarity > best:\n",
    "            best = temp_similarity\n",
    "        if temp_similarity > topk[-1]:\n",
    "            # keep the list size to k elements\n",
    "            # insort method allows for more efficient insertion and sorting\n",
    "            insort(topk, temp_similarity)[:k]\n",
    "    return best, topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mixed score with alpha\n",
    "def get_mix_score(best, topk, alpha=0.5):\n",
    "    return (alpha * best) + ((1-alpha) * np.average(topk))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput score\n",
    "output.print(mix_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5623M_CW1_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
