{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR4bovYL4CJz"
   },
   "source": [
    "## Dissertation Project - News Summary Dissertation [100 marks]\n",
    "\n",
    "### Motivation \n",
    "\n",
    "> 1. Provide tools for anyone needing to speed up their research process\n",
    "> 2. Providing ways for user to quickly determine whether a piece of research is beneficial for their specific search terms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import string\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import json\n",
    "\n",
    "DATASET = \"./Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect which device (CPU/GPU) to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Summarisation model\n",
    "> 1. Dataset preprocessing\n",
    "> 2. Dataloader\n",
    "> 3. RNN model definition\n",
    "> 4. Model training\n",
    "> 5. Model prediction evaluation\n",
    "> 6. Dataset Exploration\n",
    "> 7. Dataset modification/Data Augmentation\n",
    "> 8. Model improvement\n",
    "> 9. Model finalisation and evaluation\n",
    "\n",
    "Paper querying\n",
    "> 1. Attention on query (Return usefulness percentage\n",
    "> 2. Evaluate performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m DATASET\u001b[38;5;241m+\u001b[39mDATA_DIR\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dataset_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 5\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m      6\u001b[0m df_inter \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(lines)\n\u001b[0;32m      7\u001b[0m df_inter\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson_element\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py:22\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalDecoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalDecoder):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Comment this block if dataset is reorganised\n",
    "DATA_DIR = \"SSN/papers.SSN.jsonl\"\n",
    "dataset_path = DATASET+DATA_DIR\n",
    "with open(dataset_path) as f:\n",
    "    lines = f.read().splitlines()\n",
    "df_inter = pd.DataFrame(lines)\n",
    "df_inter.columns = ['json_element']\n",
    "df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "df_final.to_json(\"./Dataset/SSN/SSN_Dataset.json\")\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,summary in df_final.iterrows():\n",
    "    temp = summary[\"abstract\"]\n",
    "    print(type(summary[\"abstract\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>section_names</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4650265</td>\n",
       "      <td>XGBoost: A Scalable Tree Boosting System</td>\n",
       "      <td>[tree boosting is a highly effective and widel...</td>\n",
       "      <td>[introduction, tree boosting in a nutshell, re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[machine learning and data - driven approache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9195903</td>\n",
       "      <td>Robust Face Alignment Using a Mixture of Invar...</td>\n",
       "      <td>[face alignment , which is the task of finding...</td>\n",
       "      <td>[introduction, previous work, our approach, su...</td>\n",
       "      <td>[Computer science]</td>\n",
       "      <td>[[face alignment refers to finding the pixel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119332442</td>\n",
       "      <td>Modulation instability associated nonlinear dy...</td>\n",
       "      <td>[we study pattern - forming nonlinear dynamics...</td>\n",
       "      <td>[introduction, modulation instability of becs ...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[modulation instability ( mi ) is one of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13494452</td>\n",
       "      <td>Free evolution on algebras with two states</td>\n",
       "      <td>[the key result in the paper concerns two tran...</td>\n",
       "      <td>[introduction, preliminaries, polynomials and ...</td>\n",
       "      <td>[Mathematics]</td>\n",
       "      <td>[[in a series of papers belinschi and nica int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119269876</td>\n",
       "      <td>Light Dilaton at Fixed Points and Ultra Light ...</td>\n",
       "      <td>[we investigate the infrared dynamics of a non...</td>\n",
       "      <td>[introduction, a comment on the large nn and n...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[understanding strong dynamics constitutes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140794</th>\n",
       "      <td>12157610</td>\n",
       "      <td>Minimal and Maximal Operator Spaces and Operat...</td>\n",
       "      <td>[we examine k - minimal and k - maximal operat...</td>\n",
       "      <td>[introduction, quantum information theory prel...</td>\n",
       "      <td>[Mathematics]</td>\n",
       "      <td>[[a primary goal of this paper is to formally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140795</th>\n",
       "      <td>14690185</td>\n",
       "      <td>AN OBSTRUCTION TO ASYMPTOTIC SEMISTABILITY AND...</td>\n",
       "      <td>[in this paper , we consider an obstruction to...</td>\n",
       "      <td>[introduction, statement of results, an obstru...</td>\n",
       "      <td>[Mathematics]</td>\n",
       "      <td>[[for a polarized algebraic manifold inlinefor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140796</th>\n",
       "      <td>15296646</td>\n",
       "      <td>Direct Detection of Neutralino Dark Matter and...</td>\n",
       "      <td>[we compare predictions for the spin - indepen...</td>\n",
       "      <td>[introduction, msugra, more general models, co...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[the minimal supersymmetric standard model ( ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140797</th>\n",
       "      <td>119576690</td>\n",
       "      <td>PCA by Optimisation of Symmetric Functions has...</td>\n",
       "      <td>[principal component analysis ( pca ) finds th...</td>\n",
       "      <td>[introduction, pca by determinant optimisation...</td>\n",
       "      <td>[Mathematics]</td>\n",
       "      <td>[[let inlineform0 be a data matrix , with rows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140798</th>\n",
       "      <td>119301470</td>\n",
       "      <td>Turbulent fluxes of entropy and internal energ...</td>\n",
       "      <td>[we derive equations for the mean entropy and,...</td>\n",
       "      <td>[introduction, turbulent convective flux of me...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[temperature stratified turbulence ( e.g. , t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140799 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_id                                              title  \\\n",
       "0         4650265           XGBoost: A Scalable Tree Boosting System   \n",
       "1         9195903  Robust Face Alignment Using a Mixture of Invar...   \n",
       "2       119332442  Modulation instability associated nonlinear dy...   \n",
       "3        13494452         Free evolution on algebras with two states   \n",
       "4       119269876  Light Dilaton at Fixed Points and Ultra Light ...   \n",
       "...           ...                                                ...   \n",
       "140794   12157610  Minimal and Maximal Operator Spaces and Operat...   \n",
       "140795   14690185  AN OBSTRUCTION TO ASYMPTOTIC SEMISTABILITY AND...   \n",
       "140796   15296646  Direct Detection of Neutralino Dark Matter and...   \n",
       "140797  119576690  PCA by Optimisation of Symmetric Functions has...   \n",
       "140798  119301470  Turbulent fluxes of entropy and internal energ...   \n",
       "\n",
       "                                                 abstract  \\\n",
       "0       [tree boosting is a highly effective and widel...   \n",
       "1       [face alignment , which is the task of finding...   \n",
       "2       [we study pattern - forming nonlinear dynamics...   \n",
       "3       [the key result in the paper concerns two tran...   \n",
       "4       [we investigate the infrared dynamics of a non...   \n",
       "...                                                   ...   \n",
       "140794  [we examine k - minimal and k - maximal operat...   \n",
       "140795  [in this paper , we consider an obstruction to...   \n",
       "140796  [we compare predictions for the spin - indepen...   \n",
       "140797  [principal component analysis ( pca ) finds th...   \n",
       "140798  [we derive equations for the mean entropy and,...   \n",
       "\n",
       "                                            section_names              domain  \\\n",
       "0       [introduction, tree boosting in a nutshell, re...                  []   \n",
       "1       [introduction, previous work, our approach, su...  [Computer science]   \n",
       "2       [introduction, modulation instability of becs ...           [Physics]   \n",
       "3       [introduction, preliminaries, polynomials and ...       [Mathematics]   \n",
       "4       [introduction, a comment on the large nn and n...           [Physics]   \n",
       "...                                                   ...                 ...   \n",
       "140794  [introduction, quantum information theory prel...       [Mathematics]   \n",
       "140795  [introduction, statement of results, an obstru...       [Mathematics]   \n",
       "140796  [introduction, msugra, more general models, co...           [Physics]   \n",
       "140797  [introduction, pca by determinant optimisation...       [Mathematics]   \n",
       "140798  [introduction, turbulent convective flux of me...           [Physics]   \n",
       "\n",
       "                                                     text  \n",
       "0       [[machine learning and data - driven approache...  \n",
       "1       [[face alignment refers to finding the pixel l...  \n",
       "2       [[modulation instability ( mi ) is one of the ...  \n",
       "3       [[in a series of papers belinschi and nica int...  \n",
       "4       [[understanding strong dynamics constitutes a ...  \n",
       "...                                                   ...  \n",
       "140794  [[a primary goal of this paper is to formally ...  \n",
       "140795  [[for a polarized algebraic manifold inlinefor...  \n",
       "140796  [[the minimal supersymmetric standard model ( ...  \n",
       "140797  [[let inlineform0 be a data matrix , with rows...  \n",
       "140798  [[temperature stratified turbulence ( e.g. , t...  \n",
       "\n",
       "[140799 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comment this block if dataset is shortened\n",
    "DATA_DIR = \"SSN/SSN_Dataset.json\"\n",
    "dataset_path = DATASET+DATA_DIR\n",
    "df = pd.read_json(dataset_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['introduction',\n",
       " 'quantum information theory preliminaries',\n",
       " 'kk-minimal and kk-maximal operator spaces',\n",
       " 'kk-super minimal and kk-super maximal operator systems',\n",
       " 'norms on operator systems',\n",
       " 'contractive maps as separability criteria']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[140794][\"section_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return index for conclusion section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_index(row):\n",
    "    return [row.index(x)+1 for x in row if x.startswith('conclusion') or x.startswith(\"summar\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_text(text, index):\n",
    "    return text[0:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49413\n"
     ]
    }
   ],
   "source": [
    "# Comment this block if dataset is shortened\n",
    "# Trim text after conclusion\n",
    "indexes = []\n",
    "for i, row in df.iterrows():\n",
    "    section = row[\"section_names\"]\n",
    "    #print(section)\n",
    "    index = trim_index(section)\n",
    "    #print(index)\n",
    "    if not index:\n",
    "        indexes.append(i)\n",
    "    # if section can be filtered\n",
    "    else:\n",
    "        index = index[0]\n",
    "        abstract = row[\"abstract\"]\n",
    "        text = row[\"text\"]\n",
    "        section = row[\"section_names\"]\n",
    "        df.at[i, \"section_names\"] = trim_text(section, index)\n",
    "        df.at[i, \"abstract\"] = trim_text(abstract, index)\n",
    "        df.at[i, \"text\"] = trim_text(text, index)\n",
    "# dropping rows in dataframe that can't easily filter out reference section\n",
    "print(len(indexes))\n",
    "df.drop(indexes, inplace=True)\n",
    "df.to_json(\"./Dataset/SSN/SSN_Dataset_Short.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35% of paper will be removed from the dataset due to it not having conclusion(s) and summary(ies) in their section titles, making it difficult to filter out the reference and appendix text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>section_names</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4650265</td>\n",
       "      <td>XGBoost: A Scalable Tree Boosting System</td>\n",
       "      <td>[tree boosting is a highly effective and widel...</td>\n",
       "      <td>[introduction, tree boosting in a nutshell, re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[machine learning and data - driven approache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9195903</td>\n",
       "      <td>Robust Face Alignment Using a Mixture of Invar...</td>\n",
       "      <td>[face alignment , which is the task of finding...</td>\n",
       "      <td>[introduction, previous work, our approach, su...</td>\n",
       "      <td>[Computer science]</td>\n",
       "      <td>[[face alignment refers to finding the pixel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119332442</td>\n",
       "      <td>Modulation instability associated nonlinear dy...</td>\n",
       "      <td>[we study pattern - forming nonlinear dynamics...</td>\n",
       "      <td>[introduction, modulation instability of becs ...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[modulation instability ( mi ) is one of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119269876</td>\n",
       "      <td>Light Dilaton at Fixed Points and Ultra Light ...</td>\n",
       "      <td>[we investigate the infrared dynamics of a non...</td>\n",
       "      <td>[introduction, a comment on the large nn and n...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[understanding strong dynamics constitutes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59413881</td>\n",
       "      <td>Decoder-tailored Polar Code Design Using the G...</td>\n",
       "      <td>[we propose a new framework for constructing p...</td>\n",
       "      <td>[introduction, polar codes, polar code constru...</td>\n",
       "      <td>[Computer science, Mathematics]</td>\n",
       "      <td>[[polar codes   are the first family of codes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91381</th>\n",
       "      <td>1520660</td>\n",
       "      <td>Dirichlet Process Mixtures of Generalized Line...</td>\n",
       "      <td>[we propose dirichlet process mixtures of gene...</td>\n",
       "      <td>[introduction, related work, mathematical back...</td>\n",
       "      <td>[Mathematics, Computer science]</td>\n",
       "      <td>[[in this paper , we examine the general regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91382</th>\n",
       "      <td>118501110</td>\n",
       "      <td>Minimal Matter at the Large Hadron Collider</td>\n",
       "      <td>[we classify all possible new u(1 ) x su(2 ), ...</td>\n",
       "      <td>[introduction, new matter and its production, ...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[the higgs mass hierarchy puzzle suggests new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91383</th>\n",
       "      <td>16180248</td>\n",
       "      <td>On simulations of the classical harmonic oscil...</td>\n",
       "      <td>[we show that any second order linear ordinary...</td>\n",
       "      <td>[introduction, simplest discretizations of the...</td>\n",
       "      <td>[Physics, Mathematics]</td>\n",
       "      <td>[[the motivation for writing this paper is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91384</th>\n",
       "      <td>15296646</td>\n",
       "      <td>Direct Detection of Neutralino Dark Matter and...</td>\n",
       "      <td>[we compare predictions for the spin - indepen...</td>\n",
       "      <td>[introduction, msugra, more general models, co...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[the minimal supersymmetric standard model ( ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91385</th>\n",
       "      <td>119301470</td>\n",
       "      <td>Turbulent fluxes of entropy and internal energ...</td>\n",
       "      <td>[we derive equations for the mean entropy and,...</td>\n",
       "      <td>[introduction, turbulent convective flux of me...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[temperature stratified turbulence ( e.g. , t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91386 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper_id                                              title  \\\n",
       "0        4650265           XGBoost: A Scalable Tree Boosting System   \n",
       "1        9195903  Robust Face Alignment Using a Mixture of Invar...   \n",
       "2      119332442  Modulation instability associated nonlinear dy...   \n",
       "3      119269876  Light Dilaton at Fixed Points and Ultra Light ...   \n",
       "4       59413881  Decoder-tailored Polar Code Design Using the G...   \n",
       "...          ...                                                ...   \n",
       "91381    1520660  Dirichlet Process Mixtures of Generalized Line...   \n",
       "91382  118501110        Minimal Matter at the Large Hadron Collider   \n",
       "91383   16180248  On simulations of the classical harmonic oscil...   \n",
       "91384   15296646  Direct Detection of Neutralino Dark Matter and...   \n",
       "91385  119301470  Turbulent fluxes of entropy and internal energ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      [tree boosting is a highly effective and widel...   \n",
       "1      [face alignment , which is the task of finding...   \n",
       "2      [we study pattern - forming nonlinear dynamics...   \n",
       "3      [we investigate the infrared dynamics of a non...   \n",
       "4      [we propose a new framework for constructing p...   \n",
       "...                                                  ...   \n",
       "91381  [we propose dirichlet process mixtures of gene...   \n",
       "91382  [we classify all possible new u(1 ) x su(2 ), ...   \n",
       "91383  [we show that any second order linear ordinary...   \n",
       "91384  [we compare predictions for the spin - indepen...   \n",
       "91385  [we derive equations for the mean entropy and,...   \n",
       "\n",
       "                                           section_names  \\\n",
       "0      [introduction, tree boosting in a nutshell, re...   \n",
       "1      [introduction, previous work, our approach, su...   \n",
       "2      [introduction, modulation instability of becs ...   \n",
       "3      [introduction, a comment on the large nn and n...   \n",
       "4      [introduction, polar codes, polar code constru...   \n",
       "...                                                  ...   \n",
       "91381  [introduction, related work, mathematical back...   \n",
       "91382  [introduction, new matter and its production, ...   \n",
       "91383  [introduction, simplest discretizations of the...   \n",
       "91384  [introduction, msugra, more general models, co...   \n",
       "91385  [introduction, turbulent convective flux of me...   \n",
       "\n",
       "                                domain  \\\n",
       "0                                   []   \n",
       "1                   [Computer science]   \n",
       "2                            [Physics]   \n",
       "3                            [Physics]   \n",
       "4      [Computer science, Mathematics]   \n",
       "...                                ...   \n",
       "91381  [Mathematics, Computer science]   \n",
       "91382                        [Physics]   \n",
       "91383           [Physics, Mathematics]   \n",
       "91384                        [Physics]   \n",
       "91385                        [Physics]   \n",
       "\n",
       "                                                    text  \n",
       "0      [[machine learning and data - driven approache...  \n",
       "1      [[face alignment refers to finding the pixel l...  \n",
       "2      [[modulation instability ( mi ) is one of the ...  \n",
       "3      [[understanding strong dynamics constitutes a ...  \n",
       "4      [[polar codes   are the first family of codes ...  \n",
       "...                                                  ...  \n",
       "91381  [[in this paper , we examine the general regre...  \n",
       "91382  [[the higgs mass hierarchy puzzle suggests new...  \n",
       "91383  [[the motivation for writing this paper is an ...  \n",
       "91384  [[the minimal supersymmetric standard model ( ...  \n",
       "91385  [[temperature stratified turbulence ( e.g. , t...  \n",
       "\n",
       "[91386 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"SSN/SSN_Dataset_Short.json\"\n",
    "dataset_path = DATASET+DATA_DIR\n",
    "df = pd.read_json(dataset_path)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tree boosting is a highly effective and widel...</td>\n",
       "      <td>[[machine learning and data - driven approache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[face alignment , which is the task of finding...</td>\n",
       "      <td>[[face alignment refers to finding the pixel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[we study pattern - forming nonlinear dynamics...</td>\n",
       "      <td>[[modulation instability ( mi ) is one of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we investigate the infrared dynamics of a non...</td>\n",
       "      <td>[[understanding strong dynamics constitutes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[we propose a new framework for constructing p...</td>\n",
       "      <td>[[polar codes   are the first family of codes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91381</th>\n",
       "      <td>[we propose dirichlet process mixtures of gene...</td>\n",
       "      <td>[[in this paper , we examine the general regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91382</th>\n",
       "      <td>[we classify all possible new u(1 ) x su(2 ), ...</td>\n",
       "      <td>[[the higgs mass hierarchy puzzle suggests new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91383</th>\n",
       "      <td>[we show that any second order linear ordinary...</td>\n",
       "      <td>[[the motivation for writing this paper is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91384</th>\n",
       "      <td>[we compare predictions for the spin - indepen...</td>\n",
       "      <td>[[the minimal supersymmetric standard model ( ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91385</th>\n",
       "      <td>[we derive equations for the mean entropy and,...</td>\n",
       "      <td>[[temperature stratified turbulence ( e.g. , t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91386 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "0      [tree boosting is a highly effective and widel...   \n",
       "1      [face alignment , which is the task of finding...   \n",
       "2      [we study pattern - forming nonlinear dynamics...   \n",
       "3      [we investigate the infrared dynamics of a non...   \n",
       "4      [we propose a new framework for constructing p...   \n",
       "...                                                  ...   \n",
       "91381  [we propose dirichlet process mixtures of gene...   \n",
       "91382  [we classify all possible new u(1 ) x su(2 ), ...   \n",
       "91383  [we show that any second order linear ordinary...   \n",
       "91384  [we compare predictions for the spin - indepen...   \n",
       "91385  [we derive equations for the mean entropy and,...   \n",
       "\n",
       "                                                    text  \n",
       "0      [[machine learning and data - driven approache...  \n",
       "1      [[face alignment refers to finding the pixel l...  \n",
       "2      [[modulation instability ( mi ) is one of the ...  \n",
       "3      [[understanding strong dynamics constitutes a ...  \n",
       "4      [[polar codes   are the first family of codes ...  \n",
       "...                                                  ...  \n",
       "91381  [[in this paper , we examine the general regre...  \n",
       "91382  [[the higgs mass hierarchy puzzle suggests new...  \n",
       "91383  [[the motivation for writing this paper is an ...  \n",
       "91384  [[the minimal supersymmetric standard model ( ...  \n",
       "91385  [[temperature stratified turbulence ( e.g. , t...  \n",
       "\n",
       "[91386 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = df[[\"abstract\", \"text\"]]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any columns contain empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstract    False\n",
       "text        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\'hi\\' \\ is used for space <br>\n",
    "random space, which is used for reference [15] quote box <br>\n",
    "sec ref is hyperlink to a section <br>\n",
    "fig ref is hyperlink to a figure <br>\n",
    "inlineform <br>\n",
    "displayform are both symbols, both contains numbers in string <br>\n",
    "remove all forms and remove all symbols but keep numbers <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_let(string):\n",
    "    return any(char.isalpha() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_num(string):\n",
    "    return any(char.isdigit() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLine(line, text=False):\n",
    "    \"Text parameter is to indicate whether the line is from text or abstract\"\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    number = list(map(str, range(10)))\n",
    "    symbols = [\"'\", \"’\"]\n",
    "    valid_char = alphabet + number + symbols\n",
    "    stop_words = list(ENGLISH_STOP_WORDS)\n",
    "    \n",
    "    clean_line = line.lower()\n",
    "    clean_line = clean_line.strip()\n",
    "    \n",
    "    # fix apostrophes in line by removing apostrophe with no following alphabet character\n",
    "    clean_line = clean_line.replace(\"' \", \" \")\n",
    "    if clean_line and clean_line[-1] == \"'\":\n",
    "        clean_line = clean_line[0:len(clean_line)-1]\n",
    "    # fix apostrophes in line by removing space before single quote\n",
    "    clean_line = clean_line.replace(\" '\", \"'\")\n",
    "    #remove punctuation\n",
    "    # replace all non alphabet character with space\n",
    "    difference = list(set(clean_line).symmetric_difference(valid_char))\n",
    "\n",
    "    for dif in difference:\n",
    "        clean_line = clean_line.replace(dif, \" \")\n",
    "    \n",
    "    # clean line = clean line remove forms\n",
    "    words = clean_line.split()\n",
    "\n",
    "    #  remove forms\n",
    "    words = [x.replace(x, \"\") if contain_let(x) and contain_num(x) else x for x in words]\n",
    "    # remove empty strings\n",
    "    words = filter(None, words)\n",
    "\n",
    "    # stop words from sklearn, remove stop words\n",
    "    if text:\n",
    "        words = [x for x in words if not x in stop_words]\n",
    "\n",
    "    # combine the items into 1 string\n",
    "    clean_line = ' '.join(words)\n",
    "    return clean_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatParagraph(paragraph, text):\n",
    "    clean_paragraph = \"\"\n",
    "    for line in paragraph:\n",
    "        lines = cleanLine(line)\n",
    "        clean_paragraph += cleanLine(lines, text) + \" \"\n",
    "        #print(clean_paragraph)\n",
    "        \n",
    "    return(clean_paragraph.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatPaper(paper, text):\n",
    "    clean_paper = \"\"\n",
    "    for paragraph in paper:\n",
    "        clean_paper += concatParagraph(paragraph, text) + \" \"\n",
    "    return(clean_paper.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c747d1730049bb899ed98de284d97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, row in tqdm(summary_df.iterrows(), total=df.shape[0]):\n",
    "    abstract = row[\"abstract\"]\n",
    "    paper = row[\"text\"]\n",
    "    \n",
    "    summary_df.at[i, \"abstract\"] = concatParagraph(abstract, text=False)\n",
    "    summary_df.at[i, \"text\"] = concatPaper(paper, text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree boosting is a highly effective and widely...</td>\n",
       "      <td>machine learning and data driven approaches ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face alignment which is the task of finding th...</td>\n",
       "      <td>face alignment refers to finding the pixel loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we study pattern forming nonlinear dynamics st...</td>\n",
       "      <td>modulation instability mi is one of the most f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we investigate the infrared dynamics of a nons...</td>\n",
       "      <td>understanding strong dynamics constitutes a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we propose a new framework for constructing po...</td>\n",
       "      <td>polar codes are the first family of codes prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91381</th>\n",
       "      <td>we propose dirichlet process mixtures of gener...</td>\n",
       "      <td>in this paper we examine the general regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91382</th>\n",
       "      <td>we classify all possible new u 1 x su 2 x su 3...</td>\n",
       "      <td>the higgs mass hierarchy puzzle suggests new p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91383</th>\n",
       "      <td>we show that any second order linear ordinary ...</td>\n",
       "      <td>the motivation for writing this paper is an ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91384</th>\n",
       "      <td>we compare predictions for the spin independen...</td>\n",
       "      <td>the minimal supersymmetric standard model mssm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91385</th>\n",
       "      <td>we derive equations for the mean entropy and t...</td>\n",
       "      <td>temperature stratified turbulence e g turbulen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91386 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "0      tree boosting is a highly effective and widely...   \n",
       "1      face alignment which is the task of finding th...   \n",
       "2      we study pattern forming nonlinear dynamics st...   \n",
       "3      we investigate the infrared dynamics of a nons...   \n",
       "4      we propose a new framework for constructing po...   \n",
       "...                                                  ...   \n",
       "91381  we propose dirichlet process mixtures of gener...   \n",
       "91382  we classify all possible new u 1 x su 2 x su 3...   \n",
       "91383  we show that any second order linear ordinary ...   \n",
       "91384  we compare predictions for the spin independen...   \n",
       "91385  we derive equations for the mean entropy and t...   \n",
       "\n",
       "                                                    text  \n",
       "0      machine learning and data driven approaches ar...  \n",
       "1      face alignment refers to finding the pixel loc...  \n",
       "2      modulation instability mi is one of the most f...  \n",
       "3      understanding strong dynamics constitutes a co...  \n",
       "4      polar codes are the first family of codes prov...  \n",
       "...                                                  ...  \n",
       "91381  in this paper we examine the general regressio...  \n",
       "91382  the higgs mass hierarchy puzzle suggests new p...  \n",
       "91383  the motivation for writing this paper is an ob...  \n",
       "91384  the minimal supersymmetric standard model mssm...  \n",
       "91385  temperature stratified turbulence e g turbulen...  \n",
       "\n",
       "[91386 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.to_json(\"./Dataset/SSN/SSN_Dataset_Short_Clean_NoStop.json\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree boosting is a highly effective and widely...</td>\n",
       "      <td>machine learning and data driven approaches ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face alignment which is the task of finding th...</td>\n",
       "      <td>face alignment refers to finding the pixel loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we study pattern forming nonlinear dynamics st...</td>\n",
       "      <td>modulation instability mi is one of the most f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we investigate the infrared dynamics of a nons...</td>\n",
       "      <td>understanding strong dynamics constitutes a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we propose a new framework for constructing po...</td>\n",
       "      <td>polar codes are the first family of codes prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91381</th>\n",
       "      <td>we propose dirichlet process mixtures of gener...</td>\n",
       "      <td>in this paper we examine the general regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91382</th>\n",
       "      <td>we classify all possible new u 1 x su 2 x su 3...</td>\n",
       "      <td>the higgs mass hierarchy puzzle suggests new p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91383</th>\n",
       "      <td>we show that any second order linear ordinary ...</td>\n",
       "      <td>the motivation for writing this paper is an ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91384</th>\n",
       "      <td>we compare predictions for the spin independen...</td>\n",
       "      <td>the minimal supersymmetric standard model mssm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91385</th>\n",
       "      <td>we derive equations for the mean entropy and t...</td>\n",
       "      <td>temperature stratified turbulence e g turbulen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91386 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "0      tree boosting is a highly effective and widely...   \n",
       "1      face alignment which is the task of finding th...   \n",
       "2      we study pattern forming nonlinear dynamics st...   \n",
       "3      we investigate the infrared dynamics of a nons...   \n",
       "4      we propose a new framework for constructing po...   \n",
       "...                                                  ...   \n",
       "91381  we propose dirichlet process mixtures of gener...   \n",
       "91382  we classify all possible new u 1 x su 2 x su 3...   \n",
       "91383  we show that any second order linear ordinary ...   \n",
       "91384  we compare predictions for the spin independen...   \n",
       "91385  we derive equations for the mean entropy and t...   \n",
       "\n",
       "                                                    text  \n",
       "0      machine learning and data driven approaches ar...  \n",
       "1      face alignment refers to finding the pixel loc...  \n",
       "2      modulation instability mi is one of the most f...  \n",
       "3      understanding strong dynamics constitutes a co...  \n",
       "4      polar codes are the first family of codes prov...  \n",
       "...                                                  ...  \n",
       "91381  in this paper we examine the general regressio...  \n",
       "91382  the higgs mass hierarchy puzzle suggests new p...  \n",
       "91383  the motivation for writing this paper is an ob...  \n",
       "91384  the minimal supersymmetric standard model mssm...  \n",
       "91385  temperature stratified turbulence e g turbulen...  \n",
       "\n",
       "[91386 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"SSN/SSN_Dataset_Short_Clean_NoStop.json\"\n",
    "dataset_path = DATASET+DATA_DIR\n",
    "df = pd.read_json(dataset_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>study pattern forming nonlinear dynamics start...</td>\n",
       "      <td>modulation instability mi fundamental process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>investigate infrared dynamics nonsupersymmetri...</td>\n",
       "      <td>understanding strong dynamics constitutes cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>derive present expressions kinematic endpoints...</td>\n",
       "      <td>standard model sm particle physics enormously ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compute strange quark mass m s average u d qua...</td>\n",
       "      <td>masses strange light quarks fundamental parame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qcd analysis world data inclusive polarized de...</td>\n",
       "      <td>remarkable growth experimental data inclusive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29799</th>\n",
       "      <td>goal paper use multi task learning efficiently...</td>\n",
       "      <td>slot filling models useful method simple natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29800</th>\n",
       "      <td>consider source alice trying communicate desti...</td>\n",
       "      <td>information secrecy challenge wireless communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29801</th>\n",
       "      <td>propose novel deep supervised neural network t...</td>\n",
       "      <td>action recognition description videos fundamen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29802</th>\n",
       "      <td>examine learning offensive content twitter lim...</td>\n",
       "      <td>proliferation social media millions people cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29803</th>\n",
       "      <td>second order linear ordinary diffrential equat...</td>\n",
       "      <td>motivation writing paper observation small app...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29804 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "0      study pattern forming nonlinear dynamics start...   \n",
       "1      investigate infrared dynamics nonsupersymmetri...   \n",
       "2      derive present expressions kinematic endpoints...   \n",
       "3      compute strange quark mass m s average u d qua...   \n",
       "4      qcd analysis world data inclusive polarized de...   \n",
       "...                                                  ...   \n",
       "29799  goal paper use multi task learning efficiently...   \n",
       "29800  consider source alice trying communicate desti...   \n",
       "29801  propose novel deep supervised neural network t...   \n",
       "29802  examine learning offensive content twitter lim...   \n",
       "29803  second order linear ordinary diffrential equat...   \n",
       "\n",
       "                                                    text  \n",
       "0      modulation instability mi fundamental process ...  \n",
       "1      understanding strong dynamics constitutes cont...  \n",
       "2      standard model sm particle physics enormously ...  \n",
       "3      masses strange light quarks fundamental parame...  \n",
       "4      remarkable growth experimental data inclusive ...  \n",
       "...                                                  ...  \n",
       "29799  slot filling models useful method simple natur...  \n",
       "29800  information secrecy challenge wireless communi...  \n",
       "29801  action recognition description videos fundamen...  \n",
       "29802  proliferation social media millions people cur...  \n",
       "29803  motivation writing paper observation small app...  \n",
       "\n",
       "[29804 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "t_max= 1983.0\n",
    "a_max=  82.0\n",
    "t_min=  250.108\n",
    "a_min=  20.0\n",
    "for i, row in df.iterrows():\n",
    "    t_word = len(row[\"text\"].split())\n",
    "    a_word = len(row[\"abstract\"].split())\n",
    "    if (t_word >= t_max or t_word <=t_min or a_word>=a_max or a_word <= a_min):\n",
    "        rows.append(i)\n",
    "df.drop(rows, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\" Simple vocabulary wrapper which maps every unique word to an integer ID. \"\"\"\n",
    "    def __init__(self):\n",
    "        # intially, set both the IDs and words to dictionaries with special tokens\n",
    "        self.word2idx = {'<start>': 0, '<end>': 1, '<pad>':2, '<unk>':3}\n",
    "        self.idx2word = {0: '<start>', 1: '<end>', 2: '<pad>', 3: '<unk>'}\n",
    "        self.idx = 4\n",
    "\n",
    "    def add_word(self, word):\n",
    "        # if the word does not already exist in the dictionary, add it\n",
    "        if not word in self.word2idx:\n",
    "            # this will convert each word to index and index to word as you saw in the tutorials\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            # increment the ID for the next word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        # if we try to access a word not in the dictionary, return the id for <unk>\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    ## added function for utility\n",
    "    def get_word(self,index):\n",
    "        # this returns the word when given an index\n",
    "        return self.idx2word[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "    \"\"\" \n",
    "    Parses training set token file captions and builds a Vocabulary object and dataframe for \n",
    "    the image and caption data\n",
    "\n",
    "    Returns:\n",
    "        vocab (Vocabulary): Vocabulary object containing all words appearing more than min_frequency\n",
    "    \"\"\"\n",
    "    MIN_FREQUENCY = 0\n",
    "    word_mapping = Counter()\n",
    "\n",
    "    # for index in df.index:\n",
    "    for text in tqdm(data):\n",
    "        for word in text.split():\n",
    "            #print(word)\n",
    "            if word in word_mapping:\n",
    "                word_mapping[word] += 1\n",
    "            else:\n",
    "                word_mapping[word] = 1\n",
    "\n",
    "    # create a vocab instance\n",
    "    vocab = Vocabulary()\n",
    "\n",
    "    # add the words to the vocabulary\n",
    "    for word in word_mapping:\n",
    "        if word_mapping[word] > MIN_FREQUENCY:\n",
    "            vocab.add_word(word)\n",
    "\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert DF to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_txt = df['text']\n",
    "text_txt.to_csv(\"text_NoStop.txt\", header=False,index=False)\n",
    "# write to file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_model = fasttext.train_unsupervised('text_NoStop.txt', minn=2, epoch=10)\n",
    "vocab_model.save_model(\"fastText_NoStop.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7835723"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(vocab_model.get_words)\n",
    "# import numpy as np\n",
    "# import gc\n",
    "# import sys\n",
    "\n",
    "# def get_obj_size(obj):\n",
    "#     marked = {id(obj)}\n",
    "#     obj_q = [obj]\n",
    "#     sz = 0\n",
    "\n",
    "#     while obj_q:\n",
    "#         sz += sum(map(sys.getsizeof, obj_q))\n",
    "\n",
    "#         # Lookup all the object referred to by the object in obj_q.\n",
    "#         # See: https://docs.python.org/3.7/library/gc.html#gc.get_referents\n",
    "#         all_refr = ((id(o), o) for o in gc.get_referents(*obj_q))\n",
    "\n",
    "#         # Filter object that are already marked.\n",
    "#         # Using dict notation will prevent repeated objects.\n",
    "#         new_refr = {o_id: o for o_id, o in all_refr if o_id not in marked and not isinstance(o, type)}\n",
    "\n",
    "#         # The new obj_q will be the ones that were not marked,\n",
    "#         # and we will update marked with their ids so we will\n",
    "#         # not traverse them again.\n",
    "#         obj_q = new_refr.values()\n",
    "#         marked.update(new_refr.keys())\n",
    "\n",
    "#     return sz\n",
    "# x = np.random.rand(1024).astype(np.float64)\n",
    "# y = np.random.rand(1024).astype(np.float64)\n",
    "# a = {'x': x, 'y': y}\n",
    "# get_obj_size(vocab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getWordVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326814c7aa9743c68bd49bd627d8fc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstract_vocab = build_vocab(df[\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbbb88a87f946a18b87810a64da1b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_vocab = build_vocab(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(vocab, text, max_len):\n",
    "    word_ids = []\n",
    "    for word in text.split():\n",
    "        word_ids.append(vocab(word))\n",
    "    word_ids.append(vocab(\"<end>\"))\n",
    "#     while len(word_ids) < max_len:\n",
    "#             word_ids.append(vocab(\"<pad>\"))\n",
    "    return word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTRACT_MAX = 82\n",
    "TEXT_MAX = 1983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "# https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html\n",
    "w= widgets.IntSlider()\n",
    "display(w)\n",
    "w.value\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "display(out)\n",
    "with out:\n",
    "    for i in range(10):\n",
    "        print(i, 'Hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de614e57abef4f1e8fdfeaa93d05e141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab508313a4e45959643b8f3ef0ba1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNDataset(Dataset):\n",
    "    def __init__(self, df, a_vocab, t_vocab):\n",
    "\n",
    "        self.df = df\n",
    "        self.a_vocab = a_vocab\n",
    "        self.t_vocab = t_vocab\n",
    "        self.abstract_max_len = ABSTRACT_MAX\n",
    "        self.text_max_len = TEXT_MAX\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return word_id\n",
    "        abstract = self.df.iloc[index][\"abstract\"]\n",
    "        text = self.df.iloc[index][\"text\"]\n",
    "        \n",
    "        a_word_ids = tokenise(self.a_vocab, abstract, self.abstract_max_len)\n",
    "        t_word_ids = tokenise(self.t_vocab, text, self.text_max_len)\n",
    "\n",
    "        a_length = len(a_word_ids)\n",
    "        t_length = len(t_word_ids)\n",
    "    \n",
    "        return torch.tensor(a_word_ids), torch.tensor(t_word_ids)# torch.tensor(t_length)# torch.tensor(t_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_list(lis):\n",
    "    list_len = [len(i) for i in lis]\n",
    "    return (max(list_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_collate_fn(data):\n",
    "    \"\"\" Creates mini-batch tensors from the list of tuples (image, caption).\n",
    "    Args:\n",
    "        data: list of tuple of 2 word ids\n",
    "        - abstract id\n",
    "        - text id\n",
    "    Returns:\n",
    "        abstract list ids\n",
    "        text list ids\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    abstracts, texts = zip(*data)\n",
    "#     abstract_list = []\n",
    "#     text_list = []\n",
    "#     for i in range(len(texts)):\n",
    "#         while len(texts[i]) < find_max_list(texts):\n",
    "#             texts[i].append(text_vocab(\"<pad>\"))\n",
    "#         text_list.append(torch.tensor(texts[i]))\n",
    "        \n",
    "#     for i in range(len(abstracts)):\n",
    "#         while len(abstracts[i]) < 82:\n",
    "#             abstracts[i].append(abstract_vocab(\"<pad>\"))\n",
    "#         abstract_list.append(torch.tensor(abstracts[i]))\n",
    "\n",
    "\n",
    "#     abstracts = torch.tensor(abstracts)\n",
    "#     texts = torch.tensor(texts)\n",
    "#     abstracts = [ torch.Tensor(abstract).to(device) for abstract in abstracts ]\n",
    "# if batch size is 1 then use [0]\n",
    "    abstracts = torch.stack(abstracts, 0)\n",
    "    #abstracts = abstracts.unsqueeze(0)\n",
    "#     abstracts = torch.nn.utils.rnn.pad_sequence(abstracts)\n",
    "    texts = torch.stack(texts, 0)\n",
    "    #texts = texts.unsqueeze(0)\n",
    "\n",
    "    return abstracts, texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, random_state=seed, train_size = 0.7)\n",
    "train_data, valid_data = train_test_split(train_data, random_state=seed, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SSNDataset(train_data, abstract_vocab, text_vocab)\n",
    "valid_set = SSNDataset(valid_data, abstract_vocab, text_vocab)\n",
    "test_set = SSNDataset(test_data, abstract_vocab, text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, collate_fn=text_collate_fn) # num_worker can't be 2+ as the time it \n",
    "                                                                 # takes to build iter is much longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(valid_set, batch_size=2, shuffle=True, collate_fn=text_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abfcd6f175a4bda8b438b9466a4fa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_set = SSNDataset(df, abstract_vocab, text_vocab)\n",
    "all_loader = DataLoader(all_set, batch_size=1, shuffle=True, collate_fn=text_collate_fn)\n",
    "abstracts = []\n",
    "texts = []\n",
    "for i, (abstract, text) in tqdm(enumerate(all_loader)):\n",
    "    a_size = list(abstract.size())[1]\n",
    "\n",
    "    t_size = list(text.size())[1]\n",
    "    abstracts.append(a_size)\n",
    "    texts.append(t_size)\n",
    "numbers = list(range(len(all_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(numbers, abstracts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(numbers, texts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length for abstract:  395\n",
      "max length for text:  8311\n",
      "min length for abstract:  2\n",
      "min length for text:  13\n",
      "average length for abstract:  144\n",
      "average length for text:  3899\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "print(\"max length for abstract: \",max(abstracts))\n",
    "print(\"max length for text: \",max(texts))\n",
    "print(\"min length for abstract: \",min(abstracts))\n",
    "print(\"min length for text: \",min(texts))\n",
    "print(\"average length for abstract: \",math.floor(mean(abstracts)))\n",
    "print(\"average length for text: \",math.floor(mean(texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 percentile:  3800.0\n",
      "50 percentile:  140.0\n",
      "0.08 percentile:  702.3240000000001\n",
      "0.08 percentile:  31.0\n"
     ]
    }
   ],
   "source": [
    "print(\"50 percentile: \", np.percentile(texts, 50))\n",
    "print(\"50 percentile: \", np.percentile(abstracts, 50))\n",
    "print(\"0.08 percentile: \", np.percentile(texts, 0.08))\n",
    "print(\"0.08 percentile: \", np.percentile(abstracts, 0.08))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, voc_size, num_layer, hidden_dim, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layer = num_layer\n",
    "        \n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=voc_size,\n",
    "            embedding_dim=hidden_dim\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layer,\n",
    "            bidirectional=False,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layer, batch_size, self.hidden_dim, device=device),\n",
    "                torch.zeros(self.num_layer, batch_size, self.hidden_dim, device=device))\n",
    "\n",
    "    def forward(self, input):\n",
    "        #start = time.time()\n",
    "\n",
    "        #print(input.shape)\n",
    "        embedded = self.embeddings(input)\n",
    "        lengths = (input != 2).sum(1) # pad index = 2\n",
    "        #print(lengths)\n",
    "        batch_size = input.shape[0]\n",
    "        embedded = self.embeddings(input)\n",
    "        #print(\"lengths: \",lengths.shape)\n",
    "#         print(lengths)\n",
    "#         print(\"embedded: \",embedded.shape)\n",
    "#         print(\"embedded: \",embedded.view(1, 1, -1).shape)\n",
    "    \n",
    "#         print(\"initial_hidden\", initial_hidden.shape)\n",
    "        embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), \n",
    "                                                           batch_first=True,enforce_sorted=False)\n",
    "#         print(\"embedded: \",embedded[0].shape)\n",
    "#         print(\"embedded: \",embedded[1].shape)\n",
    "        output, hidden = self.lstm(embedded)\n",
    "        #print(\"output: \",output.shape)\n",
    "        output, lengths = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True,padding_value=2)\n",
    "        lengths = lengths.to(device)\n",
    "        return output, hidden, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, voc_size, num_layer,hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=voc_size,\n",
    "            embedding_dim=hidden_dim\n",
    "        )\n",
    "        self.attention = Attention(hidden_dim,hidden_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim*2,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layer,\n",
    "            bidirectional=False,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=hidden_dim * 2,\n",
    "            out_features=voc_size\n",
    "        )\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "\n",
    "    def forward(self, input, hidden, context, encoder_outputs, lengths): # also add in encoder outputs \n",
    "                                                                # to create context\n",
    "        #start = time.time()\n",
    "        embedded = self.embeddings(input) # [batch, 256]\n",
    "        # hidden = [bathc, seq_len, hidden_dim]\n",
    "        # print(hidden[0])\n",
    "        #hidden_permute = hidden.permute(0,1) # [1, 512]\n",
    "        decoder_input = torch.cat((embedded, context), -1).unsqueeze(1) # [batch, 1, 512]\n",
    "        decoder_output, hidden = self.lstm(decoder_input, hidden)\n",
    "        decoder_output = decoder_output.squeeze(1)\n",
    "        \n",
    "        # mask to block decoder from knowing future sequences/block padding\n",
    "        max_len = lengths.max().item()\n",
    "        #print(\"max len: \", max_len)\n",
    "        \n",
    "       \n",
    "    \n",
    "        mask = torch.arange(max_len).expand(len(lengths), max_len) < lengths.unsqueeze(1).cpu()\n",
    "        mask = mask.to(device)\n",
    "#         print(\"size: \", len(mask))\n",
    "#         print(\"mask 0\",mask[0])\n",
    "#         print(\"mask0 len\",len(mask[0]))\n",
    "#         print(\"mask0 = true\",torch.sum(mask[0] == True))\n",
    "#         print(\"mask1\",mask[1])\n",
    "#         print(\"mask1 len\",len(mask[1]))\n",
    "#         print(\"mask1 = true\",torch.sum(mask[1] == True))\n",
    "        attention = self.attention(decoder_output, encoder_outputs, mask).to(device)\n",
    "\n",
    "        context = attention.unsqueeze(1).bmm(encoder_outputs).squeeze(1)\n",
    "        #print(\"context shape: \", context.shape)\n",
    "        output_context = torch.cat((decoder_output, context), dim=1) # []\n",
    "        #output_context = torch.nn.functional.relu(output_context)\n",
    "        \n",
    "        output_context = self.fc(output_context)\n",
    "        #print(output[0])\n",
    "        output = self.logsoftmax(output_context)\n",
    "        #end = time.time()\n",
    "        #print(\"Decoder Time: \",end - start)\n",
    "#         print(\"decode output: \",output)\n",
    "#         print(\"output: \", output.shape)\n",
    "        # output is [batch, seq_len, hidden_dim]\n",
    "        # hidden = 2,2,256 [2, batch, hidden_dim]\n",
    "        return output, hidden, context, attention\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.attn_hidden_vector = nn.Linear(encoder_hidden_dim + decoder_hidden_dim, decoder_hidden_dim)\n",
    "        \n",
    "#         self.attn_scoring_fn = nn.Linear(decoder_hidden_dim, decoder_hidden_dim, bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden = [num_layer, batch size, decoder hidden dim]\n",
    "        # encoder_outputs [batch, seq_len, hidden_dim]\n",
    "        seq_len = encoder_outputs.shape[1] # 10000\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        \n",
    "        #attention_scores = torch.zeros((batch_size, seq_len), device=device)\n",
    "\n",
    "        hidden = hidden.repeat(seq_len,1,1)\n",
    "        #print(hidden.shape)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "        #print(encoder_outputs.shape)\n",
    "\n",
    "        #print(\"attention score: \", attention_scores.shape)\n",
    "#         print(\"hidden atten: \",hidden.shape)\n",
    "#         print(\"encoder output: \", encoder_outputs.shape)\n",
    "\n",
    "\n",
    "        attention_scores = torch.einsum('sbd,sbd->bs',hidden, encoder_outputs) \n",
    "        # need to check if can use just lbd, sbd ->bs because hidden repeat don't work if more than 1 layer\n",
    "        #print(\"attention_scores: \",attention_scores.shape)\n",
    "\n",
    "            \n",
    "        attention_scores[~mask] = -float('inf')\n",
    "        #print(attention_scores)\n",
    "        #attention_scores = nn.functional.relu(attention_scores)\n",
    "        #end = time.time()\n",
    "        #print(\"Attention Time: \",end - start)\n",
    "        attention_scores = nn.functional.softmax(attention_scores, dim=1)\n",
    "        return attention_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder, hidden_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, abstract, text):\n",
    "        #decoder = Decoder(len(abstract_vocab), 512).to(device)\n",
    "        output, hidden, lengths = self.encoder(text) # [10000, 512] [seq_len, hidden_dim]\n",
    "        batch_size = output.shape[0]\n",
    "        \n",
    "        decoder_hidden = hidden\n",
    "        context = torch.zeros(batch_size, self.hidden_dim).to(device) # batch, hidden_dim\n",
    "        decoder_input = torch.LongTensor([0]).repeat(batch_size).to(device)\n",
    "#         out1 = output[0] # varied\n",
    "#         out2 = output[1]\n",
    "#         out3 = output[2]\n",
    "        done = torch.BoolTensor(batch_size).fill_(False).to(device)\n",
    "        outputs = []\n",
    "        words = []\n",
    "        for t in range(82):\n",
    "            decoder_output, decoder_hidden, context, attention = self.decoder(decoder_input, \n",
    "                                                            decoder_hidden, context, output, lengths)\n",
    "\n",
    "            outputs.append(decoder_output)\n",
    "\n",
    "            decoder_input = decoder_output.argmax(1)\n",
    "           \n",
    "            words.append(decoder_input)\n",
    "\n",
    "        sentence = \"\"\n",
    "        \n",
    "        for i in words:\n",
    "            sentence += abstract_vocab.get_word(i[0].item()) + \" \"\n",
    "        print(\"predict:\", sentence)\n",
    "        sentence = \"\"\n",
    "        for i in abstract[0]:\n",
    "            sentence += abstract_vocab.get_word(i.item()) + \" \"\n",
    "        print(\"actual:\", sentence)\n",
    "        outputs = torch.stack(outputs, 1) # B x T x D\n",
    "        return outputs\n",
    "\n",
    "        #input, hidden, context, encoder_outputs\n",
    "        # squeeze converts the [[]] 3d tensor to 2D, then detach converts it to 1D and item converts to int\n",
    "    #     _, initial = decode_output.topk(1)\n",
    "    #     initial = initial.squeeze().detach().item()\n",
    "    #     start_input = [initial]\n",
    "    #     decoded_words = [initial]\n",
    "#         decoded_words = [[]]\n",
    "#         done = [False for i in range(batch_size)]\n",
    "#         decoded_loss = torch.Tensor().to(device)\n",
    "        \n",
    "#         # attentions = []\n",
    "#         # repeat until end token, but should limit to less than text length\n",
    "#         # try keeping the variable length\n",
    "#         # when calculating loss expand either prediction or original to fit the lengthier target's length\n",
    "#         # by filling the rest with token for pad\n",
    "\n",
    "#         for i in range(82):\n",
    "#             decoder_output, decoder_hidden, context, attention = self.decoder(decoder_input, \n",
    "#                                                                   decoder_hidden, context, output, lengths)\n",
    "            \n",
    "            \n",
    "#             #print(decoder_output)\n",
    "\n",
    "#             # return attention\n",
    "#             # attentions.append(attention)\n",
    "#             # teacher forcing here, basically use ground truth values for input\n",
    "#     #         if random.uniform(0, 1) > 0.5:\n",
    "#             decoded_loss = torch.cat((decoded_loss, decoder_output.unsqueeze(1)), 1)\n",
    "#             _, topi = decoder_output.topk(k=1)\n",
    "#             #print(\"topi\",topi)\n",
    "#     #         else:\n",
    "#     #             topi = text[i]\n",
    "\n",
    "#             decoder_input = decoder_output.argmax(1)\n",
    "#             #print(\"deocder output\",decoder_input)\n",
    "\n",
    "#             for j in range(1):\n",
    "#                 if decoder_input[j].item() == 1:\n",
    "#                     done[j] = True\n",
    "#                 if not done[j]:\n",
    "#                     decoded_words[j].append(decoder_input[j].item())\n",
    "#                 else:\n",
    "#                     decoded_words[j].append(2)\n",
    "# #             start_input = [decoder_input.item()]\n",
    "#             #do some processing here to convert words into tensor for loss calculation\n",
    "\n",
    "#         for k in range(1):\n",
    "#             sentence=\"\"\n",
    "#             for i in decoded_words[k]:\n",
    "#                 sentence+= abstract_vocab.get_word(i) + \" \"\n",
    "#             print(\"predict: \",sentence)\n",
    "#         for i in range(1):\n",
    "#             sentence=\"\"\n",
    "#             for i in abstract[i]:\n",
    "#                 sentence+= abstract_vocab.get_word(i.item()) + \" \"\n",
    "#             print(\"actual: \",sentence)\n",
    "        #print((decoded_loss))\n",
    "        \n",
    "        return decoded_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(text_vocab), num_layer=2, hidden_dim=256, device=device)\n",
    "encoder = encoder.to(device)\n",
    "decoder = Decoder(len(abstract_vocab), num_layer=2, hidden_dim=256)\n",
    "decoder = decoder.to(device)\n",
    "# abstract, text = next(iter(train_loader))\n",
    "# abstract = abstract.to(device)\n",
    "# text = text.to(device)\n",
    "model = Model(encoder, decoder, 256)\n",
    "model = model.to(device)\n",
    "#out1 = model(abstract, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "~~1 - Complete model definition~~ <br>\n",
    "~~2 - fix word vocab~~ <br>\n",
    "~~3 - Define Attention model and combine with Decoder~~ <br>\n",
    "    ~~1 - Adjust to allow for batch ~~<br>\n",
    "4 - trace through program to see where it starts to have the same tensor <br>\n",
    "~~5 - use mask to hide paddings~~ switch on off to see difference<br>\n",
    "~~6 - Switch from GRU to LSTM~~<br>\n",
    "~~7 - Add training script to train ~~<br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model):\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # learning rate also affects overfitting\n",
    "    epoch_size = 150\n",
    "    loss_points = []\n",
    "    eval_loss_points = []\n",
    "    best_loss = 10000\n",
    "\n",
    "    for epoch in range(epoch_size):\n",
    "        \n",
    "        model.train()\n",
    "        loss_avg = []\n",
    "        for i, (abstract, text) in enumerate(train_loader):\n",
    "            # send batch data to device\n",
    "            abstract = abstract.to(device)\n",
    "            text = text.to(device)\n",
    "            \n",
    "            outputs = model(abstract, text).to(device).permute(0,2,1)\n",
    "            #print(\"output\",outputs[:,0,:])\n",
    "#             print(outputs.dtype)\n",
    "#             print(\"abstract\", abstract[:,0])\n",
    "#             print(abstract.dtype)\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            loss = criterion(outputs, abstract)\n",
    "            print(loss.item())\n",
    "\n",
    "            # Optimise\n",
    "            del abstract\n",
    "            del text\n",
    "            del outputs\n",
    "\n",
    "            loss_avg.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "           # plot_grad_flow(model.named_parameters())\n",
    "\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "            optimizer.step()\n",
    "\n",
    "            #print(loss.item())\n",
    "        current_loss = np.average(loss_avg)\n",
    "        loss_points.append(current_loss)\n",
    "\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "            .format(epoch+1, epoch_size, current_loss))\n",
    "\n",
    "        eval_loss_avg = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for j, (abstract, text) in enumerate(valid_loader):\n",
    "                abstract = abstract.to(device)\n",
    "                text = text.to(device)\n",
    "\n",
    "                scores = model(abstract, text).permute(0,2,1)\n",
    "                eval_loss = 0\n",
    "                \n",
    "                eval_loss = criterion(scores, abstract)\n",
    "                print(eval_loss.item())\n",
    "                eval_loss_avg.append(eval_loss.item())\n",
    "                del abstract\n",
    "                del text\n",
    "                del scores\n",
    "                del eval_loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        current_eval_loss = np.average(eval_loss_avg)\n",
    "        eval_loss_points.append(current_eval_loss)\n",
    "        if (current_eval_loss < best_loss):\n",
    "            best_loss = current_eval_loss\n",
    "            torch.save(model.state_dict(), 'best_decoder.pth')\n",
    "            print(\"Best eval loss updated!\")\n",
    "\n",
    "        print('Valid Epoch [{}/{}], Loss: {:.4f}'\n",
    "            .format(epoch+1, epoch_size, current_eval_loss))\n",
    "    return loss_points, eval_loss_points\n",
    "train_loss, eval_loss = train(train_loader, valid_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_decoder20230719.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        print(n)\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            #print(type(p.grad))\n",
    "            ave_grads.append(torch.mean(torch.abs(p.grad)).cpu())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f8bb119ac0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(eval_loss)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train loss','Valid loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train fasttext model\n",
    "obtain weight from fasttest\n",
    "then embedding can load weights\n",
    "\n",
    "- train 2 fasttext model, 1 for text and another for abstract\n",
    "- obtain weights for both vocab\n",
    "- put in encoder and decoder like normal\n",
    "- https://stackoverflow.com/questions/31440803/how-to-fetch-vectors-for-a-word-list-with-word2vec\n",
    "- use this to update the vocab class to update ways to fetch words\n",
    "- to solve querying, use the model and use function to find cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "data/fil9 cannot be opened for training!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_unsupervised\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/fil9\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult/fil9.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult/fil9.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\fasttext\\FastText.py:559\u001b[0m, in \u001b[0;36mtrain_unsupervised\u001b[1;34m(*kargs, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m a \u001b[38;5;241m=\u001b[39m _build_args(args, manually_set_args)\n\u001b[0;32m    558\u001b[0m ft \u001b[38;5;241m=\u001b[39m _FastText(args\u001b[38;5;241m=\u001b[39ma)\n\u001b[1;32m--> 559\u001b[0m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m ft\u001b[38;5;241m.\u001b[39mset_args(ft\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mgetArgs())\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ft\n",
      "\u001b[1;31mValueError\u001b[0m: data/fil9 cannot be opened for training!"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_unsupervised('data/fil9')\n",
    "model.save_model(\"result/fil9.bin\")\n",
    "model = fasttext.load_model(\"result/fil9.bin\")\n",
    "# EXPECTS TEXT FILE FORMAT WHERE 1 TEXT PER ROW\n",
    "# IMPORTANT, NEED TO REDESIGN CLEANING PROCESS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"\\....Downloads\\RuchaSawarkar.pdf\"\n",
    "#Using PyPDF2\n",
    "#importing required modules\n",
    "import PyPDF4\n",
    "# creating a pdf file object\n",
    "pdfFileObj = open(path, 'rb')\n",
    "#creating a pdf reader object\n",
    "pdfReader = PyPDF4.PdfFileReader(pdfFileObj)\n",
    "#printing number of pages in pdf file\n",
    "print(pdfReader.numPages)\n",
    "#creating a page object\n",
    "pageObj = pdfReader.getPage(0)\n",
    "# extracting text from page\n",
    "for i in range(pdfReader.numPages):\n",
    "    pypdf2_text +=pdfReader.getPage(i).extractText()\n",
    "#closing the pdf file object\n",
    "pdfFileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_lengths(df):\n",
    "    ratio = []\n",
    "    for i,row in df.iterrows():\n",
    "        article = len(row[\"article\"].split())\n",
    "        highlight = len(row[\"highlights\"].split())\n",
    "        if (i==137538):\n",
    "            print(row[\"article\"])\n",
    "            print(\"---------------------\")\n",
    "            print(row[\"highlights\"])\n",
    "        ratio.append(highlight/article)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downton Abbey's famously grim butler, Mr Bates .\n",
      "---------------------\n",
      "And now for the good news . . . Following a particularly grim week, here’s a compendium of some of the world’s most comforting headlines: .\n",
      "Supermodel Smiles On Catwalk .\n",
      "Jack Russell Dog Welcomes Stranger .\n",
      "Child At Funfair ‘Delighted’ By Goldfish .\n",
      "Katie Price Breasts ‘Roughly Same Size As Last Week’ Say Experts .\n",
      "Teenager Looks Up From Phone, Greets Parent .\n",
      "Political Pundits Agree To Stop Discussing Hung Parliament For Next Three Months .\n",
      "Diner Finishes His Curly Kale .\n",
      "Pensioner Looks Great In Party Hat .\n",
      "Celebrity Fails To Compare Life To Roller-coaster .\n",
      "Pet Hamster Repays Child’s Affection .\n",
      "‘Cheer Up, It May Never Happen’ — Downton’s Mr Bates Enjoys Belly-laugh .\n",
      "Style Journalist Fails To Employ The Word ‘Iconic’\n",
      "Sally Bercow Goes Out On Town, Retains Dignity .\n",
      "Entire Windfarm Operates According To Plan .\n",
      "Miley Cyrus Feels A Bit Chilly, Opts For Extra Layer .\n"
     ]
    }
   ],
   "source": [
    "ratio = get_df_lengths(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18686868686868688,\n",
       " 0.09693877551020408,\n",
       " 0.0853960396039604,\n",
       " 0.09981167608286252,\n",
       " 0.11551724137931034,\n",
       " 0.12574850299401197,\n",
       " 0.03099730458221024,\n",
       " 0.08695652173913043,\n",
       " 0.09688013136288999,\n",
       " 0.06306306306306306,\n",
       " 0.09338235294117647,\n",
       " 0.09428129829984544,\n",
       " 0.04805914972273567,\n",
       " 0.14903846153846154,\n",
       " 0.05941845764854614,\n",
       " 0.12058212058212059,\n",
       " 0.03619909502262444,\n",
       " 0.05114029025570145,\n",
       " 0.14392059553349876,\n",
       " 0.09248554913294797,\n",
       " 0.11290322580645161,\n",
       " 0.06223175965665236,\n",
       " 0.025252525252525252,\n",
       " 0.0670807453416149,\n",
       " 0.07357357357357357,\n",
       " 0.059931506849315065,\n",
       " 0.0497335701598579,\n",
       " 0.04749512036434613,\n",
       " 0.22916666666666666,\n",
       " 0.12189616252821671,\n",
       " 0.10119840213049268,\n",
       " 0.04323094425483504,\n",
       " 0.09049773755656108,\n",
       " 0.022063208109719738,\n",
       " 0.10561797752808989,\n",
       " 0.16293929712460065,\n",
       " 0.058163265306122446,\n",
       " 0.11014492753623188,\n",
       " 0.04020979020979021,\n",
       " 0.13213213213213212,\n",
       " 0.1079734219269103,\n",
       " 0.05200945626477541,\n",
       " 0.07241379310344828,\n",
       " 0.07616707616707617,\n",
       " 0.09510869565217392,\n",
       " 0.11284722222222222,\n",
       " 0.13166144200626959,\n",
       " 0.08482142857142858,\n",
       " 0.07086614173228346,\n",
       " 0.03248099516240498,\n",
       " 0.1076555023923445,\n",
       " 0.08943089430894309,\n",
       " 0.07090103397341212,\n",
       " 0.07272727272727272,\n",
       " 0.03939393939393939,\n",
       " 0.06487341772151899,\n",
       " 0.0389321468298109,\n",
       " 0.076163610719323,\n",
       " 0.055842812823164424,\n",
       " 0.13648293963254593,\n",
       " 0.040634291377601585,\n",
       " 0.07153284671532846,\n",
       " 0.20555555555555555,\n",
       " 0.09803921568627451,\n",
       " 0.024691358024691357,\n",
       " 0.05551149881046788,\n",
       " 0.07025411061285501,\n",
       " 0.08278145695364239,\n",
       " 0.052083333333333336,\n",
       " 0.13564668769716087,\n",
       " 0.07599118942731277,\n",
       " 0.10480349344978165,\n",
       " 0.116600790513834,\n",
       " 0.05077262693156733,\n",
       " 0.056676272814601344,\n",
       " 0.07973421926910298,\n",
       " 0.10470588235294118,\n",
       " 0.08161512027491409,\n",
       " 0.02046204620462046,\n",
       " 0.050808314087759814,\n",
       " 0.14105793450881612,\n",
       " 0.04881656804733728,\n",
       " 0.13653136531365315,\n",
       " 0.12142038946162657,\n",
       " 0.07822085889570553,\n",
       " 0.06643356643356643,\n",
       " 0.10251450676982592,\n",
       " 0.046255506607929514,\n",
       " 0.015037593984962405,\n",
       " 0.05555555555555555,\n",
       " 0.04645161290322581,\n",
       " 0.18543046357615894,\n",
       " 0.13921901528013583,\n",
       " 0.11219512195121951,\n",
       " 0.09090909090909091,\n",
       " 0.03052805280528053,\n",
       " 0.15471698113207547,\n",
       " 0.19631901840490798,\n",
       " 0.14532019704433496,\n",
       " 0.03944315545243619,\n",
       " 0.1456953642384106,\n",
       " 0.0974264705882353,\n",
       " 0.037383177570093455,\n",
       " 0.08912655971479501,\n",
       " 0.09859154929577464,\n",
       " 0.14320388349514562,\n",
       " 0.03433835845896147,\n",
       " 0.04825090470446321,\n",
       " 0.07600950118764846,\n",
       " 0.04100946372239748,\n",
       " 0.16829268292682928,\n",
       " 0.05714285714285714,\n",
       " 0.09340659340659341,\n",
       " 0.08695652173913043,\n",
       " 0.10645724258289703,\n",
       " 0.07947019867549669,\n",
       " 0.16831683168316833,\n",
       " 0.044534412955465584,\n",
       " 0.11504424778761062,\n",
       " 0.03903477643718949,\n",
       " 0.2391304347826087,\n",
       " 0.15202702702702703,\n",
       " 0.1890547263681592,\n",
       " 0.13882863340563992,\n",
       " 0.17880794701986755,\n",
       " 0.04878048780487805,\n",
       " 0.09742120343839542,\n",
       " 0.03532008830022075,\n",
       " 0.07425742574257425,\n",
       " 0.07449856733524356,\n",
       " 0.056838365896980464,\n",
       " 0.08280254777070063,\n",
       " 0.03932151117964534,\n",
       " 0.1945031712473573,\n",
       " 0.06229860365198711,\n",
       " 0.08353221957040573,\n",
       " 0.07523510971786834,\n",
       " 0.18796992481203006,\n",
       " 0.06351351351351352,\n",
       " 0.14285714285714285,\n",
       " 0.09662921348314607,\n",
       " 0.12324929971988796,\n",
       " 0.05623471882640587,\n",
       " 0.234375,\n",
       " 0.09444444444444444,\n",
       " 0.032407407407407406,\n",
       " 0.07636887608069164,\n",
       " 0.06053268765133172,\n",
       " 0.08009708737864078,\n",
       " 0.06,\n",
       " 0.11635220125786164,\n",
       " 0.060221870047543584,\n",
       " 0.06155632984901278,\n",
       " 0.18719211822660098,\n",
       " 0.04461942257217848,\n",
       " 0.05394190871369295,\n",
       " 0.056768558951965066,\n",
       " 0.03225806451612903,\n",
       " 0.07341269841269842,\n",
       " 0.10112359550561797,\n",
       " 0.060203283815480846,\n",
       " 0.2037037037037037,\n",
       " 0.1276595744680851,\n",
       " 0.12788632326820604,\n",
       " 0.2,\n",
       " 0.09971509971509972,\n",
       " 0.04984423676012461,\n",
       " 0.11871227364185111,\n",
       " 0.01904761904761905,\n",
       " 0.04932735426008968,\n",
       " 0.053504144687264506,\n",
       " 0.0832072617246596,\n",
       " 0.08320950965824665,\n",
       " 0.04810126582278481,\n",
       " 0.10554371002132196,\n",
       " 0.06913183279742766,\n",
       " 0.08857808857808858,\n",
       " 0.059431524547803614,\n",
       " 0.09165687426556991,\n",
       " 0.06701030927835051,\n",
       " 0.08695652173913043,\n",
       " 0.06235912847483095,\n",
       " 0.07456140350877193,\n",
       " 0.14363143631436315,\n",
       " 0.125,\n",
       " 0.04173354735152488,\n",
       " 0.06611570247933884,\n",
       " 0.06885758998435054,\n",
       " 0.15011037527593818,\n",
       " 0.09720176730486009,\n",
       " 0.07507987220447285,\n",
       " 0.0717628705148206,\n",
       " 0.16521739130434782,\n",
       " 0.037996545768566495,\n",
       " 0.06902086677367576,\n",
       " 0.04112554112554113,\n",
       " 0.0913978494623656,\n",
       " 0.08588957055214724,\n",
       " 0.05970149253731343,\n",
       " 0.13984674329501914,\n",
       " 0.10829103214890017,\n",
       " 0.05786618444846293,\n",
       " 0.04661654135338346,\n",
       " 0.09927360774818401,\n",
       " 0.16085271317829458,\n",
       " 0.1273996509598604,\n",
       " 0.08108108108108109,\n",
       " 0.04157043879907621,\n",
       " 0.06840077071290944,\n",
       " 0.07026143790849673,\n",
       " 0.0411522633744856,\n",
       " 0.164,\n",
       " 0.05119047619047619,\n",
       " 0.06608695652173913,\n",
       " 0.07699619771863118,\n",
       " 0.08085808580858085,\n",
       " 0.06997455470737914,\n",
       " 0.15955056179775282,\n",
       " 0.05714285714285714,\n",
       " 0.10047846889952153,\n",
       " 0.07373271889400922,\n",
       " 0.05414551607445008,\n",
       " 0.008733624454148471,\n",
       " 0.12394957983193278,\n",
       " 0.17329545454545456,\n",
       " 0.2087912087912088,\n",
       " 0.09565217391304348,\n",
       " 0.06958762886597938,\n",
       " 0.08367768595041322,\n",
       " 0.0691358024691358,\n",
       " 0.0763239875389408,\n",
       " 0.09655172413793103,\n",
       " 0.06625441696113074,\n",
       " 0.06693440428380187,\n",
       " 0.10655737704918032,\n",
       " 0.11219512195121951,\n",
       " 0.09037328094302555,\n",
       " 0.07575757575757576,\n",
       " 0.03664302600472813,\n",
       " 0.10256410256410256,\n",
       " 0.12464589235127478,\n",
       " 0.0979689366786141,\n",
       " 0.05172413793103448,\n",
       " 0.08235294117647059,\n",
       " 0.07782101167315175,\n",
       " 0.1488095238095238,\n",
       " 0.18202247191011237,\n",
       " 0.08676599474145487,\n",
       " 0.11483253588516747,\n",
       " 0.10223642172523961,\n",
       " 0.11604095563139932,\n",
       " 0.12738853503184713,\n",
       " 0.0519653564290473,\n",
       " 0.06904231625835189,\n",
       " 0.13846153846153847,\n",
       " 0.18591549295774648,\n",
       " 0.020308692120227456,\n",
       " 0.05737704918032787,\n",
       " 0.08393285371702638,\n",
       " 0.10299003322259136,\n",
       " 0.048355899419729204,\n",
       " 0.06459627329192547,\n",
       " 0.11424100156494522,\n",
       " 0.024193548387096774,\n",
       " 0.0975609756097561,\n",
       " 0.15333333333333332,\n",
       " 0.09608540925266904,\n",
       " 0.17092034029389017,\n",
       " 0.05166051660516605,\n",
       " 0.10471698113207548,\n",
       " 0.07809110629067245,\n",
       " 0.08520710059171598,\n",
       " 0.09193245778611632,\n",
       " 0.10311284046692606,\n",
       " 0.09090909090909091,\n",
       " 0.14883720930232558,\n",
       " 0.08088235294117647,\n",
       " 0.045507584597432905,\n",
       " 0.046052631578947366,\n",
       " 0.09009009009009009,\n",
       " 0.11670480549199085,\n",
       " 0.03005780346820809,\n",
       " 0.08553654743390357,\n",
       " 0.05997693194925029,\n",
       " 0.0670807453416149,\n",
       " 0.04106280193236715,\n",
       " 0.10588235294117647,\n",
       " 0.16037735849056603,\n",
       " 0.0759493670886076,\n",
       " 0.11869436201780416,\n",
       " 0.1223021582733813,\n",
       " 0.26666666666666666,\n",
       " 0.2898550724637681,\n",
       " 0.07357357357357357,\n",
       " 0.05303030303030303,\n",
       " 0.05490549054905491,\n",
       " 0.05207413945278023,\n",
       " 0.06724782067247821,\n",
       " 0.36153846153846153,\n",
       " 0.036180904522613064,\n",
       " 0.06134969325153374,\n",
       " 0.047619047619047616,\n",
       " 0.08560311284046693,\n",
       " 0.08156606851549755,\n",
       " 0.02901178603807797,\n",
       " 0.035961272475795295,\n",
       " 0.08086785009861933,\n",
       " 0.09921671018276762,\n",
       " 0.040369088811995385,\n",
       " 0.059149722735674676,\n",
       " 0.04540023894862605,\n",
       " 0.04688763136620857,\n",
       " 0.166270783847981,\n",
       " 0.08656330749354005,\n",
       " 0.060240963855421686,\n",
       " 0.10644257703081232,\n",
       " 0.037340619307832425,\n",
       " 0.09921671018276762,\n",
       " 0.05891238670694864,\n",
       " 0.10904255319148937,\n",
       " 0.17073170731707318,\n",
       " 0.18666666666666668,\n",
       " 0.09259259259259259,\n",
       " 0.03859174001354096,\n",
       " 0.06770833333333333,\n",
       " 0.09104367135455219,\n",
       " 0.12474849094567404,\n",
       " 0.08368794326241134,\n",
       " 0.06765327695560254,\n",
       " 0.056179775280898875,\n",
       " 0.07162921348314606,\n",
       " 0.05367231638418079,\n",
       " 0.05183585313174946,\n",
       " 0.048167539267015703,\n",
       " 0.273972602739726,\n",
       " 0.07095709570957096,\n",
       " 0.03206106870229008,\n",
       " 0.10206896551724139,\n",
       " 0.1075050709939148,\n",
       " 0.12534059945504086,\n",
       " 0.0920353982300885,\n",
       " 0.02771855010660981,\n",
       " 0.048426150121065374,\n",
       " 0.043519394512771994,\n",
       " 0.05791505791505792,\n",
       " 0.23076923076923078,\n",
       " 0.0613107822410148,\n",
       " 0.07434052757793765,\n",
       " 0.15932203389830507,\n",
       " 0.07052186177715092,\n",
       " 0.2041343669250646,\n",
       " 0.04607046070460705,\n",
       " 0.05872756933115824,\n",
       " 0.12738853503184713,\n",
       " 0.05829596412556054,\n",
       " 0.06920415224913495,\n",
       " 0.04477611940298507,\n",
       " 0.13424947145877378,\n",
       " 0.05675459632294165,\n",
       " 0.06629834254143646,\n",
       " 0.10256410256410256,\n",
       " 0.08875739644970414,\n",
       " 0.09014675052410902,\n",
       " 0.3271604938271605,\n",
       " 0.07034220532319392,\n",
       " 0.06652126499454744,\n",
       " 0.041237113402061855,\n",
       " 0.04993252361673414,\n",
       " 0.15960912052117263,\n",
       " 0.091324200913242,\n",
       " 0.11802232854864433,\n",
       " 0.09508196721311475,\n",
       " 0.10588235294117647,\n",
       " 0.052884615384615384,\n",
       " 0.05718270571827057,\n",
       " 0.05714285714285714,\n",
       " 0.055499495459132187,\n",
       " 0.1065891472868217,\n",
       " 0.0733162830349531,\n",
       " 0.07380457380457381,\n",
       " 0.11406844106463879,\n",
       " 0.33035714285714285,\n",
       " 0.14527845036319612,\n",
       " 0.16901408450704225,\n",
       " 0.24380165289256198,\n",
       " 0.10848126232741617,\n",
       " 0.05804749340369393,\n",
       " 0.08589951377633712,\n",
       " 0.07491289198606271,\n",
       " 0.12853470437017994,\n",
       " 0.0723589001447178,\n",
       " 0.2524752475247525,\n",
       " 0.1488469601677149,\n",
       " 0.09897610921501707,\n",
       " 0.07055630936227951,\n",
       " 0.20209059233449478,\n",
       " 0.10271041369472182,\n",
       " 0.10571428571428572,\n",
       " 0.03608847497089639,\n",
       " 0.11737089201877934,\n",
       " 0.11405295315682282,\n",
       " 0.09456740442655935,\n",
       " 0.09621993127147767,\n",
       " 0.3602941176470588,\n",
       " 0.1267605633802817,\n",
       " 0.0429769392033543,\n",
       " 0.07565011820330969,\n",
       " 0.038551401869158876,\n",
       " 0.08615384615384615,\n",
       " 0.07150837988826815,\n",
       " 0.08223062381852551,\n",
       " 0.14982164090368608,\n",
       " 0.029369627507163324,\n",
       " 0.033112582781456956,\n",
       " 0.10031347962382445,\n",
       " 0.1011826544021025,\n",
       " 0.07894736842105263,\n",
       " 0.055357142857142855,\n",
       " 0.06459948320413436,\n",
       " 0.06315789473684211,\n",
       " 0.02710843373493976,\n",
       " 0.1324200913242009,\n",
       " 0.11764705882352941,\n",
       " 0.12080536912751678,\n",
       " 0.03130016051364366,\n",
       " 0.03763440860215054,\n",
       " 0.04847645429362881,\n",
       " 0.07920792079207921,\n",
       " 0.05359565807327001,\n",
       " 0.10403120936280884,\n",
       " 0.05480682839173405,\n",
       " 0.09808102345415778,\n",
       " 0.07326732673267326,\n",
       " 0.03838383838383838,\n",
       " 0.2125,\n",
       " 0.05549263873159683,\n",
       " 0.0362400906002265,\n",
       " 0.1309823677581864,\n",
       " 0.15633423180592992,\n",
       " 0.039819684447783624,\n",
       " 0.09118086696562033,\n",
       " 0.10242587601078167,\n",
       " 0.019776440240756664,\n",
       " 0.08,\n",
       " 0.057757644394110984,\n",
       " 0.2265193370165746,\n",
       " 0.061389337641357025,\n",
       " 0.05756578947368421,\n",
       " 0.05492730210016155,\n",
       " 0.06306306306306306,\n",
       " 0.08139534883720931,\n",
       " 0.049738219895287955,\n",
       " 0.08648648648648649,\n",
       " 0.14380530973451328,\n",
       " 0.06914212548015365,\n",
       " 0.1388888888888889,\n",
       " 0.11083333333333334,\n",
       " 0.2,\n",
       " 0.0603448275862069,\n",
       " 0.07327586206896551,\n",
       " 0.10139860139860139,\n",
       " 0.1038374717832957,\n",
       " 0.06684491978609626,\n",
       " 0.0691358024691358,\n",
       " 0.25,\n",
       " 0.07015306122448979,\n",
       " 0.07659115426105717,\n",
       " 0.13550135501355012,\n",
       " 0.0636042402826855,\n",
       " 0.21710526315789475,\n",
       " 0.07033639143730887,\n",
       " 0.08263305322128851,\n",
       " 0.0919175911251981,\n",
       " 0.075,\n",
       " 0.038525963149078725,\n",
       " 0.12052117263843648,\n",
       " 0.11048951048951049,\n",
       " 0.05963302752293578,\n",
       " 0.10740740740740741,\n",
       " 0.11789772727272728,\n",
       " 0.060240963855421686,\n",
       " 0.0407433881343817,\n",
       " 0.041627246925260174,\n",
       " 0.15808823529411764,\n",
       " 0.11166253101736973,\n",
       " 0.06772908366533864,\n",
       " 0.08506944444444445,\n",
       " 0.07095046854082998,\n",
       " 0.04728877679697352,\n",
       " 0.17490494296577946,\n",
       " 0.08294209702660407,\n",
       " 0.08908045977011494,\n",
       " 0.16805324459234608,\n",
       " 0.0458984375,\n",
       " 0.05166846071044134,\n",
       " 0.09281437125748503,\n",
       " 0.03209876543209877,\n",
       " 0.029005524861878452,\n",
       " 0.16981132075471697,\n",
       " 0.13747228381374724,\n",
       " 0.06181015452538632,\n",
       " 0.0828125,\n",
       " 0.04259438528557599,\n",
       " 0.06320541760722348,\n",
       " 0.05023364485981308,\n",
       " 0.13043478260869565,\n",
       " 0.04129263913824058,\n",
       " 0.03210382513661202,\n",
       " 0.09502262443438914,\n",
       " 0.0817490494296578,\n",
       " 0.08041958041958042,\n",
       " 0.11497730711043873,\n",
       " 0.05150753768844221,\n",
       " 0.0880281690140845,\n",
       " 0.04938271604938271,\n",
       " 0.0787518573551263,\n",
       " 0.0691114245416079,\n",
       " 0.1892744479495268,\n",
       " 0.09115281501340483,\n",
       " 0.11182519280205655,\n",
       " 0.08177570093457943,\n",
       " 0.08284023668639054,\n",
       " 0.04160688665710186,\n",
       " 0.20276497695852536,\n",
       " 0.13267813267813267,\n",
       " 0.05907172995780591,\n",
       " 0.1188118811881188,\n",
       " 0.05218617771509168,\n",
       " 0.06437291897891231,\n",
       " 0.08298755186721991,\n",
       " 0.062169312169312166,\n",
       " 0.03648269410664172,\n",
       " 0.04399441340782123,\n",
       " 0.00946969696969697,\n",
       " 0.07003891050583658,\n",
       " 0.11948051948051948,\n",
       " 0.07916666666666666,\n",
       " 0.16417910447761194,\n",
       " 0.030303030303030304,\n",
       " 0.13984168865435356,\n",
       " 0.14482758620689656,\n",
       " 0.05089538171536286,\n",
       " 0.12290502793296089,\n",
       " 0.14512471655328799,\n",
       " 0.11716171617161716,\n",
       " 0.0641025641025641,\n",
       " 0.028045574057843997,\n",
       " 0.036585365853658534,\n",
       " 0.16441441441441443,\n",
       " 0.06732348111658457,\n",
       " 0.04564315352697095,\n",
       " 0.25316455696202533,\n",
       " 0.09577464788732394,\n",
       " 0.038293216630196934,\n",
       " 0.125,\n",
       " 0.05269320843091335,\n",
       " 0.08426966292134831,\n",
       " 0.07155963302752294,\n",
       " 0.0695266272189349,\n",
       " 0.14371980676328502,\n",
       " 0.08264462809917356,\n",
       " 0.05433186490455213,\n",
       " 0.050514499532273154,\n",
       " 0.13660245183887915,\n",
       " 0.12623762376237624,\n",
       " 0.06823821339950373,\n",
       " 0.11918604651162791,\n",
       " 0.14675767918088736,\n",
       " 0.08626198083067092,\n",
       " 0.13066666666666665,\n",
       " 0.0752212389380531,\n",
       " 0.07113821138211382,\n",
       " 0.06887755102040816,\n",
       " 0.10622710622710622,\n",
       " 0.16944444444444445,\n",
       " 0.09221902017291066,\n",
       " 0.046489563567362426,\n",
       " 0.14345991561181434,\n",
       " 0.04153354632587859,\n",
       " 0.06093189964157706,\n",
       " 0.06746987951807229,\n",
       " 0.06731946144430845,\n",
       " 0.020741671904462602,\n",
       " 0.10606060606060606,\n",
       " 0.03968253968253968,\n",
       " 0.08032128514056225,\n",
       " 0.04680365296803653,\n",
       " 0.18805309734513273,\n",
       " 0.053009883198562445,\n",
       " 0.2054794520547945,\n",
       " 0.04945904173106646,\n",
       " 0.16080402010050251,\n",
       " 0.06753246753246753,\n",
       " 0.13438735177865613,\n",
       " 0.020446096654275093,\n",
       " 0.06577480490523968,\n",
       " 0.04844290657439446,\n",
       " 0.06483516483516484,\n",
       " 0.09541984732824428,\n",
       " 0.18691588785046728,\n",
       " 0.046610169491525424,\n",
       " 0.052132701421800945,\n",
       " 0.07521367521367521,\n",
       " 0.08807588075880758,\n",
       " 0.09579439252336448,\n",
       " 0.085383502170767,\n",
       " 0.06240126382306477,\n",
       " 0.09026548672566372,\n",
       " 0.07905982905982906,\n",
       " 0.03656821378340366,\n",
       " 0.028333333333333332,\n",
       " 0.04534883720930233,\n",
       " 0.06283280085197018,\n",
       " 0.14849624060150377,\n",
       " 0.04580896686159844,\n",
       " 0.08602150537634409,\n",
       " 0.04488188976377953,\n",
       " 0.18698060941828254,\n",
       " 0.055025266704098824,\n",
       " 0.15835777126099707,\n",
       " 0.08,\n",
       " 0.18027210884353742,\n",
       " 0.04780361757105943,\n",
       " 0.14386792452830188,\n",
       " 0.061105722599418044,\n",
       " 0.15770609318996415,\n",
       " 0.1069364161849711,\n",
       " 0.11647727272727272,\n",
       " 0.09585492227979274,\n",
       " 0.11627906976744186,\n",
       " 0.062448644207066556,\n",
       " 0.0528,\n",
       " 0.15034965034965034,\n",
       " 0.07709251101321586,\n",
       " 0.061511423550087874,\n",
       " 0.03269537480063796,\n",
       " 0.18638466622604097,\n",
       " 0.225130890052356,\n",
       " 0.10285714285714286,\n",
       " 0.19705882352941176,\n",
       " 0.06477272727272727,\n",
       " 0.1301859799713877,\n",
       " 0.06,\n",
       " 0.022336769759450172,\n",
       " 0.07428040854224698,\n",
       " 0.06406685236768803,\n",
       " 0.08141592920353982,\n",
       " 0.07764390896921017,\n",
       " 0.04803073967339097,\n",
       " 0.09969788519637462,\n",
       " 0.07089947089947089,\n",
       " 0.10669456066945607,\n",
       " 0.09701492537313433,\n",
       " 0.10962566844919786,\n",
       " 0.10726072607260725,\n",
       " 0.06125574272588055,\n",
       " 0.06818181818181818,\n",
       " 0.0692167577413479,\n",
       " 0.05006418485237484,\n",
       " 0.137291280148423,\n",
       " 0.05236907730673317,\n",
       " 0.1152073732718894,\n",
       " 0.11824324324324324,\n",
       " 0.06723891273247497,\n",
       " 0.1,\n",
       " 0.04048964218455744,\n",
       " 0.028295376121463076,\n",
       " 0.05279187817258883,\n",
       " 0.07711442786069651,\n",
       " 0.11410459587955626,\n",
       " 0.07152317880794702,\n",
       " 0.05343511450381679,\n",
       " 0.04628099173553719,\n",
       " 0.1536144578313253,\n",
       " 0.04883720930232558,\n",
       " 0.11960132890365449,\n",
       " 0.14619883040935672,\n",
       " 0.1326530612244898,\n",
       " 0.05531914893617021,\n",
       " 0.08925869894099848,\n",
       " 0.1724137931034483,\n",
       " 0.0947176684881603,\n",
       " 0.06488156539649846,\n",
       " 0.17261904761904762,\n",
       " 0.0650994575045208,\n",
       " 0.03125,\n",
       " 0.040229885057471264,\n",
       " 0.08241758241758242,\n",
       " 0.060158910329171394,\n",
       " 0.04136690647482014,\n",
       " 0.1180722891566265,\n",
       " 0.10434782608695652,\n",
       " 0.06941838649155722,\n",
       " 0.18785578747628084,\n",
       " 0.06093189964157706,\n",
       " 0.15225563909774437,\n",
       " 0.09768637532133675,\n",
       " 0.02757229320780094,\n",
       " 0.045829514207149404,\n",
       " 0.070298769771529,\n",
       " 0.1414141414141414,\n",
       " 0.15593220338983052,\n",
       " 0.07360861759425494,\n",
       " 0.08806262230919765,\n",
       " 0.1032258064516129,\n",
       " 0.08142493638676845,\n",
       " 0.05476529160739687,\n",
       " 0.08296296296296296,\n",
       " 0.06363636363636363,\n",
       " 0.03896103896103896,\n",
       " 0.10158013544018059,\n",
       " 0.0821256038647343,\n",
       " 0.1366120218579235,\n",
       " 0.036677454153182305,\n",
       " 0.040983606557377046,\n",
       " 0.12637362637362637,\n",
       " 0.08595988538681948,\n",
       " 0.7333333333333333,\n",
       " 0.11706629055007052,\n",
       " 0.11437908496732026,\n",
       " 0.0652971386647102,\n",
       " 0.11666666666666667,\n",
       " 0.06283422459893048,\n",
       " 0.1411764705882353,\n",
       " 0.06862745098039216,\n",
       " 0.25210084033613445,\n",
       " 0.046680497925311204,\n",
       " 0.07644628099173553,\n",
       " 0.09335038363171355,\n",
       " 0.09573091849935317,\n",
       " 0.14685314685314685,\n",
       " 0.04878048780487805,\n",
       " 0.13488372093023257,\n",
       " 0.0631768953068592,\n",
       " 0.07330827067669173,\n",
       " 0.05889724310776942,\n",
       " 0.07702020202020202,\n",
       " 0.032825322391559206,\n",
       " 0.06504065040650407,\n",
       " 0.09868421052631579,\n",
       " 0.14950980392156862,\n",
       " 0.03524590163934426,\n",
       " 0.10764872521246459,\n",
       " 0.16129032258064516,\n",
       " 0.09359944941500344,\n",
       " 0.1724137931034483,\n",
       " 0.0959409594095941,\n",
       " 0.06864988558352403,\n",
       " 0.06402048655569782,\n",
       " 0.08076514346439957,\n",
       " 0.10432569974554708,\n",
       " 0.09950248756218906,\n",
       " 0.06351183063511831,\n",
       " 0.08130081300813008,\n",
       " 0.034050179211469536,\n",
       " 0.05710814094775213,\n",
       " 0.104,\n",
       " 0.06301824212271974,\n",
       " 0.05983545250560957,\n",
       " 0.05197505197505198,\n",
       " 0.04885057471264368,\n",
       " 0.04371584699453552,\n",
       " 0.06867469879518072,\n",
       " 0.0556792873051225,\n",
       " 0.08396946564885496,\n",
       " 0.08472803347280335,\n",
       " 0.04088586030664395,\n",
       " 0.05246422893481717,\n",
       " 0.05721716514954486,\n",
       " 0.09461663947797716,\n",
       " 0.04367201426024955,\n",
       " 0.06823027718550106,\n",
       " 0.05454545454545454,\n",
       " 0.05102040816326531,\n",
       " 0.11711711711711711,\n",
       " 0.12804878048780488,\n",
       " 0.056511056511056514,\n",
       " 0.06060606060606061,\n",
       " 0.039047619047619046,\n",
       " 0.020618556701030927,\n",
       " 0.12987012987012986,\n",
       " 0.18831168831168832,\n",
       " 0.07804232804232804,\n",
       " 0.09480122324159021,\n",
       " 0.08934707903780069,\n",
       " 0.03625730994152047,\n",
       " 0.09090909090909091,\n",
       " 0.14623655913978495,\n",
       " 0.02564102564102564,\n",
       " 0.07263922518159806,\n",
       " 0.08333333333333333,\n",
       " 0.09344490934449093,\n",
       " 0.0737527114967462,\n",
       " 0.10570469798657718,\n",
       " 0.10268562401263823,\n",
       " 0.12731481481481483,\n",
       " 0.06923950056753689,\n",
       " 0.07482993197278912,\n",
       " 0.040444091990483745,\n",
       " 0.11163895486935867,\n",
       " 0.061096136567834684,\n",
       " 0.1362126245847176,\n",
       " 0.11337868480725624,\n",
       " 0.09967845659163987,\n",
       " 0.06593406593406594,\n",
       " 0.11405835543766578,\n",
       " 0.054613935969868174,\n",
       " 0.10991957104557641,\n",
       " 0.06046511627906977,\n",
       " 0.10865561694290976,\n",
       " 0.07649253731343283,\n",
       " 0.05545286506469501,\n",
       " 0.14955640050697086,\n",
       " 0.05897887323943662,\n",
       " 0.09349593495934959,\n",
       " 0.043357933579335796,\n",
       " 0.16307692307692306,\n",
       " 0.09052631578947369,\n",
       " 0.11682242990654206,\n",
       " 0.043509789702683106,\n",
       " 0.03248811410459588,\n",
       " 0.15047021943573669,\n",
       " 0.125,\n",
       " 0.138801261829653,\n",
       " 0.06125356125356125,\n",
       " 0.15813953488372093,\n",
       " 0.10815602836879433,\n",
       " 0.1680161943319838,\n",
       " 0.02309344790547798,\n",
       " 0.13619402985074627,\n",
       " 0.03543307086614173,\n",
       " 0.05079962370649106,\n",
       " 0.05277401894451962,\n",
       " 0.1492063492063492,\n",
       " 0.06601941747572816,\n",
       " 0.04153686396677051,\n",
       " 0.08704453441295547,\n",
       " 0.0468564650059312,\n",
       " 0.061277705345501955,\n",
       " 0.07559681697612732,\n",
       " 0.08472222222222223,\n",
       " 0.10897435897435898,\n",
       " 0.12595419847328243,\n",
       " 0.09433962264150944,\n",
       " 0.020477815699658702,\n",
       " 0.17209302325581396,\n",
       " 0.07946026986506746,\n",
       " 0.04778156996587031,\n",
       " 0.12727272727272726,\n",
       " 0.08470588235294117,\n",
       " 0.05170068027210884,\n",
       " 0.034227567067530065,\n",
       " 0.1048951048951049,\n",
       " 0.03825956489122281,\n",
       " 0.06976744186046512,\n",
       " 0.04319793681495809,\n",
       " 0.16967509025270758,\n",
       " 0.09557109557109557,\n",
       " 0.04710144927536232,\n",
       " 0.14285714285714285,\n",
       " 0.06744868035190615,\n",
       " 0.06995230524642289,\n",
       " 0.08597285067873303,\n",
       " 0.09803921568627451,\n",
       " 0.028749028749028748,\n",
       " 0.09048723897911833,\n",
       " 0.043668122270742356,\n",
       " 0.07068607068607069,\n",
       " 0.05655042412818096,\n",
       " 0.060459492140266025,\n",
       " 0.06726457399103139,\n",
       " 0.09523809523809523,\n",
       " 0.2357142857142857,\n",
       " 0.04234527687296417,\n",
       " 0.15444015444015444,\n",
       " 0.26229508196721313,\n",
       " 0.19005847953216373,\n",
       " 0.15950920245398773,\n",
       " 0.0975609756097561,\n",
       " 0.03327338129496403,\n",
       " 0.037714285714285714,\n",
       " 0.1186046511627907,\n",
       " 0.1910828025477707,\n",
       " 0.08944954128440367,\n",
       " 0.24528301886792453,\n",
       " 0.16828478964401294,\n",
       " 0.052132701421800945,\n",
       " 0.07215189873417721,\n",
       " 0.12272727272727273,\n",
       " 0.060267857142857144,\n",
       " 0.01811248808388942,\n",
       " 0.041349292709466814,\n",
       " 0.1096938775510204,\n",
       " 0.09041591320072333,\n",
       " 0.07975460122699386,\n",
       " 0.08294209702660407,\n",
       " 0.02862595419847328,\n",
       " 0.07882882882882883,\n",
       " 0.21705426356589147,\n",
       " 0.0759493670886076,\n",
       " 0.18552036199095023,\n",
       " 0.04331087584215592,\n",
       " 0.05436337625178827,\n",
       " 0.11419753086419752,\n",
       " 0.06146926536731634,\n",
       " 0.1864406779661017,\n",
       " 0.13815789473684212,\n",
       " 0.01564828614008942,\n",
       " 0.04096045197740113,\n",
       " 0.04397163120567376,\n",
       " 0.0759493670886076,\n",
       " 0.02955082742316785,\n",
       " 0.09274873524451939,\n",
       " 0.11401425178147269,\n",
       " 0.10029498525073746,\n",
       " 0.12264150943396226,\n",
       " 0.10658307210031348,\n",
       " 0.10238095238095238,\n",
       " 0.03996003996003996,\n",
       " 0.19029850746268656,\n",
       " 0.17665615141955837,\n",
       " 0.058394160583941604,\n",
       " 0.03218645948945616,\n",
       " 0.14395393474088292,\n",
       " 0.12094395280235988,\n",
       " 0.03640040444893832,\n",
       " 0.035003977724741446,\n",
       " 0.13106796116504854,\n",
       " 0.0532994923857868,\n",
       " 0.03700588730025231,\n",
       " 0.06998158379373849,\n",
       " 0.06775700934579439,\n",
       " 0.08791208791208792,\n",
       " 0.08279220779220779,\n",
       " 0.07055630936227951,\n",
       " 0.14157303370786517,\n",
       " 0.1144578313253012,\n",
       " 0.04423748544819558,\n",
       " 0.09549549549549549,\n",
       " 0.054461181923522596,\n",
       " 0.10580204778156997,\n",
       " 0.07317073170731707,\n",
       " 0.14935064935064934,\n",
       " 0.15853658536585366,\n",
       " 0.19161676646706588,\n",
       " 0.11566265060240964,\n",
       " 0.020773638968481375,\n",
       " 0.1079734219269103,\n",
       " 0.06402048655569782,\n",
       " 0.03743961352657005,\n",
       " 0.056558363417569195,\n",
       " 0.12557077625570776,\n",
       " 0.0647419072615923,\n",
       " 0.10964912280701754,\n",
       " 0.03621399176954732,\n",
       " 0.1674641148325359,\n",
       " 0.016203703703703703,\n",
       " 0.14617169373549885,\n",
       " 0.08771929824561403,\n",
       " 0.07011070110701106,\n",
       " 0.027093596059113302,\n",
       " 0.10299003322259136,\n",
       " 0.06666666666666667,\n",
       " 0.053763440860215055,\n",
       " 0.0632688927943761,\n",
       " 0.08050847457627118,\n",
       " 0.08385093167701864,\n",
       " 0.05997693194925029,\n",
       " 0.04285714285714286,\n",
       " 0.01881720430107527,\n",
       " 0.16977225672877846,\n",
       " 0.011294526498696786,\n",
       " 0.053545586107091175,\n",
       " 0.12140575079872204,\n",
       " 0.021825396825396824,\n",
       " 0.16932907348242812,\n",
       " 0.07932692307692307,\n",
       " 0.07851239669421488,\n",
       " 0.07560137457044673,\n",
       " 0.039525691699604744,\n",
       " 0.2635135135135135,\n",
       " 0.05357142857142857,\n",
       " 0.44339622641509435,\n",
       " 0.07049608355091384,\n",
       " 0.06104129263913824,\n",
       " 0.07559055118110236,\n",
       " 0.14732142857142858,\n",
       " 0.07789473684210527,\n",
       " 0.09259259259259259,\n",
       " 0.08345120226308345,\n",
       " 0.1111111111111111,\n",
       " 0.07132667617689016,\n",
       " 0.04621212121212121,\n",
       " 0.057488653555219364,\n",
       " 0.11370262390670553,\n",
       " 0.06333739342265529,\n",
       " 0.07910750507099391,\n",
       " 0.07705192629815745,\n",
       " 0.07816091954022988,\n",
       " 0.12982456140350876,\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137538"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio.index(max(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sep = np.arange(len(art_len))\n",
    "\n",
    "plt.plot(ratio)\n",
    "\n",
    "plt.xlabel(\"Text Type\")\n",
    "plt.ylabel(\"Number words\")\n",
    "plt.title(\"Article length vs highlight length\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            False\n",
       "article       False\n",
       "highlights    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring, all highlight:article ratio being more than 1.0 means the summary text is producing more text than the original text, this defeats the purpose of the model, therefore all data with a ratio of more than or equal to 1.0 will be omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset modification/Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(224), \n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),   # using ImageNet norms\n",
    "                         (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model improvement/Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Finalisation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5623M_CW1_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
