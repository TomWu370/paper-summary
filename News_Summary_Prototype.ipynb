{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR4bovYL4CJz"
   },
   "source": [
    "## COMP5625M* Project - News Summary Dissertation [100 marks]\n",
    "update module code\n",
    "\n",
    "<div class=\"logos\"><img src=\"./Comp5625M_logo.jpg\" width=\"220px\" align=\"right\"></div>\n",
    "\n",
    "The maximum marks for each part are shown in the section headers. The overall assessment carries a total of 100 marks.\n",
    "\n",
    "This assessment is weighted 25% of the final grade for the module.\n",
    "\n",
    "### Motivation \n",
    "\n",
    "Through this assessment, you will:\n",
    "\n",
    "> 1. Understand the principles of text pre-processing and vocabulary building.\n",
    "> 2. Gain experience working with an image-to-text model.\n",
    "> 3. Use and compare two text similarity metrics for evaluating an image-to-text model, and understand evaluation challenges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import string\n",
    "import random\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "DATASET = \"./Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect which device (CPU/GPU) to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "> 1. Dataset preprocessing\n",
    "> 2. Dataloader\n",
    "> 3. RNN model definition\n",
    "> 4. Model training\n",
    "> 5. Model prediction evaluation\n",
    "> 6. Dataset Exploration\n",
    "> 7. Dataset modification/Data Augmentation\n",
    "> 8. Model improvement\n",
    "> 9. Model finalisation and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),   # using ImageNet norms\n",
    "                         (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class COCOImagesDataset(Dataset) function that takes the \n",
    "# image file names and reads the image and apply transform to it\n",
    "# ---> your code here! we have provided you a sketch \n",
    "\n",
    "DATA_DIR = \"SSN/papers.SSN.jsonl\"\n",
    "\n",
    "class COCOImagesDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        # df = array of all the file names\n",
    "\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        # --> your code here!\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df.iloc[index]['file_name']\n",
    "        image = Image.open(os.path.join(IMAGE_DIR, filename)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "\n",
    "        # --> your code here!\n",
    "\n",
    "\n",
    "        return image, filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Load the pretrained ResNet-50 and replace top fc layer.\"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        # Your code here!\n",
    "#         resnet = models.resnet50(pretrained=True)\n",
    "#         self.resnet = nn.Sequential(*(list(resnet.children())[:-1]))\n",
    "#         self.linear = nn.Linear(2048,256)\n",
    "        #print(resnet)\n",
    "\n",
    "        # TO COMPLETE\n",
    "        # keep all layers of the pretrained net except the last layers of fully-connected ones (you are permitted to take other layers too but this can affect your accuracy!)\n",
    "\n",
    "        \n",
    "    def forward(self, images):\n",
    "        \"\"\"Extract feature vectors from input images.\"\"\"\n",
    "\n",
    "        # TO COMPLETE\n",
    "        # remember no gradients are needed\n",
    "#         with torch.no_grad():\n",
    "#             features = self.resnet(images)\n",
    "#             features = features.reshape(features.size(0), -1)\n",
    "#             features = self.linear(features)\n",
    "#         return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = DATASET+DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>json_element</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"paper_id\": \"4650265\", \"title\": \"XGBoost: A S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"paper_id\": \"9195903\", \"title\": \"Robust Face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"paper_id\": \"119332442\", \"title\": \"Modulation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"paper_id\": \"13494452\", \"title\": \"Free evolut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"paper_id\": \"119269876\", \"title\": \"Light Dila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140794</th>\n",
       "      <td>{\"paper_id\": \"12157610\", \"title\": \"Minimal and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140795</th>\n",
       "      <td>{\"paper_id\": \"14690185\", \"title\": \"AN OBSTRUCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140796</th>\n",
       "      <td>{\"paper_id\": \"15296646\", \"title\": \"Direct Dete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140797</th>\n",
       "      <td>{\"paper_id\": \"119576690\", \"title\": \"PCA by Opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140798</th>\n",
       "      <td>{\"paper_id\": \"119301470\", \"title\": \"Turbulent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140799 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             json_element\n",
       "0       {\"paper_id\": \"4650265\", \"title\": \"XGBoost: A S...\n",
       "1       {\"paper_id\": \"9195903\", \"title\": \"Robust Face ...\n",
       "2       {\"paper_id\": \"119332442\", \"title\": \"Modulation...\n",
       "3       {\"paper_id\": \"13494452\", \"title\": \"Free evolut...\n",
       "4       {\"paper_id\": \"119269876\", \"title\": \"Light Dila...\n",
       "...                                                   ...\n",
       "140794  {\"paper_id\": \"12157610\", \"title\": \"Minimal and...\n",
       "140795  {\"paper_id\": \"14690185\", \"title\": \"AN OBSTRUCT...\n",
       "140796  {\"paper_id\": \"15296646\", \"title\": \"Direct Dete...\n",
       "140797  {\"paper_id\": \"119576690\", \"title\": \"PCA by Opt...\n",
       "140798  {\"paper_id\": \"119301470\", \"title\": \"Turbulent ...\n",
       "\n",
       "[140799 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(dataset_path) as f:\n",
    "    lines = f.read().splitlines()\n",
    "df_inter = pd.DataFrame(lines)\n",
    "df_inter.columns = ['json_element']\n",
    "df_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         {'paper_id': '4650265', 'title': 'XGBoost: A S...\n",
       "1         {'paper_id': '9195903', 'title': 'Robust Face ...\n",
       "2         {'paper_id': '119332442', 'title': 'Modulation...\n",
       "3         {'paper_id': '13494452', 'title': 'Free evolut...\n",
       "4         {'paper_id': '119269876', 'title': 'Light Dila...\n",
       "                                ...                        \n",
       "140794    {'paper_id': '12157610', 'title': 'Minimal and...\n",
       "140795    {'paper_id': '14690185', 'title': 'AN OBSTRUCT...\n",
       "140796    {'paper_id': '15296646', 'title': 'Direct Dete...\n",
       "140797    {'paper_id': '119576690', 'title': 'PCA by Opt...\n",
       "140798    {'paper_id': '119301470', 'title': 'Turbulent ...\n",
       "Name: json_element, Length: 140799, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter['json_element'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>section_names</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4650265</td>\n",
       "      <td>XGBoost: A Scalable Tree Boosting System</td>\n",
       "      <td>[tree boosting is a highly effective and widel...</td>\n",
       "      <td>[introduction, tree boosting in a nutshell, re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[machine learning and data - driven approache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9195903</td>\n",
       "      <td>Robust Face Alignment Using a Mixture of Invar...</td>\n",
       "      <td>[face alignment , which is the task of finding...</td>\n",
       "      <td>[introduction, previous work, our approach, su...</td>\n",
       "      <td>[Computer science]</td>\n",
       "      <td>[[face alignment refers to finding the pixel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119332442</td>\n",
       "      <td>Modulation instability associated nonlinear dy...</td>\n",
       "      <td>[we study pattern - forming nonlinear dynamics...</td>\n",
       "      <td>[introduction, modulation instability of becs ...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[modulation instability ( mi ) is one of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13494452</td>\n",
       "      <td>Free evolution on algebras with two states</td>\n",
       "      <td>[the key result in the paper concerns two tran...</td>\n",
       "      <td>[introduction, preliminaries, polynomials and ...</td>\n",
       "      <td>[Mathematics]</td>\n",
       "      <td>[[in a series of papers belinschi and nica int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119269876</td>\n",
       "      <td>Light Dilaton at Fixed Points and Ultra Light ...</td>\n",
       "      <td>[we investigate the infrared dynamics of a non...</td>\n",
       "      <td>[introduction, a comment on the large nn and n...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[understanding strong dynamics constitutes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140794</th>\n",
       "      <td>12157610</td>\n",
       "      <td>Minimal and Maximal Operator Spaces and Operat...</td>\n",
       "      <td>[we examine k - minimal and k - maximal operat...</td>\n",
       "      <td>[introduction, quantum information theory prel...</td>\n",
       "      <td>[Mathematics]</td>\n",
       "      <td>[[a primary goal of this paper is to formally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140795</th>\n",
       "      <td>14690185</td>\n",
       "      <td>AN OBSTRUCTION TO ASYMPTOTIC SEMISTABILITY AND...</td>\n",
       "      <td>[in this paper , we consider an obstruction to...</td>\n",
       "      <td>[introduction, statement of results, an obstru...</td>\n",
       "      <td>[Mathematics]</td>\n",
       "      <td>[[for a polarized algebraic manifold inlinefor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140796</th>\n",
       "      <td>15296646</td>\n",
       "      <td>Direct Detection of Neutralino Dark Matter and...</td>\n",
       "      <td>[we compare predictions for the spin - indepen...</td>\n",
       "      <td>[introduction, msugra, more general models, co...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[the minimal supersymmetric standard model ( ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140797</th>\n",
       "      <td>119576690</td>\n",
       "      <td>PCA by Optimisation of Symmetric Functions has...</td>\n",
       "      <td>[principal component analysis ( pca ) finds th...</td>\n",
       "      <td>[introduction, pca by determinant optimisation...</td>\n",
       "      <td>[Mathematics]</td>\n",
       "      <td>[[let inlineform0 be a data matrix , with rows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140798</th>\n",
       "      <td>119301470</td>\n",
       "      <td>Turbulent fluxes of entropy and internal energ...</td>\n",
       "      <td>[we derive equations for the mean entropy and,...</td>\n",
       "      <td>[introduction, turbulent convective flux of me...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[temperature stratified turbulence ( e.g. , t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140799 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_id                                              title  \\\n",
       "0         4650265           XGBoost: A Scalable Tree Boosting System   \n",
       "1         9195903  Robust Face Alignment Using a Mixture of Invar...   \n",
       "2       119332442  Modulation instability associated nonlinear dy...   \n",
       "3        13494452         Free evolution on algebras with two states   \n",
       "4       119269876  Light Dilaton at Fixed Points and Ultra Light ...   \n",
       "...           ...                                                ...   \n",
       "140794   12157610  Minimal and Maximal Operator Spaces and Operat...   \n",
       "140795   14690185  AN OBSTRUCTION TO ASYMPTOTIC SEMISTABILITY AND...   \n",
       "140796   15296646  Direct Detection of Neutralino Dark Matter and...   \n",
       "140797  119576690  PCA by Optimisation of Symmetric Functions has...   \n",
       "140798  119301470  Turbulent fluxes of entropy and internal energ...   \n",
       "\n",
       "                                                 abstract  \\\n",
       "0       [tree boosting is a highly effective and widel...   \n",
       "1       [face alignment , which is the task of finding...   \n",
       "2       [we study pattern - forming nonlinear dynamics...   \n",
       "3       [the key result in the paper concerns two tran...   \n",
       "4       [we investigate the infrared dynamics of a non...   \n",
       "...                                                   ...   \n",
       "140794  [we examine k - minimal and k - maximal operat...   \n",
       "140795  [in this paper , we consider an obstruction to...   \n",
       "140796  [we compare predictions for the spin - indepen...   \n",
       "140797  [principal component analysis ( pca ) finds th...   \n",
       "140798  [we derive equations for the mean entropy and,...   \n",
       "\n",
       "                                            section_names              domain  \\\n",
       "0       [introduction, tree boosting in a nutshell, re...                  []   \n",
       "1       [introduction, previous work, our approach, su...  [Computer science]   \n",
       "2       [introduction, modulation instability of becs ...           [Physics]   \n",
       "3       [introduction, preliminaries, polynomials and ...       [Mathematics]   \n",
       "4       [introduction, a comment on the large nn and n...           [Physics]   \n",
       "...                                                   ...                 ...   \n",
       "140794  [introduction, quantum information theory prel...       [Mathematics]   \n",
       "140795  [introduction, statement of results, an obstru...       [Mathematics]   \n",
       "140796  [introduction, msugra, more general models, co...           [Physics]   \n",
       "140797  [introduction, pca by determinant optimisation...       [Mathematics]   \n",
       "140798  [introduction, turbulent convective flux of me...           [Physics]   \n",
       "\n",
       "                                                     text  \n",
       "0       [[machine learning and data - driven approache...  \n",
       "1       [[face alignment refers to finding the pixel l...  \n",
       "2       [[modulation instability ( mi ) is one of the ...  \n",
       "3       [[in a series of papers belinschi and nica int...  \n",
       "4       [[understanding strong dynamics constitutes a ...  \n",
       "...                                                   ...  \n",
       "140794  [[a primary goal of this paper is to formally ...  \n",
       "140795  [[for a polarized algebraic manifold inlinefor...  \n",
       "140796  [[the minimal supersymmetric standard model ( ...  \n",
       "140797  [[let inlineform0 be a data matrix , with rows...  \n",
       "140798  [[temperature stratified turbulence ( e.g. , t...  \n",
       "\n",
       "[140799 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"./Dataset/SSN/Reorganised_Dataset.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATASET+DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
       "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
       "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
       "      <td>A drunk driver who killed a young woman in a h...</td>\n",
       "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
       "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
       "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
       "      <td>Fleetwood are the only team still to have a 10...</td>\n",
       "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287108</th>\n",
       "      <td>fffdfb56fdf1a12d364562cc2b9b1d4de7481dee</td>\n",
       "      <td>By . James Rush . Former first daughter Chelse...</td>\n",
       "      <td>Chelsea Clinton said question of running for o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287109</th>\n",
       "      <td>fffeecb8690b85de8c3faed80adbc7a978f9ae2a</td>\n",
       "      <td>An apologetic Vanilla Ice has given his first ...</td>\n",
       "      <td>Vanilla Ice, 47 - real name Robert Van Winkle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287110</th>\n",
       "      <td>ffff5231e4c71544bc6c97015cdb16c60e42b3f4</td>\n",
       "      <td>America's most lethal sniper claimed he wished...</td>\n",
       "      <td>America's most lethal sniper made comment in i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287111</th>\n",
       "      <td>ffff924b14a8d82058b6c1c5368ff1113c1632af</td>\n",
       "      <td>By . Sara Malm . PUBLISHED: . 12:19 EST, 8 Mar...</td>\n",
       "      <td>A swarm of more than one million has crossed b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287112</th>\n",
       "      <td>ffffd563a96104f5cf4493cfa701a65f31b06abf</td>\n",
       "      <td>(CNN)Former Florida Gov. Jeb Bush has decided ...</td>\n",
       "      <td>Other 2016 hopefuls maintain that Bush's annou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  \\\n",
       "0       0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
       "1       0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
       "2       00027e965c8264c35cc1bc55556db388da82b07f   \n",
       "3       0002c17436637c4fe1837c935c04de47adb18e9a   \n",
       "4       0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
       "...                                          ...   \n",
       "287108  fffdfb56fdf1a12d364562cc2b9b1d4de7481dee   \n",
       "287109  fffeecb8690b85de8c3faed80adbc7a978f9ae2a   \n",
       "287110  ffff5231e4c71544bc6c97015cdb16c60e42b3f4   \n",
       "287111  ffff924b14a8d82058b6c1c5368ff1113c1632af   \n",
       "287112  ffffd563a96104f5cf4493cfa701a65f31b06abf   \n",
       "\n",
       "                                                  article  \\\n",
       "0       By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
       "1       (CNN) -- Ralph Mata was an internal affairs li...   \n",
       "2       A drunk driver who killed a young woman in a h...   \n",
       "3       (CNN) -- With a breezy sweep of his pen Presid...   \n",
       "4       Fleetwood are the only team still to have a 10...   \n",
       "...                                                   ...   \n",
       "287108  By . James Rush . Former first daughter Chelse...   \n",
       "287109  An apologetic Vanilla Ice has given his first ...   \n",
       "287110  America's most lethal sniper claimed he wished...   \n",
       "287111  By . Sara Malm . PUBLISHED: . 12:19 EST, 8 Mar...   \n",
       "287112  (CNN)Former Florida Gov. Jeb Bush has decided ...   \n",
       "\n",
       "                                               highlights  \n",
       "0       Bishop John Folda, of North Dakota, is taking ...  \n",
       "1       Criminal complaint: Cop used his role to help ...  \n",
       "2       Craig Eccleston-Todd, 27, had drunk at least t...  \n",
       "3       Nina dos Santos says Europe must be ready to a...  \n",
       "4       Fleetwood top of League One after 2-0 win at S...  \n",
       "...                                                   ...  \n",
       "287108  Chelsea Clinton said question of running for o...  \n",
       "287109  Vanilla Ice, 47 - real name Robert Van Winkle ...  \n",
       "287110  America's most lethal sniper made comment in i...  \n",
       "287111  A swarm of more than one million has crossed b...  \n",
       "287112  Other 2016 hopefuls maintain that Bush's annou...  \n",
       "\n",
       "[287113 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_lengths(df):\n",
    "    ratio = []\n",
    "    for i,row in df.iterrows():\n",
    "        article = len(row[\"article\"].split())\n",
    "        highlight = len(row[\"highlights\"].split())\n",
    "        if (i==137538):\n",
    "            print(row[\"article\"])\n",
    "            print(\"---------------------\")\n",
    "            print(row[\"highlights\"])\n",
    "        ratio.append(highlight/article)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downton Abbey's famously grim butler, Mr Bates .\n",
      "---------------------\n",
      "And now for the good news . . . Following a particularly grim week, here’s a compendium of some of the world’s most comforting headlines: .\n",
      "Supermodel Smiles On Catwalk .\n",
      "Jack Russell Dog Welcomes Stranger .\n",
      "Child At Funfair ‘Delighted’ By Goldfish .\n",
      "Katie Price Breasts ‘Roughly Same Size As Last Week’ Say Experts .\n",
      "Teenager Looks Up From Phone, Greets Parent .\n",
      "Political Pundits Agree To Stop Discussing Hung Parliament For Next Three Months .\n",
      "Diner Finishes His Curly Kale .\n",
      "Pensioner Looks Great In Party Hat .\n",
      "Celebrity Fails To Compare Life To Roller-coaster .\n",
      "Pet Hamster Repays Child’s Affection .\n",
      "‘Cheer Up, It May Never Happen’ — Downton’s Mr Bates Enjoys Belly-laugh .\n",
      "Style Journalist Fails To Employ The Word ‘Iconic’\n",
      "Sally Bercow Goes Out On Town, Retains Dignity .\n",
      "Entire Windfarm Operates According To Plan .\n",
      "Miley Cyrus Feels A Bit Chilly, Opts For Extra Layer .\n"
     ]
    }
   ],
   "source": [
    "ratio = get_df_lengths(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18686868686868688,\n",
       " 0.09693877551020408,\n",
       " 0.0853960396039604,\n",
       " 0.09981167608286252,\n",
       " 0.11551724137931034,\n",
       " 0.12574850299401197,\n",
       " 0.03099730458221024,\n",
       " 0.08695652173913043,\n",
       " 0.09688013136288999,\n",
       " 0.06306306306306306,\n",
       " 0.09338235294117647,\n",
       " 0.09428129829984544,\n",
       " 0.04805914972273567,\n",
       " 0.14903846153846154,\n",
       " 0.05941845764854614,\n",
       " 0.12058212058212059,\n",
       " 0.03619909502262444,\n",
       " 0.05114029025570145,\n",
       " 0.14392059553349876,\n",
       " 0.09248554913294797,\n",
       " 0.11290322580645161,\n",
       " 0.06223175965665236,\n",
       " 0.025252525252525252,\n",
       " 0.0670807453416149,\n",
       " 0.07357357357357357,\n",
       " 0.059931506849315065,\n",
       " 0.0497335701598579,\n",
       " 0.04749512036434613,\n",
       " 0.22916666666666666,\n",
       " 0.12189616252821671,\n",
       " 0.10119840213049268,\n",
       " 0.04323094425483504,\n",
       " 0.09049773755656108,\n",
       " 0.022063208109719738,\n",
       " 0.10561797752808989,\n",
       " 0.16293929712460065,\n",
       " 0.058163265306122446,\n",
       " 0.11014492753623188,\n",
       " 0.04020979020979021,\n",
       " 0.13213213213213212,\n",
       " 0.1079734219269103,\n",
       " 0.05200945626477541,\n",
       " 0.07241379310344828,\n",
       " 0.07616707616707617,\n",
       " 0.09510869565217392,\n",
       " 0.11284722222222222,\n",
       " 0.13166144200626959,\n",
       " 0.08482142857142858,\n",
       " 0.07086614173228346,\n",
       " 0.03248099516240498,\n",
       " 0.1076555023923445,\n",
       " 0.08943089430894309,\n",
       " 0.07090103397341212,\n",
       " 0.07272727272727272,\n",
       " 0.03939393939393939,\n",
       " 0.06487341772151899,\n",
       " 0.0389321468298109,\n",
       " 0.076163610719323,\n",
       " 0.055842812823164424,\n",
       " 0.13648293963254593,\n",
       " 0.040634291377601585,\n",
       " 0.07153284671532846,\n",
       " 0.20555555555555555,\n",
       " 0.09803921568627451,\n",
       " 0.024691358024691357,\n",
       " 0.05551149881046788,\n",
       " 0.07025411061285501,\n",
       " 0.08278145695364239,\n",
       " 0.052083333333333336,\n",
       " 0.13564668769716087,\n",
       " 0.07599118942731277,\n",
       " 0.10480349344978165,\n",
       " 0.116600790513834,\n",
       " 0.05077262693156733,\n",
       " 0.056676272814601344,\n",
       " 0.07973421926910298,\n",
       " 0.10470588235294118,\n",
       " 0.08161512027491409,\n",
       " 0.02046204620462046,\n",
       " 0.050808314087759814,\n",
       " 0.14105793450881612,\n",
       " 0.04881656804733728,\n",
       " 0.13653136531365315,\n",
       " 0.12142038946162657,\n",
       " 0.07822085889570553,\n",
       " 0.06643356643356643,\n",
       " 0.10251450676982592,\n",
       " 0.046255506607929514,\n",
       " 0.015037593984962405,\n",
       " 0.05555555555555555,\n",
       " 0.04645161290322581,\n",
       " 0.18543046357615894,\n",
       " 0.13921901528013583,\n",
       " 0.11219512195121951,\n",
       " 0.09090909090909091,\n",
       " 0.03052805280528053,\n",
       " 0.15471698113207547,\n",
       " 0.19631901840490798,\n",
       " 0.14532019704433496,\n",
       " 0.03944315545243619,\n",
       " 0.1456953642384106,\n",
       " 0.0974264705882353,\n",
       " 0.037383177570093455,\n",
       " 0.08912655971479501,\n",
       " 0.09859154929577464,\n",
       " 0.14320388349514562,\n",
       " 0.03433835845896147,\n",
       " 0.04825090470446321,\n",
       " 0.07600950118764846,\n",
       " 0.04100946372239748,\n",
       " 0.16829268292682928,\n",
       " 0.05714285714285714,\n",
       " 0.09340659340659341,\n",
       " 0.08695652173913043,\n",
       " 0.10645724258289703,\n",
       " 0.07947019867549669,\n",
       " 0.16831683168316833,\n",
       " 0.044534412955465584,\n",
       " 0.11504424778761062,\n",
       " 0.03903477643718949,\n",
       " 0.2391304347826087,\n",
       " 0.15202702702702703,\n",
       " 0.1890547263681592,\n",
       " 0.13882863340563992,\n",
       " 0.17880794701986755,\n",
       " 0.04878048780487805,\n",
       " 0.09742120343839542,\n",
       " 0.03532008830022075,\n",
       " 0.07425742574257425,\n",
       " 0.07449856733524356,\n",
       " 0.056838365896980464,\n",
       " 0.08280254777070063,\n",
       " 0.03932151117964534,\n",
       " 0.1945031712473573,\n",
       " 0.06229860365198711,\n",
       " 0.08353221957040573,\n",
       " 0.07523510971786834,\n",
       " 0.18796992481203006,\n",
       " 0.06351351351351352,\n",
       " 0.14285714285714285,\n",
       " 0.09662921348314607,\n",
       " 0.12324929971988796,\n",
       " 0.05623471882640587,\n",
       " 0.234375,\n",
       " 0.09444444444444444,\n",
       " 0.032407407407407406,\n",
       " 0.07636887608069164,\n",
       " 0.06053268765133172,\n",
       " 0.08009708737864078,\n",
       " 0.06,\n",
       " 0.11635220125786164,\n",
       " 0.060221870047543584,\n",
       " 0.06155632984901278,\n",
       " 0.18719211822660098,\n",
       " 0.04461942257217848,\n",
       " 0.05394190871369295,\n",
       " 0.056768558951965066,\n",
       " 0.03225806451612903,\n",
       " 0.07341269841269842,\n",
       " 0.10112359550561797,\n",
       " 0.060203283815480846,\n",
       " 0.2037037037037037,\n",
       " 0.1276595744680851,\n",
       " 0.12788632326820604,\n",
       " 0.2,\n",
       " 0.09971509971509972,\n",
       " 0.04984423676012461,\n",
       " 0.11871227364185111,\n",
       " 0.01904761904761905,\n",
       " 0.04932735426008968,\n",
       " 0.053504144687264506,\n",
       " 0.0832072617246596,\n",
       " 0.08320950965824665,\n",
       " 0.04810126582278481,\n",
       " 0.10554371002132196,\n",
       " 0.06913183279742766,\n",
       " 0.08857808857808858,\n",
       " 0.059431524547803614,\n",
       " 0.09165687426556991,\n",
       " 0.06701030927835051,\n",
       " 0.08695652173913043,\n",
       " 0.06235912847483095,\n",
       " 0.07456140350877193,\n",
       " 0.14363143631436315,\n",
       " 0.125,\n",
       " 0.04173354735152488,\n",
       " 0.06611570247933884,\n",
       " 0.06885758998435054,\n",
       " 0.15011037527593818,\n",
       " 0.09720176730486009,\n",
       " 0.07507987220447285,\n",
       " 0.0717628705148206,\n",
       " 0.16521739130434782,\n",
       " 0.037996545768566495,\n",
       " 0.06902086677367576,\n",
       " 0.04112554112554113,\n",
       " 0.0913978494623656,\n",
       " 0.08588957055214724,\n",
       " 0.05970149253731343,\n",
       " 0.13984674329501914,\n",
       " 0.10829103214890017,\n",
       " 0.05786618444846293,\n",
       " 0.04661654135338346,\n",
       " 0.09927360774818401,\n",
       " 0.16085271317829458,\n",
       " 0.1273996509598604,\n",
       " 0.08108108108108109,\n",
       " 0.04157043879907621,\n",
       " 0.06840077071290944,\n",
       " 0.07026143790849673,\n",
       " 0.0411522633744856,\n",
       " 0.164,\n",
       " 0.05119047619047619,\n",
       " 0.06608695652173913,\n",
       " 0.07699619771863118,\n",
       " 0.08085808580858085,\n",
       " 0.06997455470737914,\n",
       " 0.15955056179775282,\n",
       " 0.05714285714285714,\n",
       " 0.10047846889952153,\n",
       " 0.07373271889400922,\n",
       " 0.05414551607445008,\n",
       " 0.008733624454148471,\n",
       " 0.12394957983193278,\n",
       " 0.17329545454545456,\n",
       " 0.2087912087912088,\n",
       " 0.09565217391304348,\n",
       " 0.06958762886597938,\n",
       " 0.08367768595041322,\n",
       " 0.0691358024691358,\n",
       " 0.0763239875389408,\n",
       " 0.09655172413793103,\n",
       " 0.06625441696113074,\n",
       " 0.06693440428380187,\n",
       " 0.10655737704918032,\n",
       " 0.11219512195121951,\n",
       " 0.09037328094302555,\n",
       " 0.07575757575757576,\n",
       " 0.03664302600472813,\n",
       " 0.10256410256410256,\n",
       " 0.12464589235127478,\n",
       " 0.0979689366786141,\n",
       " 0.05172413793103448,\n",
       " 0.08235294117647059,\n",
       " 0.07782101167315175,\n",
       " 0.1488095238095238,\n",
       " 0.18202247191011237,\n",
       " 0.08676599474145487,\n",
       " 0.11483253588516747,\n",
       " 0.10223642172523961,\n",
       " 0.11604095563139932,\n",
       " 0.12738853503184713,\n",
       " 0.0519653564290473,\n",
       " 0.06904231625835189,\n",
       " 0.13846153846153847,\n",
       " 0.18591549295774648,\n",
       " 0.020308692120227456,\n",
       " 0.05737704918032787,\n",
       " 0.08393285371702638,\n",
       " 0.10299003322259136,\n",
       " 0.048355899419729204,\n",
       " 0.06459627329192547,\n",
       " 0.11424100156494522,\n",
       " 0.024193548387096774,\n",
       " 0.0975609756097561,\n",
       " 0.15333333333333332,\n",
       " 0.09608540925266904,\n",
       " 0.17092034029389017,\n",
       " 0.05166051660516605,\n",
       " 0.10471698113207548,\n",
       " 0.07809110629067245,\n",
       " 0.08520710059171598,\n",
       " 0.09193245778611632,\n",
       " 0.10311284046692606,\n",
       " 0.09090909090909091,\n",
       " 0.14883720930232558,\n",
       " 0.08088235294117647,\n",
       " 0.045507584597432905,\n",
       " 0.046052631578947366,\n",
       " 0.09009009009009009,\n",
       " 0.11670480549199085,\n",
       " 0.03005780346820809,\n",
       " 0.08553654743390357,\n",
       " 0.05997693194925029,\n",
       " 0.0670807453416149,\n",
       " 0.04106280193236715,\n",
       " 0.10588235294117647,\n",
       " 0.16037735849056603,\n",
       " 0.0759493670886076,\n",
       " 0.11869436201780416,\n",
       " 0.1223021582733813,\n",
       " 0.26666666666666666,\n",
       " 0.2898550724637681,\n",
       " 0.07357357357357357,\n",
       " 0.05303030303030303,\n",
       " 0.05490549054905491,\n",
       " 0.05207413945278023,\n",
       " 0.06724782067247821,\n",
       " 0.36153846153846153,\n",
       " 0.036180904522613064,\n",
       " 0.06134969325153374,\n",
       " 0.047619047619047616,\n",
       " 0.08560311284046693,\n",
       " 0.08156606851549755,\n",
       " 0.02901178603807797,\n",
       " 0.035961272475795295,\n",
       " 0.08086785009861933,\n",
       " 0.09921671018276762,\n",
       " 0.040369088811995385,\n",
       " 0.059149722735674676,\n",
       " 0.04540023894862605,\n",
       " 0.04688763136620857,\n",
       " 0.166270783847981,\n",
       " 0.08656330749354005,\n",
       " 0.060240963855421686,\n",
       " 0.10644257703081232,\n",
       " 0.037340619307832425,\n",
       " 0.09921671018276762,\n",
       " 0.05891238670694864,\n",
       " 0.10904255319148937,\n",
       " 0.17073170731707318,\n",
       " 0.18666666666666668,\n",
       " 0.09259259259259259,\n",
       " 0.03859174001354096,\n",
       " 0.06770833333333333,\n",
       " 0.09104367135455219,\n",
       " 0.12474849094567404,\n",
       " 0.08368794326241134,\n",
       " 0.06765327695560254,\n",
       " 0.056179775280898875,\n",
       " 0.07162921348314606,\n",
       " 0.05367231638418079,\n",
       " 0.05183585313174946,\n",
       " 0.048167539267015703,\n",
       " 0.273972602739726,\n",
       " 0.07095709570957096,\n",
       " 0.03206106870229008,\n",
       " 0.10206896551724139,\n",
       " 0.1075050709939148,\n",
       " 0.12534059945504086,\n",
       " 0.0920353982300885,\n",
       " 0.02771855010660981,\n",
       " 0.048426150121065374,\n",
       " 0.043519394512771994,\n",
       " 0.05791505791505792,\n",
       " 0.23076923076923078,\n",
       " 0.0613107822410148,\n",
       " 0.07434052757793765,\n",
       " 0.15932203389830507,\n",
       " 0.07052186177715092,\n",
       " 0.2041343669250646,\n",
       " 0.04607046070460705,\n",
       " 0.05872756933115824,\n",
       " 0.12738853503184713,\n",
       " 0.05829596412556054,\n",
       " 0.06920415224913495,\n",
       " 0.04477611940298507,\n",
       " 0.13424947145877378,\n",
       " 0.05675459632294165,\n",
       " 0.06629834254143646,\n",
       " 0.10256410256410256,\n",
       " 0.08875739644970414,\n",
       " 0.09014675052410902,\n",
       " 0.3271604938271605,\n",
       " 0.07034220532319392,\n",
       " 0.06652126499454744,\n",
       " 0.041237113402061855,\n",
       " 0.04993252361673414,\n",
       " 0.15960912052117263,\n",
       " 0.091324200913242,\n",
       " 0.11802232854864433,\n",
       " 0.09508196721311475,\n",
       " 0.10588235294117647,\n",
       " 0.052884615384615384,\n",
       " 0.05718270571827057,\n",
       " 0.05714285714285714,\n",
       " 0.055499495459132187,\n",
       " 0.1065891472868217,\n",
       " 0.0733162830349531,\n",
       " 0.07380457380457381,\n",
       " 0.11406844106463879,\n",
       " 0.33035714285714285,\n",
       " 0.14527845036319612,\n",
       " 0.16901408450704225,\n",
       " 0.24380165289256198,\n",
       " 0.10848126232741617,\n",
       " 0.05804749340369393,\n",
       " 0.08589951377633712,\n",
       " 0.07491289198606271,\n",
       " 0.12853470437017994,\n",
       " 0.0723589001447178,\n",
       " 0.2524752475247525,\n",
       " 0.1488469601677149,\n",
       " 0.09897610921501707,\n",
       " 0.07055630936227951,\n",
       " 0.20209059233449478,\n",
       " 0.10271041369472182,\n",
       " 0.10571428571428572,\n",
       " 0.03608847497089639,\n",
       " 0.11737089201877934,\n",
       " 0.11405295315682282,\n",
       " 0.09456740442655935,\n",
       " 0.09621993127147767,\n",
       " 0.3602941176470588,\n",
       " 0.1267605633802817,\n",
       " 0.0429769392033543,\n",
       " 0.07565011820330969,\n",
       " 0.038551401869158876,\n",
       " 0.08615384615384615,\n",
       " 0.07150837988826815,\n",
       " 0.08223062381852551,\n",
       " 0.14982164090368608,\n",
       " 0.029369627507163324,\n",
       " 0.033112582781456956,\n",
       " 0.10031347962382445,\n",
       " 0.1011826544021025,\n",
       " 0.07894736842105263,\n",
       " 0.055357142857142855,\n",
       " 0.06459948320413436,\n",
       " 0.06315789473684211,\n",
       " 0.02710843373493976,\n",
       " 0.1324200913242009,\n",
       " 0.11764705882352941,\n",
       " 0.12080536912751678,\n",
       " 0.03130016051364366,\n",
       " 0.03763440860215054,\n",
       " 0.04847645429362881,\n",
       " 0.07920792079207921,\n",
       " 0.05359565807327001,\n",
       " 0.10403120936280884,\n",
       " 0.05480682839173405,\n",
       " 0.09808102345415778,\n",
       " 0.07326732673267326,\n",
       " 0.03838383838383838,\n",
       " 0.2125,\n",
       " 0.05549263873159683,\n",
       " 0.0362400906002265,\n",
       " 0.1309823677581864,\n",
       " 0.15633423180592992,\n",
       " 0.039819684447783624,\n",
       " 0.09118086696562033,\n",
       " 0.10242587601078167,\n",
       " 0.019776440240756664,\n",
       " 0.08,\n",
       " 0.057757644394110984,\n",
       " 0.2265193370165746,\n",
       " 0.061389337641357025,\n",
       " 0.05756578947368421,\n",
       " 0.05492730210016155,\n",
       " 0.06306306306306306,\n",
       " 0.08139534883720931,\n",
       " 0.049738219895287955,\n",
       " 0.08648648648648649,\n",
       " 0.14380530973451328,\n",
       " 0.06914212548015365,\n",
       " 0.1388888888888889,\n",
       " 0.11083333333333334,\n",
       " 0.2,\n",
       " 0.0603448275862069,\n",
       " 0.07327586206896551,\n",
       " 0.10139860139860139,\n",
       " 0.1038374717832957,\n",
       " 0.06684491978609626,\n",
       " 0.0691358024691358,\n",
       " 0.25,\n",
       " 0.07015306122448979,\n",
       " 0.07659115426105717,\n",
       " 0.13550135501355012,\n",
       " 0.0636042402826855,\n",
       " 0.21710526315789475,\n",
       " 0.07033639143730887,\n",
       " 0.08263305322128851,\n",
       " 0.0919175911251981,\n",
       " 0.075,\n",
       " 0.038525963149078725,\n",
       " 0.12052117263843648,\n",
       " 0.11048951048951049,\n",
       " 0.05963302752293578,\n",
       " 0.10740740740740741,\n",
       " 0.11789772727272728,\n",
       " 0.060240963855421686,\n",
       " 0.0407433881343817,\n",
       " 0.041627246925260174,\n",
       " 0.15808823529411764,\n",
       " 0.11166253101736973,\n",
       " 0.06772908366533864,\n",
       " 0.08506944444444445,\n",
       " 0.07095046854082998,\n",
       " 0.04728877679697352,\n",
       " 0.17490494296577946,\n",
       " 0.08294209702660407,\n",
       " 0.08908045977011494,\n",
       " 0.16805324459234608,\n",
       " 0.0458984375,\n",
       " 0.05166846071044134,\n",
       " 0.09281437125748503,\n",
       " 0.03209876543209877,\n",
       " 0.029005524861878452,\n",
       " 0.16981132075471697,\n",
       " 0.13747228381374724,\n",
       " 0.06181015452538632,\n",
       " 0.0828125,\n",
       " 0.04259438528557599,\n",
       " 0.06320541760722348,\n",
       " 0.05023364485981308,\n",
       " 0.13043478260869565,\n",
       " 0.04129263913824058,\n",
       " 0.03210382513661202,\n",
       " 0.09502262443438914,\n",
       " 0.0817490494296578,\n",
       " 0.08041958041958042,\n",
       " 0.11497730711043873,\n",
       " 0.05150753768844221,\n",
       " 0.0880281690140845,\n",
       " 0.04938271604938271,\n",
       " 0.0787518573551263,\n",
       " 0.0691114245416079,\n",
       " 0.1892744479495268,\n",
       " 0.09115281501340483,\n",
       " 0.11182519280205655,\n",
       " 0.08177570093457943,\n",
       " 0.08284023668639054,\n",
       " 0.04160688665710186,\n",
       " 0.20276497695852536,\n",
       " 0.13267813267813267,\n",
       " 0.05907172995780591,\n",
       " 0.1188118811881188,\n",
       " 0.05218617771509168,\n",
       " 0.06437291897891231,\n",
       " 0.08298755186721991,\n",
       " 0.062169312169312166,\n",
       " 0.03648269410664172,\n",
       " 0.04399441340782123,\n",
       " 0.00946969696969697,\n",
       " 0.07003891050583658,\n",
       " 0.11948051948051948,\n",
       " 0.07916666666666666,\n",
       " 0.16417910447761194,\n",
       " 0.030303030303030304,\n",
       " 0.13984168865435356,\n",
       " 0.14482758620689656,\n",
       " 0.05089538171536286,\n",
       " 0.12290502793296089,\n",
       " 0.14512471655328799,\n",
       " 0.11716171617161716,\n",
       " 0.0641025641025641,\n",
       " 0.028045574057843997,\n",
       " 0.036585365853658534,\n",
       " 0.16441441441441443,\n",
       " 0.06732348111658457,\n",
       " 0.04564315352697095,\n",
       " 0.25316455696202533,\n",
       " 0.09577464788732394,\n",
       " 0.038293216630196934,\n",
       " 0.125,\n",
       " 0.05269320843091335,\n",
       " 0.08426966292134831,\n",
       " 0.07155963302752294,\n",
       " 0.0695266272189349,\n",
       " 0.14371980676328502,\n",
       " 0.08264462809917356,\n",
       " 0.05433186490455213,\n",
       " 0.050514499532273154,\n",
       " 0.13660245183887915,\n",
       " 0.12623762376237624,\n",
       " 0.06823821339950373,\n",
       " 0.11918604651162791,\n",
       " 0.14675767918088736,\n",
       " 0.08626198083067092,\n",
       " 0.13066666666666665,\n",
       " 0.0752212389380531,\n",
       " 0.07113821138211382,\n",
       " 0.06887755102040816,\n",
       " 0.10622710622710622,\n",
       " 0.16944444444444445,\n",
       " 0.09221902017291066,\n",
       " 0.046489563567362426,\n",
       " 0.14345991561181434,\n",
       " 0.04153354632587859,\n",
       " 0.06093189964157706,\n",
       " 0.06746987951807229,\n",
       " 0.06731946144430845,\n",
       " 0.020741671904462602,\n",
       " 0.10606060606060606,\n",
       " 0.03968253968253968,\n",
       " 0.08032128514056225,\n",
       " 0.04680365296803653,\n",
       " 0.18805309734513273,\n",
       " 0.053009883198562445,\n",
       " 0.2054794520547945,\n",
       " 0.04945904173106646,\n",
       " 0.16080402010050251,\n",
       " 0.06753246753246753,\n",
       " 0.13438735177865613,\n",
       " 0.020446096654275093,\n",
       " 0.06577480490523968,\n",
       " 0.04844290657439446,\n",
       " 0.06483516483516484,\n",
       " 0.09541984732824428,\n",
       " 0.18691588785046728,\n",
       " 0.046610169491525424,\n",
       " 0.052132701421800945,\n",
       " 0.07521367521367521,\n",
       " 0.08807588075880758,\n",
       " 0.09579439252336448,\n",
       " 0.085383502170767,\n",
       " 0.06240126382306477,\n",
       " 0.09026548672566372,\n",
       " 0.07905982905982906,\n",
       " 0.03656821378340366,\n",
       " 0.028333333333333332,\n",
       " 0.04534883720930233,\n",
       " 0.06283280085197018,\n",
       " 0.14849624060150377,\n",
       " 0.04580896686159844,\n",
       " 0.08602150537634409,\n",
       " 0.04488188976377953,\n",
       " 0.18698060941828254,\n",
       " 0.055025266704098824,\n",
       " 0.15835777126099707,\n",
       " 0.08,\n",
       " 0.18027210884353742,\n",
       " 0.04780361757105943,\n",
       " 0.14386792452830188,\n",
       " 0.061105722599418044,\n",
       " 0.15770609318996415,\n",
       " 0.1069364161849711,\n",
       " 0.11647727272727272,\n",
       " 0.09585492227979274,\n",
       " 0.11627906976744186,\n",
       " 0.062448644207066556,\n",
       " 0.0528,\n",
       " 0.15034965034965034,\n",
       " 0.07709251101321586,\n",
       " 0.061511423550087874,\n",
       " 0.03269537480063796,\n",
       " 0.18638466622604097,\n",
       " 0.225130890052356,\n",
       " 0.10285714285714286,\n",
       " 0.19705882352941176,\n",
       " 0.06477272727272727,\n",
       " 0.1301859799713877,\n",
       " 0.06,\n",
       " 0.022336769759450172,\n",
       " 0.07428040854224698,\n",
       " 0.06406685236768803,\n",
       " 0.08141592920353982,\n",
       " 0.07764390896921017,\n",
       " 0.04803073967339097,\n",
       " 0.09969788519637462,\n",
       " 0.07089947089947089,\n",
       " 0.10669456066945607,\n",
       " 0.09701492537313433,\n",
       " 0.10962566844919786,\n",
       " 0.10726072607260725,\n",
       " 0.06125574272588055,\n",
       " 0.06818181818181818,\n",
       " 0.0692167577413479,\n",
       " 0.05006418485237484,\n",
       " 0.137291280148423,\n",
       " 0.05236907730673317,\n",
       " 0.1152073732718894,\n",
       " 0.11824324324324324,\n",
       " 0.06723891273247497,\n",
       " 0.1,\n",
       " 0.04048964218455744,\n",
       " 0.028295376121463076,\n",
       " 0.05279187817258883,\n",
       " 0.07711442786069651,\n",
       " 0.11410459587955626,\n",
       " 0.07152317880794702,\n",
       " 0.05343511450381679,\n",
       " 0.04628099173553719,\n",
       " 0.1536144578313253,\n",
       " 0.04883720930232558,\n",
       " 0.11960132890365449,\n",
       " 0.14619883040935672,\n",
       " 0.1326530612244898,\n",
       " 0.05531914893617021,\n",
       " 0.08925869894099848,\n",
       " 0.1724137931034483,\n",
       " 0.0947176684881603,\n",
       " 0.06488156539649846,\n",
       " 0.17261904761904762,\n",
       " 0.0650994575045208,\n",
       " 0.03125,\n",
       " 0.040229885057471264,\n",
       " 0.08241758241758242,\n",
       " 0.060158910329171394,\n",
       " 0.04136690647482014,\n",
       " 0.1180722891566265,\n",
       " 0.10434782608695652,\n",
       " 0.06941838649155722,\n",
       " 0.18785578747628084,\n",
       " 0.06093189964157706,\n",
       " 0.15225563909774437,\n",
       " 0.09768637532133675,\n",
       " 0.02757229320780094,\n",
       " 0.045829514207149404,\n",
       " 0.070298769771529,\n",
       " 0.1414141414141414,\n",
       " 0.15593220338983052,\n",
       " 0.07360861759425494,\n",
       " 0.08806262230919765,\n",
       " 0.1032258064516129,\n",
       " 0.08142493638676845,\n",
       " 0.05476529160739687,\n",
       " 0.08296296296296296,\n",
       " 0.06363636363636363,\n",
       " 0.03896103896103896,\n",
       " 0.10158013544018059,\n",
       " 0.0821256038647343,\n",
       " 0.1366120218579235,\n",
       " 0.036677454153182305,\n",
       " 0.040983606557377046,\n",
       " 0.12637362637362637,\n",
       " 0.08595988538681948,\n",
       " 0.7333333333333333,\n",
       " 0.11706629055007052,\n",
       " 0.11437908496732026,\n",
       " 0.0652971386647102,\n",
       " 0.11666666666666667,\n",
       " 0.06283422459893048,\n",
       " 0.1411764705882353,\n",
       " 0.06862745098039216,\n",
       " 0.25210084033613445,\n",
       " 0.046680497925311204,\n",
       " 0.07644628099173553,\n",
       " 0.09335038363171355,\n",
       " 0.09573091849935317,\n",
       " 0.14685314685314685,\n",
       " 0.04878048780487805,\n",
       " 0.13488372093023257,\n",
       " 0.0631768953068592,\n",
       " 0.07330827067669173,\n",
       " 0.05889724310776942,\n",
       " 0.07702020202020202,\n",
       " 0.032825322391559206,\n",
       " 0.06504065040650407,\n",
       " 0.09868421052631579,\n",
       " 0.14950980392156862,\n",
       " 0.03524590163934426,\n",
       " 0.10764872521246459,\n",
       " 0.16129032258064516,\n",
       " 0.09359944941500344,\n",
       " 0.1724137931034483,\n",
       " 0.0959409594095941,\n",
       " 0.06864988558352403,\n",
       " 0.06402048655569782,\n",
       " 0.08076514346439957,\n",
       " 0.10432569974554708,\n",
       " 0.09950248756218906,\n",
       " 0.06351183063511831,\n",
       " 0.08130081300813008,\n",
       " 0.034050179211469536,\n",
       " 0.05710814094775213,\n",
       " 0.104,\n",
       " 0.06301824212271974,\n",
       " 0.05983545250560957,\n",
       " 0.05197505197505198,\n",
       " 0.04885057471264368,\n",
       " 0.04371584699453552,\n",
       " 0.06867469879518072,\n",
       " 0.0556792873051225,\n",
       " 0.08396946564885496,\n",
       " 0.08472803347280335,\n",
       " 0.04088586030664395,\n",
       " 0.05246422893481717,\n",
       " 0.05721716514954486,\n",
       " 0.09461663947797716,\n",
       " 0.04367201426024955,\n",
       " 0.06823027718550106,\n",
       " 0.05454545454545454,\n",
       " 0.05102040816326531,\n",
       " 0.11711711711711711,\n",
       " 0.12804878048780488,\n",
       " 0.056511056511056514,\n",
       " 0.06060606060606061,\n",
       " 0.039047619047619046,\n",
       " 0.020618556701030927,\n",
       " 0.12987012987012986,\n",
       " 0.18831168831168832,\n",
       " 0.07804232804232804,\n",
       " 0.09480122324159021,\n",
       " 0.08934707903780069,\n",
       " 0.03625730994152047,\n",
       " 0.09090909090909091,\n",
       " 0.14623655913978495,\n",
       " 0.02564102564102564,\n",
       " 0.07263922518159806,\n",
       " 0.08333333333333333,\n",
       " 0.09344490934449093,\n",
       " 0.0737527114967462,\n",
       " 0.10570469798657718,\n",
       " 0.10268562401263823,\n",
       " 0.12731481481481483,\n",
       " 0.06923950056753689,\n",
       " 0.07482993197278912,\n",
       " 0.040444091990483745,\n",
       " 0.11163895486935867,\n",
       " 0.061096136567834684,\n",
       " 0.1362126245847176,\n",
       " 0.11337868480725624,\n",
       " 0.09967845659163987,\n",
       " 0.06593406593406594,\n",
       " 0.11405835543766578,\n",
       " 0.054613935969868174,\n",
       " 0.10991957104557641,\n",
       " 0.06046511627906977,\n",
       " 0.10865561694290976,\n",
       " 0.07649253731343283,\n",
       " 0.05545286506469501,\n",
       " 0.14955640050697086,\n",
       " 0.05897887323943662,\n",
       " 0.09349593495934959,\n",
       " 0.043357933579335796,\n",
       " 0.16307692307692306,\n",
       " 0.09052631578947369,\n",
       " 0.11682242990654206,\n",
       " 0.043509789702683106,\n",
       " 0.03248811410459588,\n",
       " 0.15047021943573669,\n",
       " 0.125,\n",
       " 0.138801261829653,\n",
       " 0.06125356125356125,\n",
       " 0.15813953488372093,\n",
       " 0.10815602836879433,\n",
       " 0.1680161943319838,\n",
       " 0.02309344790547798,\n",
       " 0.13619402985074627,\n",
       " 0.03543307086614173,\n",
       " 0.05079962370649106,\n",
       " 0.05277401894451962,\n",
       " 0.1492063492063492,\n",
       " 0.06601941747572816,\n",
       " 0.04153686396677051,\n",
       " 0.08704453441295547,\n",
       " 0.0468564650059312,\n",
       " 0.061277705345501955,\n",
       " 0.07559681697612732,\n",
       " 0.08472222222222223,\n",
       " 0.10897435897435898,\n",
       " 0.12595419847328243,\n",
       " 0.09433962264150944,\n",
       " 0.020477815699658702,\n",
       " 0.17209302325581396,\n",
       " 0.07946026986506746,\n",
       " 0.04778156996587031,\n",
       " 0.12727272727272726,\n",
       " 0.08470588235294117,\n",
       " 0.05170068027210884,\n",
       " 0.034227567067530065,\n",
       " 0.1048951048951049,\n",
       " 0.03825956489122281,\n",
       " 0.06976744186046512,\n",
       " 0.04319793681495809,\n",
       " 0.16967509025270758,\n",
       " 0.09557109557109557,\n",
       " 0.04710144927536232,\n",
       " 0.14285714285714285,\n",
       " 0.06744868035190615,\n",
       " 0.06995230524642289,\n",
       " 0.08597285067873303,\n",
       " 0.09803921568627451,\n",
       " 0.028749028749028748,\n",
       " 0.09048723897911833,\n",
       " 0.043668122270742356,\n",
       " 0.07068607068607069,\n",
       " 0.05655042412818096,\n",
       " 0.060459492140266025,\n",
       " 0.06726457399103139,\n",
       " 0.09523809523809523,\n",
       " 0.2357142857142857,\n",
       " 0.04234527687296417,\n",
       " 0.15444015444015444,\n",
       " 0.26229508196721313,\n",
       " 0.19005847953216373,\n",
       " 0.15950920245398773,\n",
       " 0.0975609756097561,\n",
       " 0.03327338129496403,\n",
       " 0.037714285714285714,\n",
       " 0.1186046511627907,\n",
       " 0.1910828025477707,\n",
       " 0.08944954128440367,\n",
       " 0.24528301886792453,\n",
       " 0.16828478964401294,\n",
       " 0.052132701421800945,\n",
       " 0.07215189873417721,\n",
       " 0.12272727272727273,\n",
       " 0.060267857142857144,\n",
       " 0.01811248808388942,\n",
       " 0.041349292709466814,\n",
       " 0.1096938775510204,\n",
       " 0.09041591320072333,\n",
       " 0.07975460122699386,\n",
       " 0.08294209702660407,\n",
       " 0.02862595419847328,\n",
       " 0.07882882882882883,\n",
       " 0.21705426356589147,\n",
       " 0.0759493670886076,\n",
       " 0.18552036199095023,\n",
       " 0.04331087584215592,\n",
       " 0.05436337625178827,\n",
       " 0.11419753086419752,\n",
       " 0.06146926536731634,\n",
       " 0.1864406779661017,\n",
       " 0.13815789473684212,\n",
       " 0.01564828614008942,\n",
       " 0.04096045197740113,\n",
       " 0.04397163120567376,\n",
       " 0.0759493670886076,\n",
       " 0.02955082742316785,\n",
       " 0.09274873524451939,\n",
       " 0.11401425178147269,\n",
       " 0.10029498525073746,\n",
       " 0.12264150943396226,\n",
       " 0.10658307210031348,\n",
       " 0.10238095238095238,\n",
       " 0.03996003996003996,\n",
       " 0.19029850746268656,\n",
       " 0.17665615141955837,\n",
       " 0.058394160583941604,\n",
       " 0.03218645948945616,\n",
       " 0.14395393474088292,\n",
       " 0.12094395280235988,\n",
       " 0.03640040444893832,\n",
       " 0.035003977724741446,\n",
       " 0.13106796116504854,\n",
       " 0.0532994923857868,\n",
       " 0.03700588730025231,\n",
       " 0.06998158379373849,\n",
       " 0.06775700934579439,\n",
       " 0.08791208791208792,\n",
       " 0.08279220779220779,\n",
       " 0.07055630936227951,\n",
       " 0.14157303370786517,\n",
       " 0.1144578313253012,\n",
       " 0.04423748544819558,\n",
       " 0.09549549549549549,\n",
       " 0.054461181923522596,\n",
       " 0.10580204778156997,\n",
       " 0.07317073170731707,\n",
       " 0.14935064935064934,\n",
       " 0.15853658536585366,\n",
       " 0.19161676646706588,\n",
       " 0.11566265060240964,\n",
       " 0.020773638968481375,\n",
       " 0.1079734219269103,\n",
       " 0.06402048655569782,\n",
       " 0.03743961352657005,\n",
       " 0.056558363417569195,\n",
       " 0.12557077625570776,\n",
       " 0.0647419072615923,\n",
       " 0.10964912280701754,\n",
       " 0.03621399176954732,\n",
       " 0.1674641148325359,\n",
       " 0.016203703703703703,\n",
       " 0.14617169373549885,\n",
       " 0.08771929824561403,\n",
       " 0.07011070110701106,\n",
       " 0.027093596059113302,\n",
       " 0.10299003322259136,\n",
       " 0.06666666666666667,\n",
       " 0.053763440860215055,\n",
       " 0.0632688927943761,\n",
       " 0.08050847457627118,\n",
       " 0.08385093167701864,\n",
       " 0.05997693194925029,\n",
       " 0.04285714285714286,\n",
       " 0.01881720430107527,\n",
       " 0.16977225672877846,\n",
       " 0.011294526498696786,\n",
       " 0.053545586107091175,\n",
       " 0.12140575079872204,\n",
       " 0.021825396825396824,\n",
       " 0.16932907348242812,\n",
       " 0.07932692307692307,\n",
       " 0.07851239669421488,\n",
       " 0.07560137457044673,\n",
       " 0.039525691699604744,\n",
       " 0.2635135135135135,\n",
       " 0.05357142857142857,\n",
       " 0.44339622641509435,\n",
       " 0.07049608355091384,\n",
       " 0.06104129263913824,\n",
       " 0.07559055118110236,\n",
       " 0.14732142857142858,\n",
       " 0.07789473684210527,\n",
       " 0.09259259259259259,\n",
       " 0.08345120226308345,\n",
       " 0.1111111111111111,\n",
       " 0.07132667617689016,\n",
       " 0.04621212121212121,\n",
       " 0.057488653555219364,\n",
       " 0.11370262390670553,\n",
       " 0.06333739342265529,\n",
       " 0.07910750507099391,\n",
       " 0.07705192629815745,\n",
       " 0.07816091954022988,\n",
       " 0.12982456140350876,\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137538"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio.index(max(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sep = np.arange(len(art_len))\n",
    "\n",
    "plt.plot(ratio)\n",
    "\n",
    "plt.xlabel(\"Text Type\")\n",
    "plt.ylabel(\"Number words\")\n",
    "plt.title(\"Article length vs highlight length\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            False\n",
       "article       False\n",
       "highlights    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring, all highlight:article ratio being more than 1.0 means the summary text is producing more text than the original text, this defeats the purpose of the model, therefore all data with a ratio of more than or equal to 1.0 will be omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset modification/Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(224), \n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),   # using ImageNet norms\n",
    "                         (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model improvement/Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Finalisation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5623M_CW1_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
