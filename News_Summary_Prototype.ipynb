{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR4bovYL4CJz"
   },
   "source": [
    "## Dissertation Project - News Summary Dissertation [100 marks]\n",
    "\n",
    "### Motivation \n",
    "\n",
    "> 1. Provide tools for anyone needing to speed up their research process\n",
    "> 2. Providing ways for user to quickly determine whether a piece of research is beneficial for their specific search terms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "\n",
    "# HTML('''<script>\n",
    "# code_show=true; \n",
    "# function code_toggle() {\n",
    "#  if (code_show){\n",
    "#  $('div.input').hide();\n",
    "#  } else {\n",
    "#  $('div.input').show();\n",
    "#  }\n",
    "#  code_show = !code_show\n",
    "# } \n",
    "# $( document ).ready(code_toggle);\n",
    "# </script>\n",
    "# <form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import string\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "import fitz\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import _pickle as pickle\n",
    "\n",
    "import transformers\n",
    "\n",
    "DATASET = \"./Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect which device (CPU/GPU) to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Summarisation model\n",
    "> 1. Dataset preprocessing\n",
    "> 2. Dataloader\n",
    "> 3. RNN model definition\n",
    "> 4. Model training\n",
    "> 5. Model prediction evaluation\n",
    "> 6. Dataset Exploration\n",
    "> 7. Dataset modification/Data Augmentation\n",
    "> 8. Model improvement\n",
    "> 9. Model finalisation and evaluation\n",
    "\n",
    "Paper querying\n",
    "> 1. Attention on query (Return usefulness percentage\n",
    "> 2. Evaluate performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comment this block if dataset is reorganised\n",
    "# DATA_DIR = \"SSN/papers.SSN.jsonl\"\n",
    "# dataset_path = DATASET+DATA_DIR\n",
    "# with open(dataset_path) as f:\n",
    "#     lines = f.read().splitlines()\n",
    "# df_inter = pd.DataFrame(lines)\n",
    "# df_inter.columns = ['json_element']\n",
    "# df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "# df_final.to_json(\"./Dataset/SSN/SSN_Dataset.json\")\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,summary in df_final.iterrows():\n",
    "#     temp = summary[\"abstract\"]\n",
    "#     print(type(summary[\"abstract\"]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Comment this block if dataset is shortened\n",
    "# DATA_DIR = \"SSN/SSN_Dataset.json\"\n",
    "# dataset_path = DATASET+DATA_DIR\n",
    "# df = pd.read_json(dataset_path)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[140794][\"section_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return index for conclusion section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trim_index(row):\n",
    "#     return [row.index(x)+1 for x in row if x.startswith('conclusion') or x.startswith(\"summar\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trim_text(text, index):\n",
    "#     return text[0:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comment this block if dataset is shortened\n",
    "# # Trim text after conclusion\n",
    "# indexes = []\n",
    "# for i, row in df.iterrows():\n",
    "#     section = row[\"section_names\"]\n",
    "#     #print(section)\n",
    "#     index = trim_index(section)\n",
    "#     #print(index)\n",
    "#     if not index:\n",
    "#         indexes.append(i)\n",
    "#     # if section can be filtered\n",
    "#     else:\n",
    "#         index = index[0]\n",
    "#         abstract = row[\"abstract\"]\n",
    "#         text = row[\"text\"]\n",
    "#         section = row[\"section_names\"]\n",
    "#         df.at[i, \"section_names\"] = trim_text(section, index)\n",
    "#         df.at[i, \"abstract\"] = trim_text(abstract, index)\n",
    "#         df.at[i, \"text\"] = trim_text(text, index)\n",
    "# # dropping rows in dataframe that can't easily filter out reference section\n",
    "# print(len(indexes))\n",
    "# df.drop(indexes, inplace=True)\n",
    "# df.to_json(\"./Dataset/SSN/SSN_Dataset_Short.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35% of paper will be removed from the dataset due to it not having conclusion(s) and summary(ies) in their section titles, making it difficult to filter out the reference and appendix text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = \"SSN/SSN_Dataset_Short.json\"\n",
    "# dataset_path = DATASET+DATA_DIR\n",
    "# df = pd.read_json(dataset_path)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See diversity in papers, select only computer science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_points = df['domain'].value_counts()\n",
    "# plot_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[df['domain'].isin([['Computer science']])]\n",
    "# df.to_json(\"./Dataset/SSN/SSN_Dataset_CompSci_Short.json\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"cnn_dailymail/train.csv\"\n",
    "# dataset_path = DATASET+DATA_DIR\n",
    "# df = pd.read_csv(dataset_path)\n",
    "# df = df.rename(columns={'article': 'text', 'highlights': 'abstract'})\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"SSN/SSN_Dataset_CompSci_Short.json\"\n",
    "# dataset_path = DATASET+DATA_DIR\n",
    "# df = pd.read_json(dataset_path)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df = df[[\"abstract\", \"text\"]]\n",
    "# summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any columns contain empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\'hi\\' \\ is used for space <br>\n",
    "random space, which is used for reference [15] quote box <br>\n",
    "sec ref is hyperlink to a section <br>\n",
    "fig ref is hyperlink to a figure <br>\n",
    "inlineform <br>\n",
    "displayform are both symbols, both contains numbers in string <br>\n",
    "remove all forms and remove all symbols but keep numbers <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contain_let(string):\n",
    "#     return any(char.isalpha() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contain_num(string):\n",
    "#     return any(char.isdigit() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contain_special(string, allowed):\n",
    "#     '''\n",
    "#     allowed is a list containing allowed symbols to pass detection\n",
    "#     '''\n",
    "#     return any(not(char.isalpha() or char.isdigit()) and (char not in allowed) for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleanLine(line, text=True, aug=False):\n",
    "#     \"text parameter is to indicate whether the line is from text or abstract\"\n",
    "#     symbols = [\"'\", \"â€™\"]\n",
    "#     stop_words = list(ENGLISH_STOP_WORDS)\n",
    "    \n",
    "#     clean_line = line.lower()\n",
    "\n",
    "#     # fix apostrophes in line by removing apostrophe with no following alphabet character\n",
    "#     clean_line = clean_line.replace(\"'\", \" \")\n",
    "#     clean_line = clean_line.replace(\",\", \" \")\n",
    "# #     # remove apostrophe if last character is apostrophe\n",
    "# #     if clean_line and (clean_line[-1] == \"'\"):\n",
    "# #         clean_line = clean_line[0:len(clean_line)-1]\n",
    "# #     # fix apostrophes in line by removing space before single quote\n",
    "# #     clean_line = clean_line.replace(\" '\", \"'\")\n",
    "\n",
    "\n",
    "#     # clean line = clean line remove forms\n",
    "#     words = clean_line.split()\n",
    "#     #  remove forms, words with special characters inside\n",
    "#     # if contain letter and number\n",
    "#     # if contain special character not in allowed symbols and removing punctuations\n",
    "#     # then remove\n",
    "#     words = [x.replace(x, \"\") if (contain_let(x) and contain_num(x))\n",
    "#              or contain_special(x, symbols)\n",
    "#              else x for x in words]\n",
    "\n",
    "#     # remove empty strings\n",
    "#     words = filter(None, words)\n",
    "\n",
    "#     # stop words from sklearn, remove stop words\n",
    "#     if text:\n",
    "#         words = [x for x in words if not x in stop_words]\n",
    "#     # remove from line randomly\n",
    "#     if text and aug:\n",
    "#         choices = random.choices(words, k=math.floor(len(line)*0.2))\n",
    "#         words.remove(choices)\n",
    "        \n",
    "#      # combine the items into 1 string\n",
    "#     clean_line = ' '.join(words)\n",
    "\n",
    "    \n",
    "\n",
    "#     return clean_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def concatParagraph(paragraph, text=True):\n",
    "#     clean_paragraph = \"\"\n",
    "#     for line in paragraph:\n",
    "#         lines = cleanLine(line)\n",
    "#         clean_paragraph += cleanLine(lines, text) + \" \"\n",
    "#         #print(clean_paragraph)\n",
    "        \n",
    "#     return(clean_paragraph.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def concatPaper(paper, text=True):\n",
    "#     clean_paper = \"\"\n",
    "#     for paragraph in paper:\n",
    "#         clean_paper += concatParagraph(paragraph, text) + \" \"\n",
    "#     return(clean_paper.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# interval = 0.0001\n",
    "# aug_chance = 0.5\n",
    "# for i, row in tqdm(summary_df.iterrows(), total=summary_df.shape[0]):\n",
    "#     abstract = row[\"abstract\"]\n",
    "#     paper = row[\"text\"]\n",
    "    \n",
    "# #     summary_df.at[i, \"abstract\"] = concatParagraph(abstract, text=False)\n",
    "# #     summary_df.at[i, \"text\"] = concatPaper(paper)\n",
    "#     if random.random() > aug_chance:\n",
    "#         row_val = cleanLine(paper, text=True, aug=True)\n",
    "#         new_row = pd.Series([abstract, row_val], index=summary_df.columns)\n",
    "#         df_summary = df_summary.append(row1,ignore_index=True) \n",
    "#         df_summary\n",
    "#     summary_df.at[i, \"abstract\"] = cleanLine(abstract, text=True)\n",
    "#     summary_df.at[i, \"text\"] = cleanLine(paper)\n",
    "#     time.sleep(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df.to_csv(\"./Dataset/cnn_dailymail/cleaned_cnn_train.csv\")\n",
    "# summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_text</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tracking developments highly dynamic data tech...</td>\n",
       "      <td>summarize: ubiquity online resources massive g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extracting multi scale information key semanti...</td>\n",
       "      <td>summarize: medical image segmentation challeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scarcity richly annotated medical images limit...</td>\n",
       "      <td>summarize: deaths attributed pneumonia reporte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper introduce novel concept densely connecte...</td>\n",
       "      <td>summarize: language modeling key task natural ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known determined adversary fool neural network...</td>\n",
       "      <td>summarize: recent years neural networks shown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>open domain dialogue intelligent agents exhibi...</td>\n",
       "      <td>summarize: arguably key goals ai ultimate goal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>ubiquitous diffusion social networks images do...</td>\n",
       "      <td>summarize: era social networks images dominant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>paper introduces modification phase transform ...</td>\n",
       "      <td>summarize: cocktail party effect consists abil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4052</th>\n",
       "      <td>present neural encoder decoder model convert i...</td>\n",
       "      <td>summarize: optical character recognition ocr c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>propose novel deep supervised neural network t...</td>\n",
       "      <td>summarize: action recognition description vide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4054 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            target_text  \\\n",
       "0     tracking developments highly dynamic data tech...   \n",
       "1     extracting multi scale information key semanti...   \n",
       "2     scarcity richly annotated medical images limit...   \n",
       "3     paper introduce novel concept densely connecte...   \n",
       "4     known determined adversary fool neural network...   \n",
       "...                                                 ...   \n",
       "4049  open domain dialogue intelligent agents exhibi...   \n",
       "4050  ubiquitous diffusion social networks images do...   \n",
       "4051  paper introduces modification phase transform ...   \n",
       "4052  present neural encoder decoder model convert i...   \n",
       "4053  propose novel deep supervised neural network t...   \n",
       "\n",
       "                                            source_text  \n",
       "0     summarize: ubiquity online resources massive g...  \n",
       "1     summarize: medical image segmentation challeng...  \n",
       "2     summarize: deaths attributed pneumonia reporte...  \n",
       "3     summarize: language modeling key task natural ...  \n",
       "4     summarize: recent years neural networks shown ...  \n",
       "...                                                 ...  \n",
       "4049  summarize: arguably key goals ai ultimate goal...  \n",
       "4050  summarize: era social networks images dominant...  \n",
       "4051  summarize: cocktail party effect consists abil...  \n",
       "4052  summarize: optical character recognition ocr c...  \n",
       "4053  summarize: action recognition description vide...  \n",
       "\n",
       "[4054 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"SSN\\SSN_Dataset_CompSci_Short_Clean_HalfStop_170_Filter.json\"\n",
    "dataset_path = DATASET+DATA_DIR\n",
    "df = pd.read_json(dataset_path)\n",
    "#df = df[[\"source_text\", \"target_text\"]]\n",
    "# df = df.rename(columns={'text': 'source_text', 'abstract': 'target_text'})\n",
    "# df['source_text'] = \"summarize: \" + df['source_text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3aa068d8f9c4d92b97882ae86aaf579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4054 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_max:  2100\n",
      "a_max:  193\n"
     ]
    }
   ],
   "source": [
    "# t_max = 0\n",
    "# a_max = 0\n",
    "# for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "#     t_len = len(tokeniser(row['source_text'])['input_ids'])\n",
    "#     a_len = len(tokeniser(row['target_text'])['input_ids'])\n",
    "#     if t_len > t_max:\n",
    "#         t_max = t_len\n",
    "#     if a_len > a_max:\n",
    "#         a_max = a_len\n",
    "# print(\"t_max: \",t_max)\n",
    "# print(\"a_max: \", a_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6096"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_text</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tracking developments highly dynamic data tech...</td>\n",
       "      <td>summarize: ubiquity online resources massive g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extracting multi scale information key semanti...</td>\n",
       "      <td>summarize: medical image segmentation challeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scarcity richly annotated medical images limit...</td>\n",
       "      <td>summarize: deaths attributed pneumonia reporte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper introduce novel concept densely connecte...</td>\n",
       "      <td>summarize: language modeling key task natural ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known determined adversary fool neural network...</td>\n",
       "      <td>summarize: recent years neural networks shown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>open domain dialogue intelligent agents exhibi...</td>\n",
       "      <td>summarize: arguably key goals ai ultimate goal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>ubiquitous diffusion social networks images do...</td>\n",
       "      <td>summarize: era social networks images dominant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>paper introduces modification phase transform ...</td>\n",
       "      <td>summarize: cocktail party effect consists abil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4052</th>\n",
       "      <td>present neural encoder decoder model convert i...</td>\n",
       "      <td>summarize: optical character recognition ocr c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>propose novel deep supervised neural network t...</td>\n",
       "      <td>summarize: action recognition description vide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4054 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            target_text  \\\n",
       "0     tracking developments highly dynamic data tech...   \n",
       "1     extracting multi scale information key semanti...   \n",
       "2     scarcity richly annotated medical images limit...   \n",
       "3     paper introduce novel concept densely connecte...   \n",
       "4     known determined adversary fool neural network...   \n",
       "...                                                 ...   \n",
       "4049  open domain dialogue intelligent agents exhibi...   \n",
       "4050  ubiquitous diffusion social networks images do...   \n",
       "4051  paper introduces modification phase transform ...   \n",
       "4052  present neural encoder decoder model convert i...   \n",
       "4053  propose novel deep supervised neural network t...   \n",
       "\n",
       "                                            source_text  \n",
       "0     summarize: ubiquity online resources massive g...  \n",
       "1     summarize: medical image segmentation challeng...  \n",
       "2     summarize: deaths attributed pneumonia reporte...  \n",
       "3     summarize: language modeling key task natural ...  \n",
       "4     summarize: recent years neural networks shown ...  \n",
       "...                                                 ...  \n",
       "4049  summarize: arguably key goals ai ultimate goal...  \n",
       "4050  summarize: era social networks images dominant...  \n",
       "4051  summarize: cocktail party effect consists abil...  \n",
       "4052  summarize: optical character recognition ocr c...  \n",
       "4053  summarize: action recognition description vide...  \n",
       "\n",
       "[4054 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(indexes, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.to_json(DATASET+\"SSN\\SSN_Dataset_CompSci_Short_Clean_HalfStop_170_Filter.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABSTRACT_MAX = 170\n",
    "# TEXT_MAX = 3050\n",
    "ABSTRACT_MAX = 200\n",
    "TEXT_MAX = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,BertTokenizer\n",
    "tokeniser = AutoTokenizer.from_pretrained('t5-small') \n",
    "# takes into account of apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=3186, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train tokeniser\n",
    "corpus = []\n",
    "for i, row in df.iterrows():\n",
    "    corpus.append([row[\"text\"]])\n",
    "tokeniser.train_new_from_iterator(corpus, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = []\n",
    "# t_max= 2524\n",
    "# a_max=  118\n",
    "# t_min=  668\n",
    "# a_min=  39\n",
    "# for i, row in df.iterrows():\n",
    "#     t_word = len(row[\"text\"].split())\n",
    "#     a_word = len(row[\"abstract\"].split())\n",
    "#     if ((t_word > t_max or t_word < t_min) or (a_word > a_max or a_word < a_min)):\n",
    "#         rows.append(i)\n",
    "\n",
    "# df.drop(rows, inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# df.to_json(DATASET+\"SSN/SSN_Dataset_CompSci_Short_Clean_HalfStop_180.json\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Vocabulary(object):\n",
    "#     \"\"\" Simple vocabulary wrapper which maps every unique word to an integer ID. \"\"\"\n",
    "#     def __init__(self):\n",
    "#         # intially, set both the IDs and words to dictionaries with special tokens\n",
    "#         self.word2idx = {'<pad>': 0,'<start>': 1, '<end>': 2, '<unk>': 3}\n",
    "#         self.idx2word = {0: '<pad>',1: '<start>', 2: '<end>', 3: '<unk>'}\n",
    "#         self.idx = 4\n",
    "\n",
    "#     def add_word(self, word):\n",
    "#         # if the word does not already exist in the dictionary, add it\n",
    "#         if not word in self.word2idx:\n",
    "#             # this will convert each word to index and index to word as you saw in the tutorials\n",
    "#             self.word2idx[word] = self.idx\n",
    "#             self.idx2word[self.idx] = word\n",
    "#             # increment the ID for the next word\n",
    "#             self.idx += 1\n",
    "\n",
    "#     def __call__(self, word):\n",
    "#         # if we try to access a word not in the dictionary, return the id for <unk>\n",
    "#         if not word in self.word2idx:\n",
    "#             return self.word2idx['<unk>']\n",
    "#         return self.word2idx[word]\n",
    "    \n",
    "#     ## added function for utility\n",
    "#     def get_word(self,index):\n",
    "#         # this returns the word when given an index\n",
    "#         return self.idx2word[index]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_vocab(data, freq):\n",
    "#     \"\"\" \n",
    "#     Parses training set token file captions and builds a Vocabulary object and dataframe for \n",
    "#     the image and caption data\n",
    "\n",
    "#     Returns:\n",
    "#         vocab (Vocabulary): Vocabulary object containing all words appearing more than min_frequency\n",
    "#     \"\"\"\n",
    "#     MIN_FREQUENCY = freq\n",
    "#     word_mapping = Counter()\n",
    "\n",
    "#     # for index in df.index:\n",
    "#     for text in tqdm(data):\n",
    "#         for word in text.split():\n",
    "#             #print(word)\n",
    "#             if word in word_mapping:\n",
    "#                 word_mapping[word] += 1\n",
    "#             else:\n",
    "#                 word_mapping[word] = 1\n",
    "\n",
    "#     # create a vocab instance\n",
    "#     vocab = Vocabulary()\n",
    "\n",
    "#     # add the words to the vocabulary\n",
    "#     for word in word_mapping:\n",
    "#         if word_mapping[word] > MIN_FREQUENCY:\n",
    "#             vocab.add_word(word)\n",
    "\n",
    "#     return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert DF to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_txt = df['text']\n",
    "# text_txt.to_csv(\"text_cnn.txt\", header=False,index=False)\n",
    "# abstract_txt = df['abstract']\n",
    "# abstract_txt.to_csv(\"abstract_cnn.txt\", header=False,index=False)\n",
    "\n",
    "# # write to file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_model = fasttext.train_unsupervised('text_NoStop.txt', minn=2, epoch=10)\n",
    "# vocab_model.save_model(\"fastText_NoStop.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract_vocab = build_vocab(df[\"abstract\"], 0)\n",
    "# text_vocab = build_vocab(df[\"text\"], 0)\n",
    "# print(\"abstract vocab\", len(abstract_vocab))\n",
    "# print(\"text vocab\", len(text_vocab))\n",
    "# # def save_object(objects, filename):\n",
    "# #     with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "# #         pickle.dump(objects, outp, -1)\n",
    "# # vocabs = [abstract_vocab, text_vocab]\n",
    "# # save_object(vocabs, 'SSNvocabs180_0F2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('SSNvocabs180_0F2.pkl', 'rb') as inp:\n",
    "#     abstract_vocab, text_vocab = pickle.load(inp)\n",
    "# print(\"abstract vocab\", len(abstract_vocab))\n",
    "# print(\"text vocab\", len(text_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenise(vocab, text, max_len, target=True):\n",
    "#     word_ids = []\n",
    "#     if target:\n",
    "#         word_ids = [vocab(\"<start>\")]\n",
    "#     for word in text.split():\n",
    "#         word_ids.append(vocab(word))\n",
    "#     word_ids.append(vocab(\"<end>\"))\n",
    "#     while len(word_ids) < max_len:\n",
    "#             word_ids.append(vocab(\"<pad>\"))\n",
    "#     return word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNDataset(Dataset):\n",
    "    def __init__(self, df, tokeniser):\n",
    "\n",
    "        self.df = df\n",
    "#         self.a_vocab = a_vocab\n",
    "#         self.t_vocab = t_vocab\n",
    "        self.abstract_max_len = ABSTRACT_MAX\n",
    "        self.text_max_len = TEXT_MAX\n",
    "        self.tokeniser = tokeniser\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return word_id\n",
    "        prefix = \"summarize: \"\n",
    "        abstract = self.df.iloc[index][\"target_text\"]\n",
    "        text = self.df.iloc[index][\"source_text\"]\n",
    "        \n",
    "        text_id = self.tokeniser(text, max_length=self.text_max_len,padding='max_length')\n",
    "\n",
    "        abstract_id = self.tokeniser(abstract, max_length=self.abstract_max_len, padding='max_length')\n",
    "\n",
    "        \n",
    "#         a_word_ids = tokenise(self.a_vocab, abstract, self.abstract_max_len, target=True)\n",
    "#         t_word_ids = tokenise(self.t_vocab, text, self.text_max_len, target=True)\n",
    "\n",
    "#         a_length = len(a_word_ids)\n",
    "#         t_length = len(t_word_ids)\n",
    "        text_id[\"labels\"] = abstract_id[\"input_ids\"]\n",
    "        return text_id#torch.tensor(a_word_ids), torch.tensor(t_word_ids)#a_word_ids, t_word_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_collate_fn(data):\n",
    "    \"\"\" Creates mini-batch tensors from the list of tuples (image, caption).\n",
    "    Args:\n",
    "        data: list of tuple of 2 word ids\n",
    "        - abstract id\n",
    "        - text id\n",
    "    Returns:\n",
    "        abstract list ids\n",
    "        text list ids\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "\n",
    "    labels = [row['labels'] for row in data]\n",
    "    texts = [row['input_ids'] for row in data]\n",
    "    masks = [row['attention_mask'] for row in data]\n",
    "    \n",
    "    \n",
    "    dictionary['input_ids'] = torch.tensor(texts)\n",
    "    dictionary['labels'] = torch.tensor(labels)\n",
    "    dictionary['attention_mask'] = torch.tensor(masks)\n",
    "\n",
    "    return dictionary\n",
    "    \n",
    "    abstracts, texts = zip(*data)\n",
    "#     abstract_list = []\n",
    "#     text_list = []\n",
    "#     for i in range(len(texts)):\n",
    "#         text_list.append(torch.tensor(texts[i]))\n",
    "#         abstract_list.append(torch.tensor(abstracts[i]))\n",
    "\n",
    "\n",
    "#     abstracts = torch.tensor(abstracts)\n",
    "#     texts = torch.tensor(texts)\n",
    "#     abstracts = [ torch.Tensor(abstract).to(device) for abstract in abstracts ]\n",
    "# if batch size is 1 then use [0]\n",
    "#     abstracts = torch.stack(tuple(abstract_list), 0)\n",
    "#     texts = torch.stack(tuple(text_list), 0)\n",
    "    #abstracts = abstracts.unsqueeze(0)\n",
    "    abstracts = torch.stack(abstracts, 0)\n",
    "    texts = torch.stack(texts, 0)\n",
    "    #texts = texts.unsqueeze(0)\n",
    "\n",
    "    return abstracts, texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, random_state=seed, train_size = 0.7)\n",
    "train_data, valid_data = train_test_split(train_data, random_state=seed, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SSNDataset(train_data, tokeniser)\n",
    "valid_set = SSNDataset(test_data,  tokeniser)\n",
    "#test_set = SSNDataset(test_data, tokeniser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "batch_size = 2\n",
    "model_name = 't5-small'.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=100,\n",
    "    predict_with_generate=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    logging_steps=1,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at C:\\Users\\tomwu/.cache\\huggingface\\transformers\\fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.d67b370cd9d75f81ad4eb421ee7b8db09e0b6a6c693b8c2b423af5d7bcac6205\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at C:\\Users\\tomwu/.cache\\huggingface\\transformers\\fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 8.00 GiB total capacity; 7.26 GiB already allocated; 0 bytes free; 7.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 33\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#model.resize_token_embeddings(len(tokeniser))\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# checkpoint = \"t5-small\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# config = AutoConfig.from_pretrained(checkpoint)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# model.resize_token_embeddings(len(tokeniser))\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#model = AutoModelForSeq2SeqLM.from_pretrained('t5-small', config = config)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokeniser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m# the instantiated ðŸ¤— Transformers model to be trained\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# training dataset\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# evaluation dataset\u001b[39;49;00m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_collate_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# problem with removing unwanted columns by transformers.Trainer code. Doesn't really work, is it a bug?\u001b[39;49;00m\n\u001b[0;32m     40\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:377\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device:\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:535\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[1;34m(self, model, device)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[1;32m--> 535\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 8.00 GiB total capacity; 7.26 GiB already allocated; 0 bytes free; 7.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer,AutoModelForSeq2SeqLM, T5Config, T5Model, AutoConfig,AutoTokenizer\n",
    "\n",
    "#tokeniser = AutoTokenizer.from_pretrained(\"google/t5-efficient-tiny\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"google/t5-efficient-tiny\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "#model.resize_token_embeddings(len(tokeniser))\n",
    "# checkpoint = \"t5-small\"\n",
    "# config = AutoConfig.from_pretrained(checkpoint)\n",
    "# model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "# model_config = model.config.to_dict()\n",
    "# print(model_config.keys())\n",
    "# model_config[\"num_heads\"] = 2\n",
    "# model_config[\"d_model\"] = 256\n",
    "# model_config[\"d_ff\"] = 256\n",
    "# model_config[\"d_kv\"] = 4\n",
    "# model_config[\"num_decoder_layers\"] = 2\n",
    "# print(model_config[\"num_decoder_layers\"])\n",
    "# config = T5Config(**model_config)\n",
    "# model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "# model_config = model.config.to_dict()\n",
    "# print(model_config.keys())\n",
    "# model_config[\"num_heads\"] = 2\n",
    "# model_config[\"d_model\"] = 256\n",
    "# model_config[\"d_ff\"] = 256\n",
    "# model_config[\"d_kv\"] = 4\n",
    "# model_config[\"num_decoder_layers\"] = 2\n",
    "# print(model_config[\"num_decoder_layers\"])\n",
    "# config = T5Config(**model_config)\n",
    "# model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "# model.resize_token_embeddings(len(tokeniser))\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained('t5-small', config = config)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokeniser,\n",
    "    args=args,# the instantiated ðŸ¤— Transformers model to be trained\n",
    "    train_dataset=train_set,   # training dataset\n",
    "    eval_dataset=valid_set,      # evaluation dataset\n",
    "    data_collator=text_collate_fn    # problem with removing unwanted columns by transformers.Trainer code. Doesn't really work, is it a bug?\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./\" + 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomwu\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from simplet5 import SimpleT5\n",
    "model = SimpleT5()\n",
    "model.from_pretrained(model_type=\"t5\", model_name=\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomwu\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "C:\\Users\\tomwu\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2a2aff320645ffb9965673faad6e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train(train_df=train_data,\n",
    "        eval_df=valid_data,\n",
    "        source_max_token_len=TEXT_MAX,\n",
    "        target_max_token_len=ABSTRACT_MAX,\n",
    "        batch_size=2,\n",
    "        max_epochs=2,\n",
    "        use_gpu=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-small\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 4,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.16.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.model)\n",
    "from transformers import T5Config\n",
    "# model_config = model.model.config.to_dict()\n",
    "# for k, v in model_config.items():\n",
    "#     print(k, v)\n",
    "model_config = model.model.config.to_dict()\n",
    "model_config[\"num_heads\"] = 4\n",
    "config = T5Config(**model_config)\n",
    "# model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "model.model.config = config\n",
    "model.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# inputs = valid_data.at[7,\"source_text\"]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(inputs)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(\"\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(valid_data.at[7,\"target_text\"])\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\simplet5\\simplet5.py:464\u001b[0m, in \u001b[0;36mSimpleT5.predict\u001b[1;34m(self, source_text, max_length, num_return_sequences, num_beams, top_k, top_p, do_sample, repetition_penalty, length_penalty, early_stopping, skip_special_tokens, clean_up_tokenization_spaces)\u001b[0m\n\u001b[0;32m    460\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(\n\u001b[0;32m    461\u001b[0m     source_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    463\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 464\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m preds \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[0;32m    477\u001b[0m         g,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m generated_ids\n\u001b[0;32m    482\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:1088\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[0;32m   1082\u001b[0m         inputs_tensor, pad_token_id, eos_token_id\n\u001b[0;32m   1083\u001b[0m     )\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;66;03m# 4. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:507\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[0;32m    505\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    506\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 507\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:912\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 912\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    914\u001b[0m batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[0;32m    916\u001b[0m \u001b[38;5;66;03m# required mask seq length can be calculated via length of past\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "inputs = valid_data.at[7,\"source_text\"]\n",
    "print(inputs)\n",
    "print(\"\")\n",
    "print(valid_data.at[7,\"target_text\"])\n",
    "model.device = \"cpu\"\n",
    "model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summarize: s accused making fashion faux pas prime minister deaf yesterday david cameron seen pair beige loafers wore holiday mr cameron lanzarote family got shoes high street store aldo took portugal david cameron samantha yes s wearing shoes david cameron samantha portugal year debuted beige loafers yesterday teamed casual navy blue shirt beige shorts trip teguise centre island wife fashion consultant mrs cameron trumped husband style stakes wearing elegant black maxi dress emerald green couple children nancy arthur florence spending days island restored century farmhouse away main prime minister sported socks smart black work shoes memorable holiday look couple wear matching trainers holiday granada spain 2011 retreat styled indonesian includes carved buddha statues yoga hall swimming pool hot tub area hammocks ideal prime minister reputedly taste mr cameron previously ridiculed holiday attire wearing smart black work shoes socks garish floral david cameron wife samantha stop coffee water break lanzarote jetting april camerons holidayed lanzarote staying upmarket hotel camerons holidaying lanzarote eastern canary island']\n",
      "\n",
      "prime minister and his family are enjoying an easter break in lanzarote sported the same beige loafers as he wore in portugal last year pm sat and had a drink at a cafe on the spanish island\n",
      "tensor([[   0,    3,    2,    3,    7,    9,   26,   26,   23,  102, 2248,  102,\n",
      "         2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102,\n",
      "         2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102,\n",
      "         2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102,\n",
      "         2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102,\n",
      "         2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102,\n",
      "         2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102,\n",
      "         2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102,\n",
      "         2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102, 2248,  102,\n",
      "         2248,  102,   23,  102,   23,  102,    1]], device='cuda:0')\n",
      "<pad> <unk> saddipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipstipipip</s>\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\").to(device)\n",
    "inputs = [\"summarize: \" + train_data.at[1,\"text\"]]\n",
    "print(inputs)\n",
    "print(\"\")\n",
    "print(train_data.at[1,\"abstract\"])\n",
    "inputs = tokeniser(inputs, max_length=TEXT_MAX, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**inputs, num_beams=8, max_length=130)\n",
    "print(output)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=False)[0]\n",
    "print(decoded_output)\n",
    "# preds, labels= trainer.predict()\n",
    "# preds_tokens = preds.argmax(axis=2)\n",
    "# preds_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True, collate_fn=text_collate_fn) # num_worker can't be 2+ as the time it \n",
    "                                                                 # takes to build iter is much longer\n",
    "valid_loader = DataLoader(valid_set, batch_size=8, shuffle=True, collate_fn=text_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True, collate_fn=text_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_name = 't5-small'.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_set = SSNDataset(df, abstract_vocab, text_vocab)\n",
    "# all_loader = DataLoader(all_set, batch_size=1, shuffle=True, collate_fn=text_collate_fn)\n",
    "# abstracts = []\n",
    "# texts = []\n",
    "# for i, (abstract, text) in tqdm(enumerate(all_loader), total=len(all_loader)):\n",
    "#     a_size = list(abstract.size())[1]\n",
    "\n",
    "#     t_size = list(text.size())[1]\n",
    "#     abstracts.append(a_size)\n",
    "#     texts.append(t_size)\n",
    "# numbers = list(range(len(all_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statistics import mean\n",
    "# print(\"max length for abstract: \",max(abstracts))\n",
    "# print(\"max length for text: \",max(texts))\n",
    "# print(\"min length for abstract: \",min(abstracts))\n",
    "# print(\"min length for text: \",min(texts))\n",
    "# print(\"average length for abstract: \",math.floor(mean(abstracts)))\n",
    "# print(\"average length for text: \",math.floor(mean(texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(math.floor(np.percentile(texts, 50)))\n",
    "# print(math.floor(np.percentile(abstracts, 50)))\n",
    "# print(math.floor(np.percentile(texts, 1)))\n",
    "# print(math.floor(np.percentile(abstracts, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_perc = []\n",
    "# t_perc = []\n",
    "# for i in range(100):\n",
    "#     i +=1\n",
    "#     a_perc.append(np.percentile(abstracts, i))\n",
    "#     t_perc.append(np.percentile(texts,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(range(len(a_perc)),a_perc)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(range(len(t_perc)), t_perc)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# vec = Word2Vec(sentences=\"text_cnn.txt\", vector_size=300, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_vocab = vec.wv.key_to_index\n",
    "# text_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_tgt_mask(size):\n",
    "#     # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "#     mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "#     mask = mask.float()\n",
    "#     mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "#     mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "#     return mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(data, pad_idx):\n",
    "    return (data == pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderNet(nn.Module):\n",
    "    def __init__(self, text_vocab, pad_idx, embed_dim, hidden_size, nheads, n_layers, max_text_len, \n",
    "                 dropout):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        # embedding layers\n",
    "        self.enc_embedding = nn.Embedding(text_vocab, embed_dim)\n",
    "        # positional encoding layer\n",
    "        self.enc_pe = PositionalEncoding(embed_dim, max_len = max_text_len)\n",
    "        # encoder layers\n",
    "        enc_layer = nn.TransformerEncoderLayer(embed_dim, nheads, hidden_size, dropout)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers = n_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mask = create_mask(x, self.pad_idx)\n",
    "        enc_embed = self.enc_embedding(x).permute(1, 0, 2)\n",
    "        enc_pe = self.enc_pe(enc_embed)\n",
    "        memory = self.encoder(enc_pe, src_key_padding_mask=mask)\n",
    "        return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderNet(nn.Module):\n",
    "    def __init__(self, abstract_vocab, pad_idx, embed_dim, hidden_size, nheads, n_layers, max_abs_len, \n",
    "                 dropout):\n",
    "        super(DecoderNet, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        # embedding layers\n",
    "        self.dec_embedding = nn.Embedding(abstract_vocab, embed_dim)\n",
    "        # positional encoding layer\n",
    "        self.dec_pe = PositionalEncoding(embed_dim, max_len = max_abs_len)\n",
    "        # decoder layers\n",
    "        dec_layer = nn.TransformerDecoderLayer(embed_dim, nheads, hidden_size, dropout)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers = n_layers)\n",
    "    \n",
    "    def forward(self, x, enc_output):\n",
    "        #target_mask = create_tgt_mask(x.shape[1])\n",
    "        mask = create_mask(x, self.pad_idx)\n",
    "\n",
    "        dec_embed = self.dec_embedding(x).permute(1, 0, 2)\n",
    "        dec_pe = self.dec_pe(dec_embed)\n",
    "        dec_out = self.decoder(dec_pe, enc_output, tgt_key_padding_mask=mask)\n",
    "        return dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNet(nn.Module):\n",
    "  def __init__(self, text_vocab, abstract_vocab, pad_idx, embed_dim, hidden_size, nheads, n_layers, \n",
    "               max_text_len, max_abs_len, dropout):\n",
    "    super(TransformerNet, self).__init__()\n",
    "    self.EncoderNet = EncoderNet(text_vocab, pad_idx, embed_dim, hidden_size, nheads, n_layers, \n",
    "                                 max_text_len, dropout)\n",
    "    self.DecoderNet = DecoderNet(abstract_vocab, pad_idx, embed_dim, hidden_size, nheads, n_layers, \n",
    "                                 max_abs_len, dropout)\n",
    "    # final dense layer\n",
    "    self.fc = nn.Linear(embed_dim, abstract_vocab)\n",
    "    #self.log_softmax = nn.LogSoftmax()\n",
    "\n",
    "  def forward(self, text, abstract):\n",
    "\n",
    "    enc_output = self.EncoderNet(text)\n",
    "\n",
    "    dec_output = self.DecoderNet(abstract, enc_output)\n",
    "    \n",
    "    output = self.fc(dec_output)\n",
    "    return output #self.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Pytorch tutorial for details\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(text_size,abstract_size,pad_idx, embed_size, hid_dim, \n",
    "                       n_head, n_layer, TEXT_MAX, ABSTRACT_MAX, dropout, path=None):\n",
    "    \n",
    "    model = TransformerNet(text_size,abstract_size,pad_idx, embed_size, hid_dim, \n",
    "                       n_head, n_layer, TEXT_MAX, ABSTRACT_MAX, dropout).to(device)\n",
    "    if path == None:\n",
    "        for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        return model\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(best_path))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_size = len(text_vocab)\n",
    "abstract_size = len(abstract_vocab)\n",
    "pad_idx = 0\n",
    "embed_size = 128  # embedding dimension\n",
    "hid_dim = 100  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "n_head = 2\n",
    "n_layer =1  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "dropout = 0.1  # dropout probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerNet(\n",
       "  (EncoderNet): EncoderNet(\n",
       "    (enc_embedding): Embedding(14210, 128)\n",
       "    (enc_pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=100, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=100, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (DecoderNet): DecoderNet(\n",
       "    (dec_embedding): Embedding(3752, 128)\n",
       "    (dec_pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=100, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=100, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=3752, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_path = \"trans_SSN_256_256_Batch_8_4H3lr0.0001.pth\"\n",
    "# model = TransformerNet(text_size,abstract_size,pad_idx, embed_size, hid_dim, \n",
    "#                        n_head, n_layer, TEXT_MAX, ABSTRACT_MAX, dropout, best_path).to(device)\n",
    "\n",
    "model = get_model(text_size,abstract_size,pad_idx, embed_size, hid_dim, \n",
    "                       n_head, n_layer, TEXT_MAX, ABSTRACT_MAX, dropout).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, (abstract, text) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "#     # send batch data to device\n",
    "#     print(\"i\", i)\n",
    "#     src = text.to(device)\n",
    "#     trg = abstract.to(device)\n",
    "    \n",
    "    \n",
    "# #     src_mask, trg_mask = create_masks(src, trg)\n",
    "# #     src_mask.to(device)\n",
    "# #     trg_mask.to(device)\n",
    "    \n",
    "#     preds = model(src, trg)\n",
    "#     print(preds.shape)\n",
    "#     # this gives topk, then select the top1 result, then review it as a list\n",
    "#     # then select the last item, this would be the highest prob\n",
    "#     # only work in inference as this requires no batch\n",
    "#     token = preds.topk(1)[1].view(-1)[-1].item()\n",
    "#     print(token)\n",
    "#     print(abstract_vocab.get_word(token))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "~~1 - Complete model definition~~ <br>\n",
    "~~2 - fix word vocab~~ <br>\n",
    "~~3 - Define Attention model and combine with Decoder~~ <br>\n",
    "    ~~1 - Adjust to allow for batch ~~<br>\n",
    "4 - trace through program to see where it starts to have the same tensor <br>\n",
    "~~5 - use mask to hide paddings~~ switch on off to see difference<br>\n",
    "~~6 - Switch from GRU to LSTM~~<br>\n",
    "~~7 - Add training script to train ~~<br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model):\n",
    "    lr = 0.001\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx) # ignore pad\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) # learning rate also affects overfitting\n",
    "    #scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    epoch_size = 20\n",
    "    loss_epoch = []\n",
    "    loss_accuracy = []\n",
    "    eval_loss_epoch = []\n",
    "    eval_accuracy = []\n",
    "    best_loss = 1000\n",
    "    \n",
    "    for epoch in range(1,epoch_size+1):\n",
    "        \n",
    "        model.train()\n",
    "        loss_batch = []\n",
    "        batch_acc = []\n",
    "        for i, (abstract, text) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            # send batch data to device\n",
    "            \n",
    "            abstract = abstract.to(device)\n",
    "            text = text.to(device)\n",
    "            tar_inp = abstract[:, :-1]\n",
    "            tar_real = abstract[:, 1:]\n",
    "            \n",
    "            \n",
    "#             print(text)\n",
    "#             print(abstract)\n",
    "            outputs = model(text, abstract=tar_inp).to(device).permute(1,2,0)\n",
    "            #print(outputs)\n",
    "            #decode(outputs, abstract)\n",
    "            loss = criterion(outputs, tar_real)\n",
    "            #batch_acc.append(get_accuracy(outputs, abstract))\n",
    "            #print(loss.item())\n",
    "            \n",
    "            # Optimise\n",
    "            del abstract\n",
    "            del text\n",
    "            del outputs\n",
    "\n",
    "            loss_batch.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #plot_grad_flow(model.named_parameters())\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            \n",
    "        #return model\n",
    "            #print(loss.item())\n",
    "        current_loss = np.average(loss_batch)\n",
    "        current_acc = np.average(batch_acc)\n",
    "        loss_epoch.append(current_loss)\n",
    "        loss_accuracy.append(current_acc)\n",
    "\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}, Acc: {:.4f}'\n",
    "            .format(epoch, epoch_size, current_loss, current_acc))\n",
    "\n",
    "        eval_loss_batch = []\n",
    "        eval_batch_acc = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for j, (abstract, text) in enumerate(valid_loader):\n",
    "                abstract = abstract.to(device)\n",
    "                text = text.to(device)\n",
    "                \n",
    "                scores = model(text, abstract=abstract).to(device).permute(1,2,0)\n",
    "                #decode(scores, abstract)\n",
    "                eval_loss = criterion(scores, abstract)\n",
    "                \n",
    "                #print(eval_loss.item())\n",
    "                eval_loss_batch.append(eval_loss.item())\n",
    "                eval_batch_acc.append(get_accuracy(scores, abstract))\n",
    "                del abstract\n",
    "                del text\n",
    "                del scores\n",
    "                del eval_loss\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        current_eval_loss = np.average(eval_loss_batch)\n",
    "        current_eval_acc = np.average(eval_batch_acc)\n",
    "        \n",
    "        eval_loss_epoch.append(current_eval_loss)\n",
    "        eval_accuracy.append(current_eval_acc)\n",
    "        \n",
    "        #decrease learning\n",
    "        #scheduler.step(current_eval_loss)\n",
    "        \n",
    "        if (current_eval_loss < best_loss):\n",
    "            best_loss = current_eval_loss\n",
    "            torch.save(model.state_dict(), 'trans_SSN_300_256_Batch_8_4H'+str(epoch)+'lr'+str(lr)+'.pth')\n",
    "            print(\"Best eval loss updated!\")\n",
    "        else:\n",
    "            torch.save(model.state_dict(), 'Xtrans_SSN_300_256_Batch_8_4H'+str(epoch)+'lr'+str(lr)+'.pth')\n",
    "            \n",
    "        print('Valid Epoch [{}/{}], Loss: {:.4f}, Acc: {:.4f}'\n",
    "            .format(epoch, epoch_size, current_eval_loss, current_eval_acc))\n",
    "    return loss_epoch, eval_loss_epoch, loss_accuracy, eval_accuracy\n",
    "def get_accuracy(preds, abstracts):\n",
    "#     print(\"preds: \", preds.shape)\n",
    "#     print(\"abstracts:\", abstracts.shape)\n",
    "    pred_ids = preds.argmax(1)\n",
    "    correct_preds = (pred_ids == abstracts).sum().item()\n",
    "    # Calculate the total number of samples\n",
    "    total_samples = abstracts.shape[0] * abstracts.shape[1]\n",
    "    \n",
    "    # Calculate accuracy as the ratio of correct predictions to total samples\n",
    "    accuracy = correct_preds / total_samples\n",
    "    return accuracy\n",
    "def decode(preds, abstracts):\n",
    "    pred_ids = preds.argmax(1)\n",
    "    for i in range(len(pred_ids)):\n",
    "        sentence = \"\"\n",
    "        sentence2 = \"\"\n",
    "        for j in range(119):\n",
    "            sentence += abstract_vocab.get_word(pred_ids[i][j].item()) + \" \"\n",
    "            sentence2 += abstract_vocab.get_word(abstracts[i][j].item()) + \" \"\n",
    "        print(\"pred: \",sentence)\n",
    "        print(\"abstract: \",sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0e7714e75b4c93a4d8ef3902e1294c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 7.5720, Acc: nan\n",
      "Best eval loss updated!\n",
      "Valid Epoch [1/20], Loss: 8.0479, Acc: 0.0083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98283c9851949aabe33c848e32e3b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 7.4709, Acc: nan\n",
      "Valid Epoch [2/20], Loss: 8.5535, Acc: 0.0083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a5193e03e04c62983fff7d0f18c6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 7.3504, Acc: nan\n",
      "Valid Epoch [3/20], Loss: 8.5957, Acc: 0.0096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09763f832b5141be8505492293a6fc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 7.2511, Acc: nan\n",
      "Valid Epoch [4/20], Loss: 8.6936, Acc: 0.0113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad22ae13f4f408094e088cac9ae7414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 7.1545, Acc: nan\n",
      "Valid Epoch [5/20], Loss: 8.8668, Acc: 0.0111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8362a7ec4f054e7d9d32be8c626e34d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 7.0056, Acc: nan\n",
      "Valid Epoch [6/20], Loss: 8.6788, Acc: 0.0118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7847a48dc4a44f7ba610e09847ee55d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 6.8183, Acc: nan\n",
      "Valid Epoch [7/20], Loss: 8.8705, Acc: 0.0125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d1c19e78854f09a5f97d785bc2cdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 6.5829, Acc: nan\n",
      "Valid Epoch [8/20], Loss: 8.6804, Acc: 0.0142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba92f1767f16481a8135713d3b063de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 6.2786, Acc: nan\n",
      "Valid Epoch [9/20], Loss: 8.7101, Acc: 0.0152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946ab2f4518e4f918b22da7f84781bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 5.9487, Acc: nan\n",
      "Valid Epoch [10/20], Loss: 8.6904, Acc: 0.0147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1aa1a25ca94bc78fec56a6a7fa6264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 5.5946, Acc: nan\n",
      "Valid Epoch [11/20], Loss: 9.1915, Acc: 0.0112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df55c062b1448678ccac4b8520f4fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 5.2360, Acc: nan\n",
      "Valid Epoch [12/20], Loss: 9.3813, Acc: 0.0145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7663e5f092984928af2f6c187db8fe27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 4.8915, Acc: nan\n",
      "Valid Epoch [13/20], Loss: 9.8657, Acc: 0.0087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f21dec9629343b580ffe8f97e360446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 4.5439, Acc: nan\n",
      "Valid Epoch [14/20], Loss: 9.8854, Acc: 0.0105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690bb65ab7034ba88076a4ef1ddb255a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 4.2337, Acc: nan\n",
      "Valid Epoch [15/20], Loss: 10.3854, Acc: 0.0096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31acddb028049e98a3b1b0b32ab74d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 3.9223, Acc: nan\n",
      "Valid Epoch [16/20], Loss: 10.4518, Acc: 0.0089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2d70ee0a5c4decb4f695dbc9393330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 3.5831, Acc: nan\n",
      "Valid Epoch [17/20], Loss: 10.8958, Acc: 0.0107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dea4f026604a62b4411f037276ff8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 3.2253, Acc: nan\n",
      "Valid Epoch [18/20], Loss: 11.2666, Acc: 0.0069\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7fafe6ab4a4d4da15b82fcd8296bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 2.9161, Acc: nan\n",
      "Valid Epoch [19/20], Loss: 11.3405, Acc: 0.0044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8134381c88124fb5a5291638aac3ba63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 2.5895, Acc: nan\n",
      "Valid Epoch [20/20], Loss: 11.7294, Acc: 0.0048\n"
     ]
    }
   ],
   "source": [
    "train_loss, eval_loss, train_acc, eval_acc = train(train_loader, valid_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grad_flow(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def writeLoss(filename, loss):\n",
    "    # filename in format losstype+layer+dim, validL2D256\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = filename + \"_\" + timestr + \".txt\"\n",
    "    with open(filename, \"a\") as myfile:\n",
    "        for item in loss:\n",
    "            myfile.write(str(item)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'writeLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[254], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwriteLoss\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loss)\n\u001b[0;32m      2\u001b[0m writeLoss(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid\u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_loss)\n\u001b[0;32m      3\u001b[0m writeLoss(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_acc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'writeLoss' is not defined"
     ]
    }
   ],
   "source": [
    "writeLoss(\"Train\", train_loss)\n",
    "writeLoss(\"Valid\", eval_loss)\n",
    "writeLoss(\"Train_acc\", train_acc)\n",
    "writeLoss(\"Valid_acc\", eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        #print(n)\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            #print(type(p.grad))\n",
    "            ave_grads.append(torch.mean(torch.abs(p.grad)).cpu())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d696d34d60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(eval_loss)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train loss','Valid loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds, abstracts):\n",
    "#     print(\"preds: \", preds.shape)\n",
    "#     print(\"abstracts:\", abstracts.shape)\n",
    "pred_ids = preds.argmax(1)\n",
    "correct_preds = (pred_ids == abstracts).sum().item()\n",
    "# Calculate the total number of samples\n",
    "total_samples = abstracts.shape[0] * abstracts.shape[1]\n",
    "\n",
    "# Calculate accuracy as the ratio of correct predictions to total samples\n",
    "accuracy = correct_preds / total_samples\n",
    "return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[1, 2, 4]])\n"
     ]
    }
   ],
   "source": [
    "test= torch.tensor([[1,2,4],[1,2,3]])\n",
    "print(test.shape)\n",
    "print(test[:-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3819693aea3b4c3db4beadd2c5cceb1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> humans easily recognize importance people social event images focus important individuals learning learn relation people image inferring important person based relation remains undeveloped work propose deep importance relation network point combines relation modeling feature learning particular infer types interaction modules person person interaction module learns interaction people event person interaction module learns person involved event occurring image estimate importance relations people interactions encode relation feature importance relations way point automatically learns types relation features parallel aggregate relation features person's feature form importance feature important people classification extensive experimental results method effective important people detection verify efficacy learning learn relations important people detection <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> real world face detection alignment demand advanced discriminative model address challenges pose lighting expression illuminated deep learning algorithm convolutional neural networks based face detection alignment methods proposed recent studies utilized relation face detection alignment make models computationally efficiency ignore connection cascade cnns paper propose structure propose higher quality training data end end cascade network training computers space automatic adjust weight parameter accelerate convergence experiments demonstrate considerable improvement existing detection alignment models <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper studies panoptic segmentation recently proposed task segments foreground fg objects instance level background bg contents semantic level existing methods dealt problems separately paper reveal underlying relationship particular fg objects provide complementary cues assist bg understanding approach named attention guided unified network aunet unified framework branches fg bg segmentation simultaneously sources attentions added bg branch rpn fg segmentation mask provide object level pixel level attentions respectively approach generalized different backbones consistent accuracy gain fg bg segmentation sets new state arts ms coco pq cityscapes pq benchmarks <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> convolutional neural networks cnns demonstrated great results single image super resolution sisr problem currently cnn algorithms promote deep computationally expensive models solve sisr propose novel sisr method uses relatively number computations training group convolutions unused connections removed refined specifically task hand removing unnecessary modules original condensenet reconstruction network consisting deconvolutional layers used order upscale high resolution steps significantly reduce number computations required testing time bicubic upsampled input added network output easier learning model named srcondensenet evaluate method using various benchmark datasets performs favourably state art methods terms accuracy number computations required <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> using neural network architecture depth map inference monocular stabilized videos application uav videos rigid scenes propose multi range architecture unconstrained uav flight leveraging flight data sensors make accurate depth maps uncluttered outdoor environment try algorithm synthetic scenes real uav flight data quantitative results given synthetic scenes slightly noisy orientation multi range architecture improves depth inference article video present results thoroughly <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> report approach tackling task activitynet 2018 challenge described spatial temporal modelling methods adopt end end framework stage frameworks proposed existing state arts task video modelling far solved challenge propose spatial temporal network stnet better joint spatial temporal modelling comprehensively video understanding given multi modal information contained video source manage integrate early fusion later fusion strategy multi modal information proposed improved temporal xception network itxn video understanding <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper address task relation mention extraction noisy data extracting representative phrases particular relation noisy sentences collected distant supervision despite significance value downstream applications task studied noisy data major challenges exists 1 lack annotation mention phrases severely 2 handling noisy sentences express relation address challenges formulate task semi markov decision process propose novel hierarchical reinforcement learning model model consists level sentence selector remove noisy sentences low level mention extractor extract relation mentions reward estimator provide signals guide data denoising mention extraction explicit annotations experimental results model effective extract relation mentions noisy data <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> practically unlimited natural language data available recent work text comprehension focused datasets small relative current computing possibilities article making case community larger data step direction proposing booktest new dataset similar popular children's book test cbt 60 times larger training new data improves accuracy attention sum reader model original cbt test data larger margin recent attempts improve model architecture version dataset ensemble exceeds human baseline provided facebook human study space improvement <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> introduce method learning generate surface shapes approach represents shape collection parametric surface elements contrast methods generating voxel grids point clouds naturally infers surface representation shape novelty new shape generation framework atlasnet comes significant advantages improved precision generalization capabilities possibility generate shape arbitrary resolution memory issues demonstrate benefits compare strong baselines shapenet benchmark applications auto encoding shapes ii single view reconstruction image provide results showing potential applications morphing parametrization super resolution matching segmentation <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> goal sentiment change underlying sentiment sentence keeping content main challenge lack parallel data solve problem propose cycled reinforcement learning method enables training unpaired data collaboration neutralization module emotionalization module evaluate approach review datasets yelp amazon experimental results approach significantly outperforms state art systems especially proposed method substantially improves content preservation performance bleu score improved datasets respectively <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> relay channel orthogonal components affected interference signal noncausally available source studied interference signal structure produced transmitter communicating destination interferer willing adjust communication strategy minimize interference knowledge interferer's signal acquired source instance exploiting harq retransmissions interferer's link source utilize relay communicating message cooperative interference mitigation destination informing relay interference signal proposed transmission strategies based partial decode forward pdf relaying leverage interference structure achievable schemes derived discrete memoryless models gaussian ricean fading channels furthermore optimal strategies identified special cases finally numerical results bring insight advantages utilizing interference structure source relay destination <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> propose abstraction based multi document summarization framework construct new sentences exploring fine grained syntactic units sentences noun verb phrases different existing abstraction based approaches method constructs pool concepts facts represented phrases input documents new sentences generated selecting merging informative phrases maximize salience phrases satisfy sentence construction constraints employ integer linear optimization conducting phrase selection merging simultaneously order achieve global optimal solution summary experimental results benchmark data set tac 2011 framework outperforms state art models automated pyramid evaluation metric achieves reasonably results manual linguistic quality evaluation <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> policy gradient approaches reinforcement learning common undesirable overhead procedures warm start training sample variance reduction paper reinforcement learning method based softmax value function requires procedures method combines advantages policy gradient methods efficiency simplicity maximum likelihood approaches apply new cold start reinforcement learning method training sequence generation models structured output prediction problems empirical evidence validates method automatic summarization image captioning tasks <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> field evolutionary computation challenging topics algorithm selection knowing heuristics use optimization problem key obtaining high quality solutions aim extend research topic taking step selection method adaptive cma es algorithms build theoretical work van rijn al potential switching different cma es variants quantified context modular cma es framework demonstrate work proposed approach reliable implementing suggested adaptive configurations does yield predicted performance gains propose revised approach results robust fit predicted actual performance adaptive cma es approach obtains performance gains 18 24 tested functions bbob benchmark stable advantages analysis module activation indicates modules crucial different phases optimizing 24 benchmark problems module activation suggests additional gains possible including modules excluded present work <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> present novel end end visual odometry architecture guided feature selection based deep convolutional recurrent neural networks different current monocular visual odometry methods approach established intuition features contribute discriminately different motion patterns specifically propose dual branch recurrent network learn rotation translation separately leveraging current convolutional neural network cnn feature representation recurrent neural network rnn image sequence reasoning enhance ability feature selection introduce effective context aware guidance mechanism force branch distill related information specific motion pattern explicitly experiments demonstrate prevalent kitti benchmarks method outperforms current state art learning based methods decoupled joint camera pose recovery <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> lately novel developments deep learning solving cocktail party problem initial results promising allow research domain technique explored neural network approach task speaker adaptation intuitively information speakers trying separate fundamentally important speaker separation task retrieving speaker information challenging speaker identities known priori multiple speakers simultaneously active sort chicken egg problem tackle source signals vectors estimated alternately <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> neural machine translation mt reached state art results main challenges neural mt faces dealing large vocabularies morphologically rich languages paper propose neural mt using character based embeddings combination convolutional highway layers replace standard lookup based word representations resulting unlimited vocabulary affix aware source word embeddings tested state art neural mt based attention based bidirectional recurrent neural network proposed mt scheme provides improved results source language morphologically rich improvements 3 bleu points obtained german english wmt task <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper aims determine best human action recognition method based features extracted rgb d devices microsoft kinect review papers make reference msr used dataset includes depth information acquired rgb d device performed validation method used work differs direct comparison works works present results comparing taking account issue <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> increased availability high resolution satellite imagery allows sense detailed structures surface planet access information opens new directions analysis remote sensing imagery time raises set new challenges existing pixel based prediction methods semantic segmentation approaches deep neural networks achieved significant advances semantic segmentation high resolution images past existing approaches tend produce predictions poor boundaries paper address problem preserving semantic segmentation boundaries high resolution satellite imagery introducing new cascaded multi task loss evaluate approach inria aerial image labeling dataset contains large scale high resolution images results able outperform state art methods additional post processing step <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> recent work suenderhauf et al 1 demonstrated improved visual place recognition using proposal regions coupled features convolutional neural networks cnn match landmarks views work extend approach introducing descriptors built landmark features encode spatial distribution landmarks view matching descriptors enforces consistency relative positions landmarks views significant impact performance example experiments 10 image pair datasets consisting 200 urban locations significant differences viewing positions conditions recorded average precision 70 100 recall compared 58 obtained using image cnn features 50 method 1 <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> work gatys et al 1 recently showed neural style algorithm produce image style image works introduced various improvements regarding generalization quality efficiency focused styles paintings abstract images photo realistic style paper present comparison state art style transfer methods cope transferring various comic styles different images select different combinations adaptive instance normalization 11 universal style transfer 16 models confront advantages disadvantages terms qualitative quantitative analysis finally present results survey conducted 100 people aims validating evaluation results real life application comic style transfer <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> prototype dialogue response generation model customer service domain amazon model trained weakly supervised fashion measures similarity customer questions agent answers using dual encoder network siamese like neural network architecture answer templates extracted embeddings derived past agent answers turn turn annotations responses customer inquiries generated selecting best template final set templates closed domain like customer service selected templates cover past customer inquiries furthermore relevance model selected templates significantly higher templates selected standard tf idf baseline <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> recent works word representations rely predictive models distributed word representations aka word embeddings trained optimally predict contexts corresponding words tend appear models succeeded capturing word similarties semantic syntactic regularities instead aim reviving model based counts present systematic study use hellinger distance extract semantic representations word occurence statistics large text corpora distance gives good performance word similarity analogy tasks proper type size context dimensionality reduction based stochastic low rank approximation simple intuitive method provides encoding function used infer unseen words phrases clear advantage compared predictive models train new words <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> simple online realtime tracking sort pragmatic approach multiple object tracking focus simple effective algorithms paper integrate appearance information improve performance sort extension able track objects longer periods occlusions effectively reducing number identity switches spirit original framework place computational complexity offline pre training stage learn deep association metric large scale person identification dataset online application establish measurement track associations using nearest neighbor queries visual appearance space experimental evaluation shows extensions reduce number identity switches 45 achieving overall competitive performance high frame rates <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> perception grasping challenging problem robotics inexpensive range sensors microsoft kinect provide sensing capabilities given new life effort developing robust accurate perception methods robot grasping paper proposes new approach localizing enveloping grasp affordances point clouds efficiently approach based modeling enveloping grasp affordances cylindrical shells corresponds geometry robot hand fast accurate fitting method quadratic surfaces core approach evaluation set cluttered environments shows high precision recall statistics results approach compares favorably alternatives efficient employed robot grasping real time <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> neural sequence sequence networks attention achieved remarkable performance machine translation reasons effectiveness ability capture relevant source contextual information time step prediction attention mechanism target context solely based sequence model practice prone recency bias lacks ability capture effectively non sequential dependencies words address limitation propose target attentive residual recurrent network decoding attention previous words contributes directly prediction word residual learning facilitates flow information distant past able emphasize previously translated words gains access wider context proposed model outperforms neural mt baseline memory self attention network language pairs analysis attention learned decoder confirms emphasizes wider context captures syntactic like structures <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper introduce novel concept densely connected layers recurrent neural networks evaluate proposed architecture penn treebank language modeling task obtain similar perplexity scores times fewer parameters compared standard stacked lstm model trained dropout zaremba et al 2014 contrast current usage skip connections densely connecting stacked layers skip connections yields significant perplexity reductions <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> using memristor's memory store bit perform operation second input bit simple boolean logic gates built single memristor operation makes use interaction current spikes occasionally called current transients memristors devices sequential time based logic methodology allows logical input bits used port sending bits separated time resulting logic gate faster relying memristor's state switching low power requires memristor experimentally demonstrate working xor gates single flexible titanium dioxide sol gel memristor <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> visible light communications vlc studied thoroughly recent years alternative complementary technology radio frequency communications reliability vlc channels highly depends availability alignment line sight links work study effect random receiver orientation mobile users vlc downlink channels affects existence line sight links receiver field view based statistics vertical receiver orientation user mobility develop unified analytical framework characterize statistical distribution vlc downlink channels utilized obtain outage probability bit error rate analysis generalized arbitrary distributions receiver orientation location single transmitter extended multiple transmitter case certain scenarios extensive monte carlo simulations perfect match analytical simulation data terms statistical channel distribution resulting bit error rate results characterize channel attenuation random receiver orientation location various scenarios <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> count based word alignment methods ibm models fast align struggle small parallel corpora present alternative approach based cross lingual word embeddings clwes trained purely monolingual data main contribution unsupervised objective adapt clwes parallel corpora experiments 25 500 sentences method outperforms fast align fine tuning objective consistently improves clwe baseline <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> field artificial intelligence neuromorphic computing decades deep learning recent progress consistently outperforms neuromorphic learning algorithms classification tasks terms accuracy specifically field image classification neuromorphic computing traditionally using temporal rate code encoding static images datasets spike trains till recently neuromorphic vision sensors widely used neuromorphic research community provides alternative encoding methods neuromorphic datasets obtained applying sensors image datasets neuromorphic caltech 101 introduced data encoded spike trains ideal benchmarking neuromorphic learning algorithms specifically train deep learning framework used image classification caltech 101 collapsed version neuromorphic caltech 101 datasets obtained accuracy caltech 101 neuromorphic caltech 101 datasets respectively <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> work study impact relay node network finite number users sources destination node assume users saturated queues relay node does packets random access medium time slotted relay node stores source packet receives successfully queue transmission destination node failed relay destination nodes multi packet reception capabilities obtain analytical equations characteristics relay's queue average queue length stability conditions study throughput user aggregate throughput network <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> dependency parsing conversational input play important role language understanding dialog systems identifying relationships entities extracted user utterances additionally effective dependency parsing elucidate differences language structure usage discourse analysis human human versus human machine dialogs models trained datasets based news articles web data perform spoken human machine dialog currently available annotation schemes adapt dialog data propose spoken conversation universal dependencies scud annotation scheme extends universal dependencies ud nivre et al 2016 guidelines spoken human machine dialogs provide convbank conversation dataset humans open domain conversational dialog scud annotation finally demonstrate utility dataset train dependency parser convbank dataset demonstrate pre training dependency parser set larger public datasets fine tuning convbank data achieved best result unlabeled labeled attachment accuracy <end> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> online systems users purchase collect items kind effectively represented temporal bipartite networks nodes links added time use representation predict items popular near future various prediction methods evaluated distinct datasets originating popular online services movielens netflix digg prediction performance enhanced user social network known centrality individual users network used weight actions <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper efficient deployment multiple unmanned aerial vehicles uavs directional antennas acting wireless base stations provide coverage ground users analyzed downlink coverage probability uavs function altitude antenna gain derived using circle packing theory dimensional locations uavs determined way total coverage area maximized maximizing coverage lifetime uavs results order mitigate interference altitude uavs properly adjusted based beamwidth directional antenna coverage requirements furthermore minimum number uavs needed guarantee target coverage probability given geographical area determined <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> non local self similarity nss powerful prior natural images image denoising existing denoising methods employ similar patches patch level nss prior paper step forward introducing pixel level nss prior searching similar pixels non local region motivated fact finding closely similar pixels feasible similar patches natural images used enhance image denoising performance introduced pixel level nss prior propose accurate noise level estimation method develop blind image denoising method based lifting haar transform wiener filtering techniques experiments benchmark datasets demonstrate proposed method achieves better performance state art methods real world image denoising code released <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> neural generation methods task oriented dialogue typically generate meaning representation populated using database domain information table data describing restaurant earlier work focused solely semantic fidelity outputs recent work started explore methods controlling style generated text simultaneously achieving semantic accuracy experiment stylistic benchmark tasks generating language exhibits variation personality generating discourse contrast report huge performance improvement stylistic control semantic accuracy state art benchmarks test different models putting stylistic conditioning decoder eliminating semantic ranker used earlier models results 15 points higher bleu personality reduction semantic error near zero report improvement controlling contrast reduction semantic error 16 2 <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper address speaker independent multichannel speech enhancement unknown noisy environments work based established multichannel local gaussian modeling framework propose use neural network modeling speech spectro temporal content parameters supervised model learned using framework variational autoencoders noisy recording environment supposed unknown noise spectro temporal modeling remains unsupervised based non negative matrix factorization nmf develop monte carlo expectation maximization algorithm experimentally proposed approach outperforms nmf based counterpart speech modeled using supervised nmf <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> social media systems allow internet users congenial platform freely express thoughts opinions property represents incredible unique communication opportunities brings important challenges online hate speech archetypal example challenges despite magnitude scale significant gap understanding nature hate speech social media paper provide kind systematic large scale measurement study main targets hate speech online social media gather traces social media systems whisper twitter develop validate methodology identify hate speech systems results identify online hate speech forms offer broader understanding phenomenon providing directions prevention detection approaches <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper addresses task road safety assessment emerging approach conducting assessments united states road assessment program usrap rates roads highest risk 1 star lowest 5 stars obtaining ratings requires manual fine grained labeling roadway features street level panoramas slow costly process propose automate process using deep convolutional neural network directly estimates star rating street level panorama requiring milliseconds image test time network estimates road level attributes including curvature roadside hazards type median support incorporate task specific attention layers network focus panorama regions useful particular task evaluated approach large dataset real world images states incorporating additional tasks using semi supervised training approach significantly reduced overfitting problems allowed optimize layers network resulted higher accuracy <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> semantic compositional network scn developed image captioning semantic concepts tags detected image probability tag used compose parameters long short term memory lstm network scn extends weight matrix lstm ensemble tag dependent weight matrices degree member ensemble used generate image caption tied image dependent probability corresponding tag addition captioning images extend scn generate captions video clips qualitatively analyze semantic composition scns quantitatively evaluate algorithm benchmark datasets coco experimental results proposed method significantly outperforms prior state art approaches multiple evaluation metrics <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> article presents convolutional neural network automatic segmentation brain tumors multimodal mr images based u net evaluate use densely connected convolutional network encoder densenet pretrained imagenet data set network architectures account multiple images inputs work aims identify generic pretrained network used specific medical applications target data differ number spatial dimensions number inputs channels order regularize transfer learning task train decoder u net architecture evaluate effectiveness proposed approach brats 2018 segmentation challenge obtained dice scores hausdorff distance mm mm mm enhanced tumor core tumor tumor core respectively validation set scores degrades 95 hausdorff distance mm mm mm testing set <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> deep neural networks achieved extraordinary results image classification tasks shown vulnerable attacks carefully crafted perturbations input data attacks usually change values image's pixels shown deep networks vulnerable sparse alterations input computationally efficient method proposed compute sparse perturbations paper exploit low mean curvature decision boundary propose sparsefool geometry inspired sparse attack controls sparsity perturbations extensive evaluations approach computes sparse perturbations fast scales efficiently high dimensional data analyze transferability visual effects perturbations existence shared semantic information images networks finally adversarial training slightly improve robustness sparse additive perturbations computed sparsefool <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> propose novel pose robust spatial aware gan psgan transferring makeup style reference image source image previous gan based methods fail cases variant poses expressions adjust shade makeup specify transfer address issues proposed psgan includes makeup distillation network distill makeup style reference image spatial aware makeup matrices attentive makeup morphing module introduced specify pixel source image morphed reference image pixelwise correspondence built relative position features visual features based morphed makeup matrices makeup makeup network performs makeup transfer incorporating novelties psgan achieves state art results existing datasets able perform customizable shade controllable pose robust makeup transfer <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> recent research line obtained strong results bilingual lexicon induction aligning independently trained word embeddings languages using resulting cross lingual embeddings induce word translation pairs nearest neighbor related retrieval methods paper propose alternative approach problem builds recent work unsupervised machine translation way instead directly inducing bilingual lexicon cross lingual embeddings use build phrase table combine language model use resulting machine translation generate synthetic parallel corpus extract bilingual lexicon using statistical word alignment techniques method work word embedding cross lingual mapping technique does require additional resource monolingual corpus used train embeddings evaluated exact cross lingual embeddings proposed method obtains average improvement 6 accuracy points nearest neighbor 4 points csls retrieval establishing new state art standard muse dataset <end> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper extends fully convolutional neural networks fcn clothing parsing problem clothing parsing requires higher level knowledge clothing semantics contextual cues disambiguate fine grained categories extend fcn architecture branch network refer outfit encoder predict consistent set clothing labels encourage combinatorial preference conditional random field crf explicitly consider coherent label assignment given image empirical results using fashionista cfpd datasets model achieves state art performance clothing parsing additional supervision training study qualitative influence annotation current clothing parsing benchmarks web based tool multi scale pixel wise annotation manual refinement effort fashionista dataset finally image representation outfit encoder useful dress image retrieval application <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> study propose novel graph neural network called propagate selector ps propagates information sentences understand information inferred considering sentences isolation design graph structure node represents individual sentences pairs nodes selectively connected based text structure develop iterative attentive aggregation skip combine method node interacts neighborhood nodes accumulate necessary information evaluate performance proposed approaches conducted experiments hotpotqa dataset empirical results demonstrate superiority proposed approach obtains best performances compared widely used answer selection models consider inter sentential relationship <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper addresses automatic summarization videos unified manner particular propose framework multi faceted summarization extractive query base entity summarization summarization level entities like objects scenes humans faces video investigate summarization models capture notions diversity coverage representation importance argue utility different models depending application prior work submodular summarization approaches focused oncombining models learning weighted mixtures focus explainability different models featurizations apply different domains provide implementation details summarization systems different modalities involved hope study paper insights practitioners appropriately choose right summarization models problems hand <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> despite impactful variety problems applications generative adversarial nets gans remarkably difficult train issue formally analyzed propose alternative direction avoid caveats minmax player training gans corresponding algorithm called wasserstein gan wgan hinges continuity discriminator paper propose novel approach enforcing lipschitz continuity training procedure wgans approach seamlessly connects wgan recent semi supervised learning methods result gives rise better photo realistic samples previous methods state art semi supervised learning results particular approach gives rise inception score images exceeds accuracy 90 dataset using labeled images best knowledge <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> attention modules connecting encoder decoders widely applied field object recognition image captioning visual question answering neural machine translation significantly improves performance paper propose gated hierarchical attention gha mechanism image captioning proposed model employs cnn decoder able learn different concepts different layers apparently different concepts correspond different areas image develop gha low level concepts merged high level concepts simultaneously low level attended features pass make predictions gha significantly improves performance model applies level attention example cider score increases comparable state art models employ attributes boosting reinforcement learning rl conduct extensive experiments analyze cnn decoder proposed gha deeper decoders obtain better performance convolutional decoder deeper model likely collapse training <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> convolutional neural networks successfully applied various nlp tasks obvious model different linguistic patterns negation intensification clause compositionality help decision making process paper apply visualization techniques observe model capture different linguistic features features affect performance model later try identify model errors sources believe interpreting cnns step understand underlying semantic features raise awareness improve performance explainability cnn models <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> temporal action proposal generation challenging promising task aims locate temporal regions real world videos action event occur current proposal generation methods generate proposals precise boundary efficiently generate adequately reliable confidence scores retrieving proposals address difficulties introduce boundary matching bm mechanism evaluate confidence scores densely distributed proposals denote proposal matching pair starting ending boundaries combine densely distributed bm pairs bm confidence map based bm mechanism propose effective efficient end end proposal generation method named boundary matching network bmn generates proposals precise temporal boundaries reliable confidence scores simultaneously branches bmn jointly trained unified framework conduct experiments challenging datasets bmn shows significant performance improvement remarkable efficiency generalizability combining existing action classifier bmn achieve state art temporal action detection performance <end> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> propose approaches speaker adaptation end end automatic speech recognition systems kullback leibler divergence kld regularization multi task learning mtl approaches aim address data sparsity especially output target sparsity issue speaker adaptation systems kld regularization adapts model forcing output distribution adapted model close unadapted mtl utilizes jointly trained auxiliary task improve performance main task investigated approaches connectionist temporal classification ctc models different types output units experiments microsoft short message dictation task demonstrated mtl outperforms kld regularization particular mtl adaptation obtained relative word error rate reductions werrs supervised unsupervised adaptations word ctc model relative werrs mix unit ctc model respectively <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> mainly types state art object detectors hand stage detectors faster r cnn region based convolutional neural networks mask r cnn use region proposal network generate regions interests stage ii send region proposals pipeline object classification bounding box regression models reach highest accuracy rates typically slower hand single stage detectors yolo look ssd singe shot multibox detector treat object detection simple regression problem taking input image learning class probabilities bounding box coordinates models reach lower accuracy rates faster stage object detectors paper propose use image difficulty predictor achieve optimal trade accuracy speed object detection image difficulty predictor applied test images split easy versus hard images separated easy images sent faster single stage detector hard images sent accurate stage detector <end> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> dependency grammar induction task learning dependency syntax annotated training data traditional graph based models global inference achieve state art results task require run time transition based models enable faster inference time complexity performance lags work propose neural transition based parser dependency grammar induction inference procedure utilizes rich neural features time complexity train parser integration variational inference posterior regularization variance reduction techniques resulting framework outperforms previous unsupervised transition based dependency parsers achieves performance comparable graph based models english penn treebank universal dependency treebank empirical comparison approach substantially increases parsing speed graph based models <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> study unsupervised learning cnns optical flow estimation using proxy ground truth data supervised cnns immense learning capacity shown superior performance range computer vision problems including optical flow prediction require ground truth flow usually accessible limited synthetic data guidance ground truth optical flow unsupervised cnns perform worse naturally ill conditioned propose novel framework proxy ground truth data generated classical approaches used guide cnn learning models refined unsupervised fashion using image reconstruction loss guided learning approach competitive superior state art approaches standard benchmark datasets completely unsupervised run real time <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper summarizes work authors zero resource speech challenge organized technical program interspeech 2015 goal challenge discover linguistic units directly unlabeled speech data multi layered acoustic tokenizer mat proposed work automatically discovers multiple sets acoustic tokens given corpus acoustic token set specified set hyperparameters model configuration sets acoustic tokens carry different characteristics given corpus language mutually reinforced multiple sets token labels used targets multi target dnn mdnn trained low level acoustic features bottleneck features extracted mdnn used feedback mat mdnn iterative multi layered acoustic tokenizing deep neural network mat dnn generates high quality features track 1 challenge acoustic tokens track 2 challenge <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> records social interactions provide new sources data understanding interaction patterns affect collective dynamics human activity patterns bursty consist short periods intense activity followed long periods silence burstiness shown affect spreading phenomena accelerates epidemic spreading cases slows cases investigate model history dependent contagion <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> online hate speech proliferating organization countries implementing laws ban harmful speech restrictions reduce hateful content does restricting freedom speech promising alternative supported organizations counter hate speech speech paper analyze hate speech corresponding counters aka counterspeech twitter perform lexical linguistic psycholinguistic analysis user accounts obverse counter speakers employ strategies depending target community hateful accounts express negative sentiments profane hate tweets verified accounts virality compared tweet non verified account hate users use words envy hate negative emotion swearing terms ugliness counter users use words related government law leader build supervised model classifying hateful counterspeech accounts twitter obtain f score make dataset public help advance research hate speech <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper investigates maximum throughput rechargeable secondary user su sharing spectrum primary user pu plugged reliable power supply su maintains finite energy queue harvests energy natural resources solar wind acoustic noise propose probabilistic access strategy su based number packets energy queue investigate effect energy arrival rate energy energy packet capacity energy queue su throughput fading channels results reveal proposed access strategy enhance performance su <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> recently deep convolution networks dcnns applied task face alignment shown potential learning improved feature representations deeper layers capture abstract concepts like pose difficult capture geometric relationships keypoints dcnns paper propose novel convolution deconvolution network facial keypoint detection model predicts locations keypoints individual visibility head pose exploiting spatial relationships different keypoints different existing approaches modeling relationships propose learnable transform functions captures relationships keypoints feature level extensive variations pose relationships act propose pose based routing function implicitly models active relationships transform functions routing function implemented convolutions multi task framework approach presents single shot keypoint detection method making different existing cascade regression based methods learning relationships significantly improve accuracy keypoint detections wild face images challenging datasets afw aflw <end> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> traditional image recognition methods consider objects belonging learned classes training recognition model object class world unfeasible way getting information unknown objects objects class learned necessary way image recognition learn new classes asking human objects unknown paper propose method generating questions unknown objects image means information classes learned method consists module proposing objects module identifying unknown objects module generating questions unknown objects experimental results human evaluation method successfully information unknown objects image dataset code dataset available <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> probabilistic methods point set registration demonstrated competitive results recent years techniques estimate probability distribution model point clouds representation shown promise highly sensitive variations density points fundamental problem primarily caused changes sensor location point sets revisit foundations probabilistic registration paradigm contrary previous works model underlying structure scene latent probability distribution induce invariance point set density changes probabilistic model scene registration parameters inferred minimizing kullback leibler divergence expectation maximization based framework density adaptive registration successfully handles severe density variations commonly encountered terrestrial lidar applications perform extensive experiments challenging real world lidar datasets results demonstrate approach outperforms state art probabilistic methods multi view registration need sampling code available <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> deep learning approaches text sql generation limited wikisql dataset supports simple queries single table focus spider dataset complex cross domain text sql task includes complex queries multiple tables paper propose sql clause wise decoding neural architecture self attention based database schema encoder address spider task clause specific decoders consists set sub modules defined syntax clause additionally model works recursively support nested queries evaluated spider dataset approach achieves accuracy gain test dev sets respectively addition model significantly effective predicting complex nested queries previous work <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper studies problem congestion control scheduling ad hoc wireless networks support mixture best effort real time traffic optimization stochastic network theory successful designing architectures fair resource allocation meet long term throughput demands best knowledge strict packet delay deadlines considered framework previously paper propose model incorporating quality service qos requirements packets deadlines optimization framework solution problem results joint congestion control scheduling algorithm fairly allocates resources meet fairness objectives elastic inelastic flows packet delay requirements inelastic flows <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper investigate network densification influences performance downlink cellular network terms coverage probability cp area spectral efficiency ase instead simplified unbounded pathloss model upm apply realistic bounded pathloss model bpm model decay signal power caused pathloss shown network densification degrades cp base station bs density sufficiently large <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> convolutional neural networks cnns effective models reducing spectral variations modeling spectral correlations acoustic features automatic speech recognition asr hybrid speech recognition systems incorporating cnns hidden markov models gaussian mixture models hmms gmms achieved state art various benchmarks connectionist temporal classification ctc recurrent neural networks rnns proposed labeling unsegmented sequences makes feasible train end end speech recognition instead hybrid settings rnns computationally expensive difficult train paper inspired advantages cnns ctc approach propose end end speech framework sequence labeling combining hierarchical cnns ctc directly recurrent connections evaluating approach timit phoneme recognition task proposed model computationally efficient competitive existing baseline systems argue cnns capability model temporal correlations appropriate context information <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> need fast strong image cryptosystems motivates researchers develop new techniques apply traditional cryptographic primitives order exploit intrinsic features digital images popular mature technique use complex ynamic phenomena including chaotic orbits quantum walks generate required key stream paper assumption plaintext attacks investigate security classic diffusion mechanism variants used core cryptographic rimitive image cryptosystems based aforementioned complex dynamic phenomena theoretically regardless key schedule process data complexity recovering element equivalent secret key diffusion mechanisms proposed analysis validated means numerical examples additional cryptographic applications work discussed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> multimodal machine translation attractive application neural machine translation nmt helps computers deeply understand visual objects relations natural languages multimodal nmt systems suffer shortage available training data resulting poor performance translating rare words nmt pretrained word embeddings shown improve nmt low resource domains search based approach proposed address rare word problem study effectively combine approaches context multimodal nmt explore advantage pretrained word embeddings better translate rare words report overall performance improvements meteor bleu achieve improvement f score rare word translation <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> recognizing irregular text natural scene images challenging large variance text appearance curvature orientation distortion existing approaches rely heavily sophisticated model designs extra fine grained annotations extent increase difficulty algorithm implementation data collection work propose easy implement strong baseline irregular scene text recognition using shelf neural network components word level annotations composed resnet lstm based encoder decoder framework attention module despite simplicity proposed method robust achieves state art performance regular irregular scene text recognition benchmarks code available <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> recent introduction ict agriculture brought number changes way farming means use internet cloud big data bd automation gain better control process farming use technologies farms grown exponentially massive data production need develop use state art tools order gain insight data reasonable time paper present initial understanding convolutional neural network cnn recent architectures state art cnn underlying complexities propose classification taxonomy tailored agricultural application cnn finally present comprehensive review research dedicated applications state art cnns agricultural production systems <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> language evolves time ways relevant natural language processing tasks example recent occurrences tokens bert elmo publications refer neural network architectures persons type temporal signal typically overlooked important aims deploy machine learning model extended period time particular language evolution causes data drift time steps sequential decision making tasks examples tasks include prediction paper acceptance yearly conferences regular intervals author stance prediction rumours twitter irregular intervals inspired successes computer vision tackle data drift sequentially aligning learned representations evaluate challenging tasks varying terms time scales linguistic units domains tasks method outperforming strong baselines including using available data argue low computational expense sequential alignment practical solution dealing language evolution <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> extracting multi scale information key semantic segmentation classic convolutional neural networks cnns encounter difficulties achieving multi scale information extraction expanding convolutional kernel incurs high computational cost using maximum pooling sacrifices image information recently developed dilated convolution solves problems limitation dilation rates fixed receptive field fit objects different sizes image propose adaptivescale convolutional neural network ascnet introduces convolution structure end end training adaptively learn appropriate dilation rate pixel image pixel level dilation rates produce optimal receptive fields information objects different sizes extracted corresponding scale compare segmentation results using classic cnn dilated cnn proposed ascnet types medical images herlev dataset scd rbc dataset experimental results ascnet achieves highest accuracy <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> latest algorithms automatic neural architecture search perform remarkable basically directionless search space computational expensive training intermediate architecture paper propose method efficient architecture search called eena efficient evolution neural architecture elaborately designed mutation crossover operations evolution process guided information learned computational effort required searching training time reduced significantly classification eena using minimal computational resources gpu days design highly effective neural architecture achieves test error m parameters furthermore best architecture discovered transferable <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper introduce fusion dense slam takes live stream rgb d images input segments scene different objects using motion semantic cues simultaneously tracking reconstructing shape real time use multiple model fitting approach object independently background effectively tracked shape fused time using information pixels associated object label previous attempts deal dynamic scenes typically considered moving regions outliers consequently model shape track motion time contrast enable robot maintain models segmented objects improve time fusion result enable robot maintain scene description object level potential allow interactions working environment case dynamic scenes <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> study properties distance attractors random boolean networks prominent model genetic regulatory networks define distance measures attractor distance matrices constructed main statistic parameters computed experimental analysis shows ordered networks clustered set attractors chaotic networks attractors scattered critical networks instead pattern characteristics ordered chaotic networks <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> focuses green communication studies energy efficiency ee massive multiple input multiple output mimo systems massive mimo technology improve spectral efficiency se cellular networks configuring large number antennas base stations bss energy consumption radio frequency rf chains increases dramatically increment energy consumption caused increase rf chain number match antenna number massive mimo communication systems overcome problem generalized spatial modulation gsm solution presented simultaneously reduce number rf chains maintain se massive mimo communication systems ee model proposed estimate transmission computation power massive mimo communication systems gsm simulation results demonstrate ee massive mimo communication systems gsm outperforms massive mimo communication systems gsm computation power consumed massive mimo communication systems gsm effectively reduced <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> molecular communication biological entities new paradigm communications recently studied molecular communication nodes formed synthetic bacteria high randomness behavior bacteria used population node reliability communication systems depends maximum concentration molecules transmitter node able produce receiver node number bacteria nodes maximum concentration molecules falls distance makes communication far nodes nearly impossible order alleviate problem paper propose use molecular relaying node relay node resend message different type molecules original signal transmitter <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> propose graph based mechanism extract rich emotion bearing patterns fosters deeper analysis online emotional expressions corpus patterns enriched word embeddings evaluated emotion recognition tasks conduct analysis emotion oriented patterns demonstrate applicability explore properties experimental results demonstrate proposed techniques outperform state art emotion recognition techniques <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper propose new deep feature selection method based deep architecture method uses stacked auto encoders feature representation higher level abstraction developed applied novel feature learning approach specific precision medicine problem focuses assessing prioritizing risk factors hypertension htn vulnerable demographic subgroup african american approach use deep learning identify significant risk factors affecting left ventricular mass indexed body surface area lvmi indicator heart damage risk results feature learning representation approach leads better results comparison <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> search engines play important role everyday lives assisting finding information need input complex query results far satisfactory work introduce query reformulation based neural network rewrites query maximize number relevant documents returned train neural network reinforcement learning actions correspond selecting terms build reformulated query reward document recall evaluate approach datasets strong baselines relative improvement 5 20 terms recall furthermore present simple method estimate conservative upper bound performance model particular environment verify large room improvements <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> sports channel video portals offer exciting domain research multimodal multilingual analysis present methods addressing problem automatic video highlight prediction based joint visual features textual analysis real world audience discourse complex slang english traditional chinese present novel dataset based league legends championships recorded north american taiwanese channels released research demonstrate strong results using multimodal character level cnn rnn model architectures <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> training personalized dialogue requires lot data data collected single user usually insufficient common practice problem share training dialogues different users train multiple sequence sequence dialogue models transfer learning current sequence sequence transfer learning models operate entire sentence cause negative transfer different personal information different users mixed propose personalized decoder model transfer finer granularity phrase level knowledge different users keeping personal preferences user intact novel personal control gate introduced enabling personalized decoder switch generating personalized phrases shared phrases proposed personalized decoder model easily combined various deep models trained reinforcement learning real world experimental results demonstrate phrase level personalized decoder improves bleu multiple sentence level transfer baseline models <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> reading comprehension widely studied representative reading comprehension tasks stanford question answering dataset squad machine comparable human hand accessing large collections multimedia spoken content difficult time consuming plain text content humans it's highly attractive develop machines automatically understand spoken content paper propose new listening comprehension task spoken squad new task speech recognition errors catastrophic impact machine comprehension approaches proposed mitigate impact <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> computerized automatic methods employed boost productivity objectiveness hand bone age assessment approaches make predictions according x ray images include objects introduce distractions instead framework inspired clinical workflow tanner whitehouse hand bone age assessment focuses key components hand proposed framework composed components mask r cnn subnet pixelwise hand segmentation residual attention network hand bone age assessment mask r cnn subnet segments hands x ray images avoid distractions objects x ray tags hierarchical attention components residual attention subnet force network focus key components x ray images generate final predictions associated visual supports similar assessment procedure clinicians <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> present dataset large scale indoor spaces provides variety mutually registered modalities domains instance level semantic geometric annotations dataset covers contains rgb images corresponding depths surface normals semantic annotations global xyz images forms regular equirectangular images camera information includes registered raw semantically annotated meshes point clouds dataset enables development joint cross modal learning models potentially unsupervised approaches utilizing regularities present large scale indoor spaces dataset available <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper propose state art video denoising algorithm based convolutional neural network architecture previous neural network based approaches video denoising unsuccessful performance compete performance patch based methods approach outperforms patch based competitors significantly lower computing times contrast existing neural network denoisers algorithm exhibits desirable properties small memory footprint ability handle wide range noise levels single network model combination denoising performance lower computational load makes algorithm attractive practical denoising applications compare method different state art algorithms visually respect objective quality metrics experiments algorithm compares favorably state art methods video examples code models publicly available m tassano dvdnet <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> propose new learning based approach solve ill posed inverse problems imaging address case ground truth training samples rare problem severely ill posed underlying physics measurements setting common geophysical imaging remote sensing case common approach directly learn mapping measured data reconstruction unstable instead propose learn ensemble simpler mappings data projections unknown image random piecewise constant subspaces combine projections form final reconstruction solving deconvolution like problem experimentally proposed method robust measurement noise corruptions seen training directly learned inverse <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> existing approaches automatic verbnet style verb classification heavily dependent feature engineering limited languages mature nlp pipelines work propose novel cross lingual transfer method inducing verbnets multiple languages best knowledge study demonstrates architectures learning word embeddings applied challenging syntactic semantic task method uses cross lingual translation pairs tie target languages bilingual vector space english jointly specialising representations encode relational information english verbnet standard clustering algorithm run verbnet specialised representations using vector dimensions features learning verb classes results proposed cross lingual transfer approach sets new state art verb classification performance target languages explored work <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> fine scale short term cloud motion prediction needed applications including solar energy generation satellite communications tropical regions singapore clouds formed convection localized evolve quickly capture hemispherical images sky regular intervals time using ground based cameras provide high resolution localized cloud images use successive frames compute optical flow predict future location clouds achieve good prediction accuracy lead time 5 minutes <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> realistic image synthesis generate image perceptually indistinguishable actual image generating realistic looking images large variations large spatial deformations large pose change challenging handing large variations preserving appearance needs taken account realistic looking image generation paper propose novel realistic looking image synthesis method especially large change demands devise generative guiding blocks proposed generative guiding block includes realistic appearance preserving discriminator naturalistic variation transforming discriminator taking proposed generative guiding blocks generative model latent features layer generative model enhanced synthesize realistic target image qualitative quantitative evaluation experiments demonstrated effectiveness proposed generative guiding blocks compared state arts <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> tracking developments highly dynamic data technology landscape vital keeping novel technologies tools various areas artificial intelligence ai difficult track relevant technology keywords paper propose novel addresses problem tool used automatically detect existence new technologies tools text extract terms used new technologies extracted new terms logged new ai technologies fly web subsequently classified relevant semantic labels ai domains proposed tool based stage cascading model stage classifies sentence contains technology term second stage identifies technology keyword sentence obtain competitive accuracy tasks sentence classification text identification <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> robust dialogue belief tracking key component maintaining good quality dialogue systems tasks dialogue systems trying solve increasingly complex requiring scalability multi domain semantically rich dialogues current approaches difficulty scaling domains dependency model parameters dialogue ontology paper novel approach introduced fully utilizes semantic similarity dialogue utterances ontology terms allowing information shared domains evaluation performed recently collected multi domain dialogues dataset order magnitude larger currently available corpora model demonstrates great capability handling multi domain dialogues simultaneously outperforming existing state art models single domain dialogue tracking tasks <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> propose novel method selecting coherent diverse responses given dialogue context proposed method ranks response candidates generated conversational models using event causality relations events dialogue history response candidates stressed precedes relieve stress use distributed event representation based role factored tensor model robust matching event causality relations limited event causality knowledge experimental results showed proposed method improved coherency dialogue continuity responses <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> using sequence sequence framework neural conversation models chit chat succeed naturalness response neural conversation models tend generic responses specific given messages remains challenge alleviate tendency propose method promote message relevant diverse responses neural conversation model using self attention time efficient effective furthermore present investigation effective self attention deep comparison standard dialogue generation experiment results proposed method improves standard dialogue generation various evaluation metrics <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> screening applications primary goal radiologist assisting artificial intelligence rule certain findings classifiers built applications trained large datasets derive labels clinical notes written patients quality positive findings described notes reliable lack mention finding does rule presence happens radiologists comment patient context exam example focusing trauma opposed chronic disease emergency rooms disease finding ambiguity affect performance algorithms critical model ambiguity training propose scheme apply reasonable class weight modifiers loss function mention cases training experiment different deep neural network architectures proposed method results large improvement performance classifiers specially negated findings baseline performance custom dilated block network proposed paper shows improvement comparison baseline architectures benefit new proposed loss function weighting scheme <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper study resource allocation algorithm design multiuser orthogonal frequency division multiplexing ofdm downlink systems simultaneous wireless information power transfer algorithm design formulated non convex optimization problem maximizing energy efficiency data transmission bit joule delivered users particular problem formulation takes account minimum required data rate heterogeneous minimum required power transfers users circuit power consumption subsequently exploiting method time sharing properties nonlinear fractional programming considered non convex optimization problem solved using efficient iterative resource allocation algorithm iteration optimal power allocation user selection solution derived based lagrange dual decomposition simulation results illustrate proposed iterative resource allocation algorithm achieves maximum energy efficiency reveal energy efficiency capacity wireless power transfer benefit presence multiple users <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> best way define algorithmic fairness definitions fairness proposed computer science literature clear agreement particular definition work investigate ordinary people's perceptions fairness definitions online experiments test definitions people perceive fairest context loan decisions fairness perceptions change addition sensitive information race loan applicants overall definition calibrated fairness tends preferred results provide support principle affirmative action <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> training transition based dependency parsers oracle used predict transition sequence sentence gold tree transition exhibit ambiguity multiple correct transition sequences form gold tree propose make use property training neural dependency parsers present hybrid oracle new oracle gives correct transitions parsing state used cross entropy loss function provide better supervisory signal used generate different transition sequences sentence better explore training data improve generalization ability parser evaluations parsers trained using hybrid oracle outperform parsers using traditional oracle chinese dependency parsing <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> present machine learning algorithm takes input rgb image synthesizes rgbd light field color depth scene ray direction training introduce largest public light field dataset consisting 3300 plenoptic camera light fields scenes containing flowers plants synthesis pipeline consists convolutional neural network cnn estimates scene geometry stage renders lambertian light field using geometry second cnn predicts occluded rays non lambertian effects algorithm builds recent view synthesis methods unique predicting rgbd light field ray improving unsupervised single image depth estimation enforcing consistency ray depths intersect scene point supplementary video <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> saliency detection active topic multimedia field previous works saliency detection focus images methods robust complex scenes contain multiple objects complex backgrounds recently depth information supplies powerful cue saliency detection paper propose multilayer backpropagation saliency detection algorithm based depth mining exploit depth cue different layers images proposed algorithm shows good performance maintains robustness complex situations experiments results proposed framework superior existing saliency approaches innovative applications algorithm scene reconstruction multiple images small target object detection video <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> undersampling k space data widely adopted acceleration magnetic resonance imaging mri current deep learning based approaches supervised learning mri image reconstruction employ real valued operations representations treating complex valued k space spatial space real values paper propose complex dense fully convolutional neural network learning alias reconstruction artifacts undersampled mri images fashioned densely connected fully convolutional block tailored complex valued inputs introducing dedicated layers complex convolution batch normalization non linearities leverages inherently complex valued nature input k space learns richer representations demonstrate improved perceptual quality recovery anatomical structures contrast real valued counterparts <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> hand body pose estimation task depth image novel anchor based approach termed anchor joint regression network end end learning ability proposed anchor points able capture global local spatial context information densely set depth image local regressors joints contribute predict positions joints ensemble way enhance generalization ability proposed articulated pose estimation paradigm different state art encoder decoder based fcn cnn point set based manners discover informative anchor points certain joint anchor proposal procedure proposed cnn used backbone network drive using time consuming convolutional deconvolutional layers experiments 3 hand datasets 2 body datasets verify superiority high running speed 100 fps single nvidia gpu <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> batching essential technique improve computation efficiency deep learning frameworks batch processing models static feed forward computation graphs straightforward implement batching dynamic computation graphs syntax trees social network graphs challenging variable computation graph structure samples simulation analysis tree lstm model key trade graph analysis time batching effectiveness dynamic batching based finding propose dynamic batching method extension mxnet gluon's just time compilation jit framework empirically method yields times speed common dynamic workload tree lstm model semantic relatedness task <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> question answering task requires building models capable providing answers questions expressed human language question answering involves form reasoning ability introduce neural network architecture task form recognizes entities relations answers focus attention mechanism model named extends exploiting aspects question memorization process validate model synthetic real datasets question answering dataset dataset experiments models achieved state art competitive results <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> machine learning used number security related applications biometric user authentication speaker identification type causative integrity attack machine learning called poisoning attack works injecting specially crafted data points training data increase false positive rate classifier context biometric authentication means intruders classified valid user case speaker identification user classified user paper examine poisoning attack svm introduce curie method protect svm classifier poisoning attack basic idea method identify poisoned data points injected adversary filter method light weight easily integrated existing systems experimental results works filtering poisoned data <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> unlike white box counterparts widely studied readily accessible adversarial examples black box settings generally herculean account difficulty estimating gradients methods achieve task issuing numerous queries target classification systems makes procedure costly suspicious systems paper aim reducing query complexity black box attacks category propose exploit gradients reference models arguably span promising search subspaces experimental results comparison state arts method gain reductions requisite mean medium numbers queries lower failure rates reference models trained small inadequate dataset disjoint training victim model code models reproducing results publicly available <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper present deep reinforcement learning rl framework iterative dialog policy optimization end end task oriented dialog systems popular approaches learning dialog policy rl include letting dialog agent learn user simulator building reliable user simulator trivial difficult building good dialog agent address challenge jointly optimizing dialog agent user simulator deep rl simulating dialogs agents bootstrap basic dialog agent basic user simulator learning directly dialog corpora supervised training improve letting agents conduct task oriented dialogs iteratively optimizing policies deep rl dialog agent user simulator designed neural network models trained end end experiment results proposed method leads promising improvements task success rate total task reward comparing supervised training single agent rl training baseline models <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> emerging trend generating embeddings primarily unstructured data recently structured data systematic suite measuring quality embeddings deficiency sensed respect embeddings generated structured data concrete evaluation metrics measuring quality encoded structure semantic patterns embedding space paper introduce framework containing distinct tasks concerned individual aspects ontological concepts categorization aspect ii hierarchical aspect iii relational aspect scope task number intrinsic metrics proposed evaluating quality embeddings furthermore framework multiple experimental studies run compare quality available embedding models employing framework future research reduce misjudgment provide greater insight quality comparisons embeddings ontological concepts <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> paper address problem classifying documents available global network open access repositories according type metadata provided repositories enabling distinguish research papers thesis slides missing 60 cases metadata describing document types useful variety scenarios ranging research analytics improving search recommender sr systems problem sufficiently addressed context repositories infrastructure developed new approach classifying document types using supervised machine learning based exclusively text specific features achieve using random forest adaboost classifiers best performing models data analysing sr logs core 1 digital library aggregator users order magnitude likely click research papers thesis slides suggests using document types feature ranking filtering sr results digital libraries potential improve user experience <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> having reliable accuracy score crucial real world applications ocr systems judged number false readings lexicon based ocr systems deal essentially multi class classification problem employ methods explicitly taking account lexicon order improve accuracy lexicon free scenarios filtering errors requires explicit confidence calculation work explicit confidence measurement techniques able achieve significant reduction misreads standard benchmarks proprietary dataset <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "pred:  neural neural networks networks effective models models variations variations modeling modeling models models models automatic generated asr asr hybrid speech recognition recognition cnns cnns hidden markov models mixture mixture mixture gmms gmms state state art art benchmarks models models news connections recurrent recurrent neural rnns rnns rnns sequences sequences feasible feasible train end end improved sequences hybrid hybrid settings rnns expensive expensive expensive train train inspired advantages hybrid ctc ctc end train end learning sequence sequence sequence combining combining hierarchical ctc recurrent recurrent recurrent evaluating approach train train train train train computationally computationally computationally competitive competitive improves dependency dependency capability capability points points correlations appropriate context <end> <end> <end> result result unlabeled datasets <end> <end> <end> <end> <end> <end> <end> \n",
      "abstract:  <start> study presents systems submitted university texas dallas center robust speech systems utd crss arabic dialect identification adi subtask task defined discriminate dialects arabic including egyptian gulf levantine north african modern standard arabic develop multiple single systems different end representations end classifiers end level feature extraction methods mel frequency cepstral coefficients mfccs types bottleneck features bnf studied vector framework end level gaussian end gb generative adversarial networks gans classifiers applied alternately best submission contrastive achieved adi subtask accuracy augmenting randomly chosen development dataset post evaluation correction submitted final accuracy increased represents best performance achieved far challenge test dataset <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "def decode(preds, abstracts):\n",
    "    pred_ids = preds.argmax(1)\n",
    "    for i in range(len(pred_ids)):\n",
    "        sentence = \"\"\n",
    "        sentence2 = \"\"\n",
    "        for j in range(ABSTRACT_MAX):\n",
    "            sentence += abstract_vocab.get_word(pred_ids[i][j].item()) + \" \"\n",
    "            sentence2 += abstract_vocab.get_word(abstracts[i][j].item()) + \" \"\n",
    "        print(\"pred: \",sentence)\n",
    "        print(\"abstract: \",sentence2)\n",
    "def get_accuracy2(preds, abstracts):\n",
    "#     print(\"preds: \", preds.shape)\n",
    "#     print(\"abstracts:\", abstracts.shape)\n",
    "    pred_ids = preds.argmax(1)\n",
    "\n",
    "    correct_preds = (pred_ids == abstracts).sum().item()\n",
    "    # Calculate the total number of samples\n",
    "    total_samples = abstracts.shape[0] * abstracts.shape[1]\n",
    "    \n",
    "    # Calculate accuracy as the ratio of correct predictions to total samples\n",
    "    accuracy = correct_preds / total_samples\n",
    "    return accuracy\n",
    "with torch.no_grad():\n",
    "    for i, (abstract, text) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "        text = text.to(device)\n",
    "        abstract = abstract.to(device)\n",
    "        # Encode the input sequence\n",
    "        #encoder_output = model.EncoderNet(text)\n",
    "        #print(encoder_output)\n",
    "        # Initialize the initial prediction as the input sequence\n",
    "        initial_prediction = torch.full((1,120), 0, device=device)\n",
    "        initial_prediction[:,0]=1\n",
    "        #print(abstract)\n",
    "        #print(initial_prediction[:,:1])\n",
    "        \n",
    "        # Iterative refinement\n",
    "\n",
    "#             print(text)\n",
    "#             print(abstract)\n",
    "        for i in range(1,120):\n",
    "            outputs = model(text, abstract=initial_prediction[:,:i]).to(device).permute(1,2,0)\n",
    "            #print(\"output\",output.argmax(1))\n",
    "            initial_prediction[:,i] = output.argmax(1)[0][i]\n",
    "            \n",
    "            #print(output.shape)\n",
    "            # Apply temperature for sampling diversity\n",
    "            #output = output #/ temperature\n",
    "            # Apply softmax to get token probabilities\n",
    "            #probs = nn.functional.softmax(output, dim=1)\n",
    "            \n",
    "            # Perform beam search or sampling\n",
    "            # Greedy sampling (beam width of 1)\n",
    "            \n",
    "            #print(sampled_tokens.shape)\n",
    "            # Update the initial prediction for the next iteration\n",
    "            #initial_prediction = sampled_tokens\n",
    "        decode(output, abstract)\n",
    "    \n",
    "        #print(get_accuracy2(initial_prediction, abstract))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5d16eb894b401d9c01ab172c3440d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.7763e-01,  1.7719e-01, -1.1044e-01,  ...,  1.2027e-01,\n",
      "          -1.5995e+00,  3.2670e-01],\n",
      "         [ 2.1302e-01,  4.1242e-01, -2.2151e-01,  ...,  3.7272e-01,\n",
      "          -1.8935e+00,  3.5134e-01],\n",
      "         [ 5.5395e-01,  2.1600e-01, -7.0079e-01,  ...,  3.0029e-01,\n",
      "          -1.6553e+00,  4.9349e-01],\n",
      "         ...,\n",
      "         [ 4.9942e-01,  5.0533e-01, -4.5806e-01,  ..., -2.7786e-01,\n",
      "          -2.0292e+00,  4.9953e-01],\n",
      "         [-4.2056e-01,  4.2882e-01,  2.1639e-01,  ..., -1.9038e-02,\n",
      "          -1.8020e+00,  3.4817e-01],\n",
      "         [-2.6610e-01,  5.8974e-01,  2.4825e-01,  ...,  2.7032e-02,\n",
      "          -1.9835e+00,  3.2657e-01]],\n",
      "\n",
      "        [[ 1.6377e+00, -7.1653e-01,  1.4578e+00,  ...,  1.4358e-01,\n",
      "          -1.7934e+00,  5.6160e-01],\n",
      "         [ 1.4888e+00, -6.6770e-01,  1.3402e+00,  ...,  2.5333e-01,\n",
      "          -2.2955e+00,  6.5187e-01],\n",
      "         [ 1.9631e+00, -9.5902e-01,  6.4610e-01,  ...,  3.7765e-01,\n",
      "          -1.8855e+00,  6.7810e-01],\n",
      "         ...,\n",
      "         [ 1.9492e+00, -6.5100e-01,  9.8728e-01,  ..., -2.0614e-01,\n",
      "          -2.4600e+00,  7.8166e-01],\n",
      "         [ 1.0874e+00, -4.9346e-01,  1.7939e+00,  ...,  1.2011e-01,\n",
      "          -2.1215e+00,  4.0302e-01],\n",
      "         [ 1.1335e+00, -3.4019e-01,  1.6609e+00,  ...,  2.9157e-01,\n",
      "          -2.2161e+00,  3.1145e-01]],\n",
      "\n",
      "        [[ 1.6504e+00, -2.3392e+00,  2.0821e+00,  ...,  3.9907e-01,\n",
      "          -2.0619e+00,  5.8639e-01],\n",
      "         [ 1.7026e+00, -2.2578e+00,  1.7882e+00,  ...,  2.8956e-01,\n",
      "          -2.2997e+00,  5.5325e-01],\n",
      "         [ 1.9674e+00, -2.3753e+00,  1.0091e+00,  ..., -4.9742e-02,\n",
      "          -1.9203e+00,  8.5171e-01],\n",
      "         ...,\n",
      "         [ 1.9661e+00, -2.1491e+00,  1.6302e+00,  ..., -1.0231e-01,\n",
      "          -2.4869e+00,  4.4866e-01],\n",
      "         [ 1.1069e+00, -2.0445e+00,  2.2578e+00,  ...,  2.6810e-01,\n",
      "          -2.3775e+00,  2.3077e-01],\n",
      "         [ 1.3149e+00, -2.0374e+00,  2.1432e+00,  ...,  3.0704e-01,\n",
      "          -2.3516e+00,  7.2179e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.5893e-01, -1.6778e+00, -7.3297e-01,  ..., -7.6415e-01,\n",
      "           4.6095e-01, -1.7977e-02],\n",
      "         [ 4.9741e-01, -1.6963e+00, -8.0980e-01,  ..., -7.2335e-01,\n",
      "           3.0370e-01, -1.2364e-01],\n",
      "         [ 6.2055e-01, -1.7311e+00, -1.1672e+00,  ..., -8.0804e-01,\n",
      "           3.2604e-01, -1.7298e-01],\n",
      "         ...,\n",
      "         [ 8.2832e-01, -1.7475e+00, -6.9636e-01,  ..., -9.5980e-01,\n",
      "           3.1690e-01, -2.1393e-02],\n",
      "         [ 4.1518e-01, -1.6804e+00, -5.0365e-01,  ..., -8.2115e-01,\n",
      "           3.5269e-01, -3.3921e-02],\n",
      "         [ 4.9671e-01, -1.6524e+00, -5.1164e-01,  ..., -8.4765e-01,\n",
      "           3.1217e-01, -1.0662e-03]],\n",
      "\n",
      "        [[-3.8532e-01, -2.1581e+00,  2.7124e-01,  ..., -6.5225e-01,\n",
      "           6.5181e-01,  1.1538e-01],\n",
      "         [-4.5752e-01, -2.1734e+00,  2.3114e-01,  ..., -6.2340e-01,\n",
      "           5.3212e-01,  4.9979e-02],\n",
      "         [-3.6793e-01, -2.2482e+00, -1.5155e-01,  ..., -6.7947e-01,\n",
      "           5.3728e-01,  7.9954e-03],\n",
      "         ...,\n",
      "         [-3.3628e-01, -2.2922e+00,  1.9116e-01,  ..., -7.0636e-01,\n",
      "           5.0789e-01,  8.2264e-02],\n",
      "         [-5.3208e-01, -2.1583e+00,  3.3884e-01,  ..., -6.4528e-01,\n",
      "           5.6705e-01,  6.3069e-02],\n",
      "         [-4.8034e-01, -2.1319e+00,  3.3121e-01,  ..., -6.5876e-01,\n",
      "           5.1828e-01,  7.9260e-02]],\n",
      "\n",
      "        [[-1.5796e+00, -1.3258e+00,  1.1931e+00,  ..., -5.8038e-01,\n",
      "           7.7199e-01,  3.2644e-01],\n",
      "         [-1.6050e+00, -1.3499e+00,  1.1500e+00,  ..., -5.4276e-01,\n",
      "           6.5624e-01,  2.8475e-01],\n",
      "         [-1.5095e+00, -1.5037e+00,  7.7109e-01,  ..., -6.2105e-01,\n",
      "           6.9508e-01,  2.9209e-01],\n",
      "         ...,\n",
      "         [-1.5761e+00, -1.5300e+00,  1.0980e+00,  ..., -5.7729e-01,\n",
      "           6.9275e-01,  3.0227e-01],\n",
      "         [-1.6845e+00, -1.3746e+00,  1.2184e+00,  ..., -5.5100e-01,\n",
      "           7.2571e-01,  2.8643e-01],\n",
      "         [-1.6391e+00, -1.3041e+00,  1.2053e+00,  ..., -5.6393e-01,\n",
      "           6.4164e-01,  2.7618e-01]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (8) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [8]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mEncoderNet(text\u001b[38;5;241m.\u001b[39mto(device)))\n\u001b[0;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m120\u001b[39m), \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m----> 7\u001b[0m outputs[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m abstract[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(abstract_vocab\u001b[38;5;241m.\u001b[39mget_word(outputs[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(abstract_vocab\u001b[38;5;241m.\u001b[39mget_word(abstract[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (8) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [8]"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (abstract, text) in tqdm(enumerate(train_loader), total=len(test_loader)):\n",
    "        print(model.EncoderNet(text.to(device)))\n",
    "        outputs = torch.full((1,120), 1, device=device)\n",
    "        outputs[:,0] = abstract[:,0]\n",
    "        print(abstract_vocab.get_word(outputs[:,0].item()))\n",
    "        print(abstract_vocab.get_word(abstract[:,1].item()))\n",
    "        text = text.to(device)\n",
    "        abstract = abstract.to(device)\n",
    "        #print(outputs)\n",
    "        for i in range(1, 120):\n",
    "            print(outputs.shape)\n",
    "            preds = model(text, outputs)\n",
    "            #print(\"output\", preds.shape)\n",
    "\n",
    "            next_tokens = preds[:, -1, :].argmax(dim=-1).unsqueeze(1)\n",
    "            print(next_tokens.shape)\n",
    "#             for tok in next_tokens:\n",
    "#                 print(abstract_vocab.get_word(tok.item()))\n",
    "            #print(\"token\",next_tokens)\n",
    "            #print(next_tokens[i])\n",
    "        \n",
    "#             outputs[i] = next_tokens[i]\n",
    "#             sentence = \"\"\n",
    "#             sentence2 = \"\"\n",
    "            outputs = torch.cat((outputs, next_tokens), dim=-1)\n",
    "        \n",
    "        for j in range(120):\n",
    "              \n",
    "            sentence += abstract_vocab.get_word(abstract[0][j].item()) + \" \"\n",
    "            sentence2 += abstract_vocab.get_word(outputs[j].item()) + \" \"\n",
    "        print(\"abs: \",sentence)\n",
    "        print(\"\")\n",
    "        print(\"pred: \",sentence2)\n",
    "        print(\"\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(preds, abstracts):\n",
    "    pred_ids = preds.argmax(1)\n",
    "    for i in range(len(pred_ids)):\n",
    "        sentence = \"\"\n",
    "        sentence2 = \"\"\n",
    "        for j in range(ABSTRACT_MAX):\n",
    "            sentence += abstract_vocab.get_word(pred_ids[i][j].item()) + \" \"\n",
    "            sentence2 += abstract_vocab.get_word(abstracts[i][j].item()) + \" \"\n",
    "        print(\"pred: \",sentence)\n",
    "        print(\"abstract: \",sentence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train fasttext model\n",
    "obtain weight from fasttest\n",
    "then embedding can load weights\n",
    "\n",
    "- train 2 fasttext model, 1 for text and another for abstract\n",
    "- obtain weights for both vocab\n",
    "- put in encoder and decoder like normal\n",
    "- https://stackoverflow.com/questions/31440803/how-to-fetch-vectors-for-a-word-list-with-word2vec\n",
    "- use this to update the vocab class to update ways to fetch words\n",
    "- to solve querying, use the model and use function to find cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_unsupervised('data/fil9')\n",
    "model.save_model(\"result/fil9.bin\")\n",
    "model = fasttext.load_model(\"result/fil9.bin\")\n",
    "# EXPECTS TEXT FILE FORMAT WHERE 1 TEXT PER ROW\n",
    "# IMPORTANT, NEED TO REDESIGN CLEANING PROCESS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring, all highlight:article ratio being more than 1.0 means the summary text is producing more text than the original text, this defeats the purpose of the model, therefore all data with a ratio of more than or equal to 1.0 will be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model improvement/Retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Finalisation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"my_model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "best_model_path = \"best_decoder20230719.pth\"\n",
    "best_model = Model(len(text_vocab),len(abstract_vocab),2,256)\n",
    "best_model.load_state_dict(torch.load(best_model_path))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5623M_CW1_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
