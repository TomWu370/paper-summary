{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR4bovYL4CJz"
   },
   "source": [
    "## Dissertation Project - News Summary Dissertation [100 marks]\n",
    "\n",
    "### Motivation \n",
    "\n",
    "> 1. Provide tools for anyone needing to speed up their research process\n",
    "> 2. Providing ways for user to quickly determine whether a piece of research is beneficial for their specific search terms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import string\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import json\n",
    "\n",
    "DATASET = \"./Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect which device (CPU/GPU) to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Summarisation model\n",
    "> 1. Dataset preprocessing\n",
    "> 2. Dataloader\n",
    "> 3. RNN model definition\n",
    "> 4. Model training\n",
    "> 5. Model prediction evaluation\n",
    "> 6. Dataset Exploration\n",
    "> 7. Dataset modification/Data Augmentation\n",
    "> 8. Model improvement\n",
    "> 9. Model finalisation and evaluation\n",
    "\n",
    "Paper querying\n",
    "> 1. Attention on query (Return usefulness percentage\n",
    "> 2. Evaluate performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [introduction, tree boosting in a nutshell, re...\n",
       "1         [introduction, previous work, our approach, su...\n",
       "2         [introduction, modulation instability of becs ...\n",
       "3         [introduction, preliminaries, polynomials and ...\n",
       "4         [introduction, a comment on the large nn and n...\n",
       "                                ...                        \n",
       "140794    [introduction, quantum information theory prel...\n",
       "140795    [introduction, statement of results, an obstru...\n",
       "140796    [introduction, msugra, more general models, co...\n",
       "140797    [introduction, pca by determinant optimisation...\n",
       "140798    [introduction, turbulent convective flux of me...\n",
       "Name: section_names, Length: 140799, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Comment this block if dataset is reorganised\n",
    "# DATA_DIR = \"SSN/papers.SSN.jsonl\"\n",
    "# dataset_path = DATASET+DATA_DIR\n",
    "# with open(dataset_path) as f:\n",
    "#     lines = f.read().splitlines()\n",
    "# df_inter = pd.DataFrame(lines)\n",
    "# df_inter.columns = ['json_element']\n",
    "# df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "# df_final.to_json(\"./Dataset/SSN/SSN_Dataset.json\")\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# for i,summary in df_final.iterrows():\n",
    "#     temp = summary[\"abstract\"]\n",
    "#     print(type(summary[\"abstract\"]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Comment this block if dataset is shortened\n",
    "# DATA_DIR = \"SSN/SSN_Dataset.json\"\n",
    "# dataset_path = DATASET+DATA_DIR\n",
    "# df = pd.read_json(dataset_path)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return index for conclusion section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trim_index(row):\n",
    "#     return [row.index(x)+1 for x in row if x.startswith('conclusion') or x.startswith(\"summar\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trim_text(text, index):\n",
    "#     return text[0:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49413\n"
     ]
    }
   ],
   "source": [
    "# # Comment this block if dataset is shortened\n",
    "# # Trim text after conclusion\n",
    "# indexes = []\n",
    "# for i, row in df.iterrows():\n",
    "#     section = row[\"section_names\"]\n",
    "#     #print(section)\n",
    "#     index = trim_index(section)\n",
    "#     #print(index)\n",
    "#     if not index:\n",
    "#         indexes.append(i)\n",
    "#     # if section can be filtered\n",
    "#     else:\n",
    "#         index = index[0]\n",
    "#         abstract = row[\"abstract\"]\n",
    "#         text = row[\"text\"]\n",
    "#         section = row[\"section_names\"]\n",
    "#         df.at[i, \"section_names\"] = trim_text(section, index)\n",
    "#         df.at[i, \"abstract\"] = trim_text(abstract, index)\n",
    "#         df.at[i, \"text\"] = trim_text(text, index)\n",
    "# # dropping rows in dataframe that can't easily filter out reference section\n",
    "# print(len(indexes))\n",
    "# df.drop(indexes, inplace=True)\n",
    "# df.to_json(\"./Dataset/SSN/SSN_Dataset_Short.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35% of paper will be removed from the dataset due to it not having conclusion(s) and summary(ies) in their section titles, making it difficult to filter out the reference and appendix text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>section_names</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4650265</td>\n",
       "      <td>XGBoost: A Scalable Tree Boosting System</td>\n",
       "      <td>[tree boosting is a highly effective and widel...</td>\n",
       "      <td>[introduction, tree boosting in a nutshell, re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[machine learning and data - driven approache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9195903</td>\n",
       "      <td>Robust Face Alignment Using a Mixture of Invar...</td>\n",
       "      <td>[face alignment , which is the task of finding...</td>\n",
       "      <td>[introduction, previous work, our approach, su...</td>\n",
       "      <td>[Computer science]</td>\n",
       "      <td>[[face alignment refers to finding the pixel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119332442</td>\n",
       "      <td>Modulation instability associated nonlinear dy...</td>\n",
       "      <td>[we study pattern - forming nonlinear dynamics...</td>\n",
       "      <td>[introduction, modulation instability of becs ...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[modulation instability ( mi ) is one of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119269876</td>\n",
       "      <td>Light Dilaton at Fixed Points and Ultra Light ...</td>\n",
       "      <td>[we investigate the infrared dynamics of a non...</td>\n",
       "      <td>[introduction, a comment on the large nn and n...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[understanding strong dynamics constitutes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59413881</td>\n",
       "      <td>Decoder-tailored Polar Code Design Using the G...</td>\n",
       "      <td>[we propose a new framework for constructing p...</td>\n",
       "      <td>[introduction, polar codes, polar code constru...</td>\n",
       "      <td>[Computer science, Mathematics]</td>\n",
       "      <td>[[polar codes   are the first family of codes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91381</th>\n",
       "      <td>1520660</td>\n",
       "      <td>Dirichlet Process Mixtures of Generalized Line...</td>\n",
       "      <td>[we propose dirichlet process mixtures of gene...</td>\n",
       "      <td>[introduction, related work, mathematical back...</td>\n",
       "      <td>[Mathematics, Computer science]</td>\n",
       "      <td>[[in this paper , we examine the general regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91382</th>\n",
       "      <td>118501110</td>\n",
       "      <td>Minimal Matter at the Large Hadron Collider</td>\n",
       "      <td>[we classify all possible new u(1 ) x su(2 ), ...</td>\n",
       "      <td>[introduction, new matter and its production, ...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[the higgs mass hierarchy puzzle suggests new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91383</th>\n",
       "      <td>16180248</td>\n",
       "      <td>On simulations of the classical harmonic oscil...</td>\n",
       "      <td>[we show that any second order linear ordinary...</td>\n",
       "      <td>[introduction, simplest discretizations of the...</td>\n",
       "      <td>[Physics, Mathematics]</td>\n",
       "      <td>[[the motivation for writing this paper is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91384</th>\n",
       "      <td>15296646</td>\n",
       "      <td>Direct Detection of Neutralino Dark Matter and...</td>\n",
       "      <td>[we compare predictions for the spin - indepen...</td>\n",
       "      <td>[introduction, msugra, more general models, co...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[the minimal supersymmetric standard model ( ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91385</th>\n",
       "      <td>119301470</td>\n",
       "      <td>Turbulent fluxes of entropy and internal energ...</td>\n",
       "      <td>[we derive equations for the mean entropy and,...</td>\n",
       "      <td>[introduction, turbulent convective flux of me...</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[[temperature stratified turbulence ( e.g. , t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91386 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper_id                                              title  \\\n",
       "0        4650265           XGBoost: A Scalable Tree Boosting System   \n",
       "1        9195903  Robust Face Alignment Using a Mixture of Invar...   \n",
       "2      119332442  Modulation instability associated nonlinear dy...   \n",
       "3      119269876  Light Dilaton at Fixed Points and Ultra Light ...   \n",
       "4       59413881  Decoder-tailored Polar Code Design Using the G...   \n",
       "...          ...                                                ...   \n",
       "91381    1520660  Dirichlet Process Mixtures of Generalized Line...   \n",
       "91382  118501110        Minimal Matter at the Large Hadron Collider   \n",
       "91383   16180248  On simulations of the classical harmonic oscil...   \n",
       "91384   15296646  Direct Detection of Neutralino Dark Matter and...   \n",
       "91385  119301470  Turbulent fluxes of entropy and internal energ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      [tree boosting is a highly effective and widel...   \n",
       "1      [face alignment , which is the task of finding...   \n",
       "2      [we study pattern - forming nonlinear dynamics...   \n",
       "3      [we investigate the infrared dynamics of a non...   \n",
       "4      [we propose a new framework for constructing p...   \n",
       "...                                                  ...   \n",
       "91381  [we propose dirichlet process mixtures of gene...   \n",
       "91382  [we classify all possible new u(1 ) x su(2 ), ...   \n",
       "91383  [we show that any second order linear ordinary...   \n",
       "91384  [we compare predictions for the spin - indepen...   \n",
       "91385  [we derive equations for the mean entropy and,...   \n",
       "\n",
       "                                           section_names  \\\n",
       "0      [introduction, tree boosting in a nutshell, re...   \n",
       "1      [introduction, previous work, our approach, su...   \n",
       "2      [introduction, modulation instability of becs ...   \n",
       "3      [introduction, a comment on the large nn and n...   \n",
       "4      [introduction, polar codes, polar code constru...   \n",
       "...                                                  ...   \n",
       "91381  [introduction, related work, mathematical back...   \n",
       "91382  [introduction, new matter and its production, ...   \n",
       "91383  [introduction, simplest discretizations of the...   \n",
       "91384  [introduction, msugra, more general models, co...   \n",
       "91385  [introduction, turbulent convective flux of me...   \n",
       "\n",
       "                                domain  \\\n",
       "0                                   []   \n",
       "1                   [Computer science]   \n",
       "2                            [Physics]   \n",
       "3                            [Physics]   \n",
       "4      [Computer science, Mathematics]   \n",
       "...                                ...   \n",
       "91381  [Mathematics, Computer science]   \n",
       "91382                        [Physics]   \n",
       "91383           [Physics, Mathematics]   \n",
       "91384                        [Physics]   \n",
       "91385                        [Physics]   \n",
       "\n",
       "                                                    text  \n",
       "0      [[machine learning and data - driven approache...  \n",
       "1      [[face alignment refers to finding the pixel l...  \n",
       "2      [[modulation instability ( mi ) is one of the ...  \n",
       "3      [[understanding strong dynamics constitutes a ...  \n",
       "4      [[polar codes   are the first family of codes ...  \n",
       "...                                                  ...  \n",
       "91381  [[in this paper , we examine the general regre...  \n",
       "91382  [[the higgs mass hierarchy puzzle suggests new...  \n",
       "91383  [[the motivation for writing this paper is an ...  \n",
       "91384  [[the minimal supersymmetric standard model ( ...  \n",
       "91385  [[temperature stratified turbulence ( e.g. , t...  \n",
       "\n",
       "[91386 rows x 6 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"SSN/SSN_Dataset_Short.json\"\n",
    "dataset_path = DATASET+DATA_DIR\n",
    "df = pd.read_json(dataset_path)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tree boosting is a highly effective and widel...</td>\n",
       "      <td>[[machine learning and data - driven approache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[face alignment , which is the task of finding...</td>\n",
       "      <td>[[face alignment refers to finding the pixel l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[we study pattern - forming nonlinear dynamics...</td>\n",
       "      <td>[[modulation instability ( mi ) is one of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we investigate the infrared dynamics of a non...</td>\n",
       "      <td>[[understanding strong dynamics constitutes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[we propose a new framework for constructing p...</td>\n",
       "      <td>[[polar codes   are the first family of codes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91381</th>\n",
       "      <td>[we propose dirichlet process mixtures of gene...</td>\n",
       "      <td>[[in this paper , we examine the general regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91382</th>\n",
       "      <td>[we classify all possible new u(1 ) x su(2 ), ...</td>\n",
       "      <td>[[the higgs mass hierarchy puzzle suggests new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91383</th>\n",
       "      <td>[we show that any second order linear ordinary...</td>\n",
       "      <td>[[the motivation for writing this paper is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91384</th>\n",
       "      <td>[we compare predictions for the spin - indepen...</td>\n",
       "      <td>[[the minimal supersymmetric standard model ( ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91385</th>\n",
       "      <td>[we derive equations for the mean entropy and,...</td>\n",
       "      <td>[[temperature stratified turbulence ( e.g. , t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91386 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "0      [tree boosting is a highly effective and widel...   \n",
       "1      [face alignment , which is the task of finding...   \n",
       "2      [we study pattern - forming nonlinear dynamics...   \n",
       "3      [we investigate the infrared dynamics of a non...   \n",
       "4      [we propose a new framework for constructing p...   \n",
       "...                                                  ...   \n",
       "91381  [we propose dirichlet process mixtures of gene...   \n",
       "91382  [we classify all possible new u(1 ) x su(2 ), ...   \n",
       "91383  [we show that any second order linear ordinary...   \n",
       "91384  [we compare predictions for the spin - indepen...   \n",
       "91385  [we derive equations for the mean entropy and,...   \n",
       "\n",
       "                                                    text  \n",
       "0      [[machine learning and data - driven approache...  \n",
       "1      [[face alignment refers to finding the pixel l...  \n",
       "2      [[modulation instability ( mi ) is one of the ...  \n",
       "3      [[understanding strong dynamics constitutes a ...  \n",
       "4      [[polar codes   are the first family of codes ...  \n",
       "...                                                  ...  \n",
       "91381  [[in this paper , we examine the general regre...  \n",
       "91382  [[the higgs mass hierarchy puzzle suggests new...  \n",
       "91383  [[the motivation for writing this paper is an ...  \n",
       "91384  [[the minimal supersymmetric standard model ( ...  \n",
       "91385  [[temperature stratified turbulence ( e.g. , t...  \n",
       "\n",
       "[91386 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = df[[\"abstract\", \"text\"]]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any columns contain empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\'hi\\' \\ is used for space <br>\n",
    "random space, which is used for reference [15] quote box <br>\n",
    "sec ref is hyperlink to a section <br>\n",
    "fig ref is hyperlink to a figure <br>\n",
    "inlineform <br>\n",
    "displayform are both symbols, both contains numbers in string <br>\n",
    "remove all forms and remove all symbols but keep numbers <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_let(string):\n",
    "    return any(char.isalpha() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_num(string):\n",
    "    return any(char.isdigit() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLine(line):\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    number = list(map(str, range(10)))\n",
    "    symbols = [\"'\", \"’\"]\n",
    "    valid_char = alphabet + number + symbols\n",
    "    stop_words = list(ENGLISH_STOP_WORDS)\n",
    "    \n",
    "    clean_line = line.lower()\n",
    "    clean_line = clean_line.strip()\n",
    "    \n",
    "    # fix apostrophes in line by removing apostrophe with no following alphabet character\n",
    "    clean_line = clean_line.replace(\"' \", \" \")\n",
    "    if clean_line and clean_line[-1] == \"'\":\n",
    "        clean_line = clean_line[0:len(clean_line)-1]\n",
    "    # fix apostrophes in line by removing space before single quote\n",
    "    clean_line = clean_line.replace(\" '\", \"'\")\n",
    "    #remove punctuation\n",
    "    # replace all non alphabet character with space\n",
    "    difference = list(set(clean_line).symmetric_difference(valid_char))\n",
    "\n",
    "    for dif in difference:\n",
    "        clean_line = clean_line.replace(dif, \" \")\n",
    "    \n",
    "    # clean line = clean line remove forms\n",
    "    words = clean_line.split()\n",
    "\n",
    "    #  remove forms\n",
    "    words = [x.replace(x, \"\") if contain_let(x) and contain_num(x) else x for x in words]\n",
    "    # remove empty strings\n",
    "    words = filter(None, words)\n",
    "\n",
    "    # stop words from sklearn, remove stop words\n",
    "    words = [x for x in words if not x in stop_words]\n",
    "\n",
    "    # combine the items into 1 string\n",
    "    clean_line = ' '.join(words)\n",
    "    return clean_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatParagraph(paragraph):\n",
    "    clean_paragraph = \"\"\n",
    "    for line in paragraph:\n",
    "        lines = cleanLine(line)\n",
    "        clean_paragraph += cleanLine(lines) + \" \"\n",
    "        #print(clean_paragraph)\n",
    "        \n",
    "    return(clean_paragraph.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatPaper(paper):\n",
    "    clean_paper = \"\"\n",
    "    for paragraph in paper:\n",
    "        para = concatParagraph(paragraph)\n",
    "        #print(para)\n",
    "        clean_paper += concatParagraph(paragraph) + \" \"\n",
    "    return(clean_paper.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376c0ee63b1e43b4b96c00ec48d9a397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, row in tqdm(summary_df.iterrows(), total=df.shape[0]):\n",
    "    abstract = row[\"abstract\"]\n",
    "    paper = row[\"text\"]\n",
    "    \n",
    "    summary_df.at[i, \"abstract\"] = concatParagraph(abstract)\n",
    "    summary_df.at[i, \"text\"] = concatPaper(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree boosting highly effective widely used mac...</td>\n",
       "      <td>machine learning data driven approaches import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face alignment task finding locations set faci...</td>\n",
       "      <td>face alignment refers finding pixel locations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>study pattern forming nonlinear dynamics start...</td>\n",
       "      <td>modulation instability mi fundamental process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>investigate infrared dynamics nonsupersymmetri...</td>\n",
       "      <td>understanding strong dynamics constitutes cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>propose new framework constructing polar codes...</td>\n",
       "      <td>polar codes family codes proven capacity achie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91381</th>\n",
       "      <td>propose dirichlet process mixtures generalized...</td>\n",
       "      <td>paper examine general regression problem gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91382</th>\n",
       "      <td>classify possible new u 1 x su 2 x su 3 multip...</td>\n",
       "      <td>higgs mass hierarchy puzzle suggests new physi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91383</th>\n",
       "      <td>second order linear ordinary diffrential equat...</td>\n",
       "      <td>motivation writing paper observation small app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91384</th>\n",
       "      <td>compare predictions spin independent contribut...</td>\n",
       "      <td>minimal supersymmetric standard model mssm bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91385</th>\n",
       "      <td>derive equations mean entropy mean internal en...</td>\n",
       "      <td>temperature stratified turbulence e g turbulen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91386 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "0      tree boosting highly effective widely used mac...   \n",
       "1      face alignment task finding locations set faci...   \n",
       "2      study pattern forming nonlinear dynamics start...   \n",
       "3      investigate infrared dynamics nonsupersymmetri...   \n",
       "4      propose new framework constructing polar codes...   \n",
       "...                                                  ...   \n",
       "91381  propose dirichlet process mixtures generalized...   \n",
       "91382  classify possible new u 1 x su 2 x su 3 multip...   \n",
       "91383  second order linear ordinary diffrential equat...   \n",
       "91384  compare predictions spin independent contribut...   \n",
       "91385  derive equations mean entropy mean internal en...   \n",
       "\n",
       "                                                    text  \n",
       "0      machine learning data driven approaches import...  \n",
       "1      face alignment refers finding pixel locations ...  \n",
       "2      modulation instability mi fundamental process ...  \n",
       "3      understanding strong dynamics constitutes cont...  \n",
       "4      polar codes family codes proven capacity achie...  \n",
       "...                                                  ...  \n",
       "91381  paper examine general regression problem gener...  \n",
       "91382  higgs mass hierarchy puzzle suggests new physi...  \n",
       "91383  motivation writing paper observation small app...  \n",
       "91384  minimal supersymmetric standard model mssm bes...  \n",
       "91385  temperature stratified turbulence e g turbulen...  \n",
       "\n",
       "[91386 rows x 2 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.to_json(\"./Dataset/SSN/SSN_Dataset_Short_Clean.json\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree boosting highly effective widely used mac...</td>\n",
       "      <td>machine learning data driven approaches import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face alignment task finding locations set faci...</td>\n",
       "      <td>face alignment refers finding pixel locations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>study pattern forming nonlinear dynamics start...</td>\n",
       "      <td>modulation instability mi fundamental process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>investigate infrared dynamics nonsupersymmetri...</td>\n",
       "      <td>understanding strong dynamics constitutes cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>propose new framework constructing polar codes...</td>\n",
       "      <td>polar codes family codes proven capacity achie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91381</th>\n",
       "      <td>propose dirichlet process mixtures generalized...</td>\n",
       "      <td>paper examine general regression problem gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91382</th>\n",
       "      <td>classify possible new u 1 x su 2 x su 3 multip...</td>\n",
       "      <td>higgs mass hierarchy puzzle suggests new physi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91383</th>\n",
       "      <td>second order linear ordinary diffrential equat...</td>\n",
       "      <td>motivation writing paper observation small app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91384</th>\n",
       "      <td>compare predictions spin independent contribut...</td>\n",
       "      <td>minimal supersymmetric standard model mssm bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91385</th>\n",
       "      <td>derive equations mean entropy mean internal en...</td>\n",
       "      <td>temperature stratified turbulence e g turbulen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91386 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "0      tree boosting highly effective widely used mac...   \n",
       "1      face alignment task finding locations set faci...   \n",
       "2      study pattern forming nonlinear dynamics start...   \n",
       "3      investigate infrared dynamics nonsupersymmetri...   \n",
       "4      propose new framework constructing polar codes...   \n",
       "...                                                  ...   \n",
       "91381  propose dirichlet process mixtures generalized...   \n",
       "91382  classify possible new u 1 x su 2 x su 3 multip...   \n",
       "91383  second order linear ordinary diffrential equat...   \n",
       "91384  compare predictions spin independent contribut...   \n",
       "91385  derive equations mean entropy mean internal en...   \n",
       "\n",
       "                                                    text  \n",
       "0      machine learning data driven approaches import...  \n",
       "1      face alignment refers finding pixel locations ...  \n",
       "2      modulation instability mi fundamental process ...  \n",
       "3      understanding strong dynamics constitutes cont...  \n",
       "4      polar codes family codes proven capacity achie...  \n",
       "...                                                  ...  \n",
       "91381  paper examine general regression problem gener...  \n",
       "91382  higgs mass hierarchy puzzle suggests new physi...  \n",
       "91383  motivation writing paper observation small app...  \n",
       "91384  minimal supersymmetric standard model mssm bes...  \n",
       "91385  temperature stratified turbulence e g turbulen...  \n",
       "\n",
       "[91386 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"SSN/SSN_Dataset_Short_Clean.json\"\n",
    "dataset_path = DATASET+DATA_DIR\n",
    "df = pd.read_json(dataset_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\" Simple vocabulary wrapper which maps every unique word to an integer ID. \"\"\"\n",
    "    def __init__(self):\n",
    "        # intially, set both the IDs and words to dictionaries with special tokens\n",
    "        self.word2idx = {'<start>': 0, '<end>': 1, '<pad>':2, '<unk>':3}\n",
    "        self.idx2word = {0: '<start>', 1: '<end>', 2: '<pad>', 3: '<unk>'}\n",
    "        self.idx = 4\n",
    "\n",
    "    def add_word(self, word):\n",
    "        # if the word does not already exist in the dictionary, add it\n",
    "        if not word in self.word2idx:\n",
    "            # this will convert each word to index and index to word as you saw in the tutorials\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            # increment the ID for the next word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        # if we try to access a word not in the dictionary, return the id for <unk>\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    ## added function for utility\n",
    "    def get_word(self,index):\n",
    "        # this returns the word when given an index\n",
    "        return self.idx2word[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "    \"\"\" \n",
    "    Parses training set token file captions and builds a Vocabulary object and dataframe for \n",
    "    the image and caption data\n",
    "\n",
    "    Returns:\n",
    "        vocab (Vocabulary): Vocabulary object containing all words appearing more than min_frequency\n",
    "    \"\"\"\n",
    "    MIN_FREQUENCY = 2\n",
    "    word_mapping = Counter()\n",
    "\n",
    "    # for index in df.index:\n",
    "    for text in tqdm(data):\n",
    "        for word in text.split():\n",
    "            #print(word)\n",
    "            if word in word_mapping:\n",
    "                word_mapping[word] += 1\n",
    "            else:\n",
    "                word_mapping[word] = 1\n",
    "\n",
    "    # create a vocab instance\n",
    "    vocab = Vocabulary()\n",
    "\n",
    "    # add the words to the vocabulary\n",
    "    for word in word_mapping:\n",
    "        if word_mapping[word] > MIN_FREQUENCY:\n",
    "            vocab.add_word(word)\n",
    "\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04efe1e9aec14e41bfb15810d2646049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstract_vocab = build_vocab(df[\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465c158f7a4547a59a84a5185ce42035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_vocab = build_vocab(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(vocab, text, max_len):\n",
    "    word_ids = []\n",
    "    for word in text.split():\n",
    "        word_ids.append(vocab(word))\n",
    "    word_ids.append(vocab(\"<end>\"))\n",
    "#     while len(word_ids) < max_len:\n",
    "#             word_ids.append(vocab(\"<pad>\"))\n",
    "    return word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTRACT_MAX = 100\n",
    "TEXT_MAX = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSNDataset(Dataset):\n",
    "    def __init__(self, df, a_vocab, t_vocab):\n",
    "\n",
    "        self.df = df\n",
    "        self.a_vocab = a_vocab\n",
    "        self.t_vocab = t_vocab\n",
    "        self.abstract_max_len = ABSTRACT_MAX\n",
    "        self.text_max_len = TEXT_MAX\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return word_id\n",
    "        abstract = self.df.iloc[index][\"abstract\"]\n",
    "        text = self.df.iloc[index][\"text\"]\n",
    "        \n",
    "        a_word_ids = tokenise(self.a_vocab, abstract, self.abstract_max_len)\n",
    "        t_word_ids = tokenise(self.t_vocab, text, self.text_max_len)\n",
    "\n",
    "        a_length = len(a_word_ids)\n",
    "        t_length = len(t_word_ids)\n",
    "    \n",
    "        return torch.tensor(a_word_ids), torch.tensor(t_word_ids)# torch.tensor(t_length)# torch.tensor(t_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_collate_fn(data):\n",
    "    \"\"\" Creates mini-batch tensors from the list of tuples (image, caption).\n",
    "    Args:\n",
    "        data: list of tuple of 2 word ids\n",
    "        - abstract id\n",
    "        - text id\n",
    "    Returns:\n",
    "        abstract list ids\n",
    "        text list ids\n",
    "    \"\"\"\n",
    "    \n",
    "    abstracts, texts = zip(*data)\n",
    "#     abstracts = [ torch.Tensor(abstract).to(device) for abstract in abstracts ]\n",
    "# if batch size is 1 then use [0]\n",
    "    abstracts = torch.stack(abstracts, 0)\n",
    "    #abstracts = abstracts.unsqueeze(0)\n",
    "#     abstracts = torch.nn.utils.rnn.pad_sequence(abstracts)\n",
    "    texts = torch.stack(texts, 0)\n",
    "    #texts = texts.unsqueeze(0)\n",
    "\n",
    "    return abstracts, texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, random_state=seed, train_size = 0.7)\n",
    "train_data, valid_data = train_test_split(train_data, random_state=seed, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SSNDataset(train_data, abstract_vocab, text_vocab)\n",
    "valid_set = SSNDataset(valid_data, abstract_vocab, text_vocab)\n",
    "test_set = SSNDataset(test_data, abstract_vocab, text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=True, collate_fn=text_collate_fn) # num_worker can't be 2+ as the time it \n",
    "                                                                 # takes to build iter is much longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(valid_set, batch_size=1, shuffle=True, collate_fn=text_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_set = SSNDataset(df, abstract_vocab, text_vocab)\n",
    "all_loader = DataLoader(all_set, batch_size=1, shuffle=True, collate_fn=text_collate_fn)\n",
    "abstracts = []\n",
    "texts = []\n",
    "for i, (abstract, text) in enumerate(all_loader):\n",
    "    a_size = list(abstract.size())[1]\n",
    "\n",
    "    t_size = list(text.size())[1]\n",
    "    abstracts.append(a_size)\n",
    "    texts.append(t_size)\n",
    "numbers = list(range(len(all_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(numbers, abstracts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(numbers, texts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length for abstract:  259\n",
      "max length for text:  5732\n",
      "min length for abstract:  2\n",
      "min length for text:  13\n",
      "average length for abstract:  85\n",
      "average length for text:  2029\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "print(\"max length for abstract: \",max(abstracts))\n",
    "print(\"max length for text: \",max(texts))\n",
    "print(\"min length for abstract: \",min(abstracts))\n",
    "print(\"min length for text: \",min(texts))\n",
    "print(\"average length for abstract: \",math.floor(mean(abstracts)))\n",
    "print(\"average length for text: \",math.floor(mean(texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 percentile:  371.108\n",
      "90 percentile:  20.0\n"
     ]
    }
   ],
   "source": [
    "print(\"50 percentile: \", np.percentile(texts, 0.08))\n",
    "print(\"90 percentile: \", np.percentile(abstracts, 0.08))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, voc_size, num_layer, hidden_dim, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layer = num_layer\n",
    "        \n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=voc_size,\n",
    "            embedding_dim=hidden_dim\n",
    "        )\n",
    "        self.lstm = nn.GRU(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layer,\n",
    "            bidirectional=False,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layer, batch_size, self.hidden_dim, device=device)\n",
    "#                 torch.zeros(self.num_layer, batch_size, self.hidden_dim, device=device))\n",
    "\n",
    "    def forward(self, input):\n",
    "        #start = time.time()\n",
    "\n",
    "        #print(input.shape)\n",
    "        lengths = (input != 2).sum(1) # pad index = 2\n",
    "        batch_size = input.shape[0]\n",
    "        initial_hidden = self.init_hidden(batch_size)\n",
    "        embedded = self.embeddings(input)\n",
    "        #print(\"lengths: \",lengths.shape)\n",
    "#         print(lengths)\n",
    "        print(\"embedded: \",embedded.shape)\n",
    "        print(\"embedded: \",embedded.view(1, 1, -1).shape)\n",
    "    \n",
    "#         print(\"initial_hidden\", initial_hidden.shape)\n",
    "        embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), \n",
    "                                                           batch_first=True,enforce_sorted=False)\n",
    "#         print(\"embedded: \",embedded[0].shape)\n",
    "#         print(\"embedded: \",embedded[1].shape)\n",
    "        output, hidden = self.lstm(embedded, initial_hidden)\n",
    "        #print(\"output: \",output.shape)\n",
    "        output, lengths = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        lengths = lengths.to(device)\n",
    "        #end = time.time()\n",
    "        #print(\"Encoder Time: \",end - start)\n",
    "#         print(\"-----------\")\n",
    "#         print(\"output: \",output.shape) # [batch, seq_len, hidden_dim]\n",
    "#         print(\"hidden: \",hidden.shape) # [layer, batch, hidden_dim]\n",
    "        return output, hidden, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, voc_size, num_layer,hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=voc_size,\n",
    "            embedding_dim=hidden_dim\n",
    "        )\n",
    "        self.attention = Attention(hidden_dim,hidden_dim)\n",
    "        self.lstm = nn.GRU(\n",
    "            input_size=2*hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layer,\n",
    "            bidirectional=False,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=hidden_dim * 2,\n",
    "            out_features=voc_size\n",
    "        )\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "\n",
    "    def forward(self, input, hidden, context, encoder_outputs, lengths): # also add in encoder outputs \n",
    "                                                                # to create context\n",
    "        #start = time.time()\n",
    "        embedded = self.embeddings(input) # [batch, 256]\n",
    "        # hidden = [bathc, seq_len, hidden_dim]\n",
    "        # print(hidden[0])\n",
    "        #hidden_permute = hidden.permute(0,1) # [1, 512]\n",
    "        decoder_input = torch.cat((embedded, context), -1).unsqueeze(1) # [batch, 1, 512]\n",
    "        decoder_output, hidden = self.lstm(decoder_input, hidden)\n",
    "        decoder_output = decoder_output.squeeze(1)\n",
    "        \n",
    "        # mask to block decoder from knowing future sequences/block padding\n",
    "        max_len = lengths.max().item()\n",
    "    \n",
    "        mask = torch.arange(max_len).expand(len(lengths), max_len) < lengths.unsqueeze(1).cpu()\n",
    "        mask = mask.to(device)\n",
    "        attention = self.attention(decoder_output, encoder_outputs, mask).to(device)\n",
    "\n",
    "        context = attention.unsqueeze(1).bmm(encoder_outputs).squeeze(1)\n",
    "        #print(\"context shape: \", context.shape)\n",
    "        output_context = torch.cat((decoder_output, context), dim=1) # []\n",
    "        output_context = torch.nn.functional.relu(output_context)\n",
    "        \n",
    "        output_context = self.fc(output_context)\n",
    "        #print(output[0])\n",
    "        output = self.logsoftmax(output_context)\n",
    "        #end = time.time()\n",
    "        #print(\"Decoder Time: \",end - start)\n",
    "#         print(\"decode output: \",output)\n",
    "#         print(\"output: \", output.shape)\n",
    "        # output is [batch, seq_len, hidden_dim]\n",
    "        # hidden = 2,2,256 [2, batch, hidden_dim]\n",
    "        return output, hidden, context, attention\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn_hidden_vector = nn.Linear(encoder_hidden_dim + decoder_hidden_dim, decoder_hidden_dim)\n",
    "        \n",
    "        self.attn_scoring_fn = nn.Linear(decoder_hidden_dim, decoder_hidden_dim, bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        \n",
    "        \n",
    "    \n",
    "        # hidden = [num_layer, batch size, decoder hidden dim]\n",
    "        # encoder_outputs [batch, seq_len, hidden_dim]\n",
    "        seq_len = encoder_outputs.shape[1] # 10000\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #attention_scores = torch.zeros((batch_size, seq_len), device=device)\n",
    "\n",
    "        hidden = hidden.repeat(encoder_outputs.shape[1],1,1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "\n",
    "        \n",
    "#         print(\"attention score: \", attention_scores.shape)\n",
    "#         print(\"hidden atten: \",hidden.shape)\n",
    "#         print(\"encoder output: \", encoder_outputs.shape)\n",
    "\n",
    "\n",
    "        attention_scores = torch.einsum('sbd,sbd->bs',hidden, encoder_outputs)\n",
    "        #print(\"attention_scores: \",attention_scores.shape)\n",
    "            \n",
    "        \n",
    "        \n",
    "#         print(attention_scores.shape)\n",
    "#         print(attention_scores)\n",
    "#         global attention_scoresg\n",
    "#         attention_scoresg = attention_scores\n",
    "            \n",
    "        attention_scores[~mask] = -float('inf')\n",
    "        attention_scores = nn.functional.relu(attention_scores)\n",
    "        #end = time.time()\n",
    "        #print(\"Attention Time: \",end - start)\n",
    "        return nn.functional.softmax(attention_scores, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder, hidden_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, abstract, text):\n",
    "        #decoder = Decoder(len(abstract_vocab), 512).to(device)\n",
    "        output, hidden, lengths = self.encoder(text) # [10000, 512] [seq_len, hidden_dim]\n",
    "        batch_size = output.shape[0]\n",
    "\n",
    "        # encoder hidden and cell\n",
    "\n",
    "        decoder_hidden = hidden\n",
    "        context = torch.zeros(text.shape[0], self.hidden_dim).to(device) # batch, hidden_dim\n",
    "        decoder_input = torch.LongTensor([0]).repeat(batch_size).to(device)\n",
    "#         out1 = output[0] # varied\n",
    "#         out2 = output[1]\n",
    "#         out3 = output[2]\n",
    "\n",
    "        #input, hidden, context, encoder_outputs\n",
    "        # squeeze converts the [[]] 3d tensor to 2D, then detach converts it to 1D and item converts to int\n",
    "    #     _, initial = decode_output.topk(1)\n",
    "    #     initial = initial.squeeze().detach().item()\n",
    "    #     start_input = [initial]\n",
    "    #     decoded_words = [initial]\n",
    "        decoded_words = [[]]\n",
    "        done = [False]\n",
    "        decoded_loss = torch.Tensor().to(device)\n",
    "        \n",
    "        # attentions = []\n",
    "        # repeat until end token, but should limit to less than text length\n",
    "        # try keeping the variable length\n",
    "        # when calculating loss expand either prediction or original to fit the lengthier target's length\n",
    "        # by filling the rest with token for pad\n",
    "\n",
    "        for i in range(100):\n",
    "            decoder_output, decoder_hidden, context, attention = self.decoder(decoder_input, \n",
    "                                                                  decoder_hidden, context, output, lengths)\n",
    "            \n",
    "            #print(decoder_output)\n",
    "\n",
    "            # return attention\n",
    "            # attentions.append(attention)\n",
    "            # teacher forcing here, basically use ground truth values for input\n",
    "    #         if random.uniform(0, 1) > 0.5:\n",
    "            decoded_loss = torch.cat((decoded_loss, decoder_output.unsqueeze(1)), 1)\n",
    "            _, topi = decoder_output.topk(k=1)\n",
    "    #         else:\n",
    "    #             topi = text[i]\n",
    "\n",
    "            decoder_input = decoder_output.argmax(1)\n",
    "            #print(decoder_input)\n",
    "\n",
    "            for j in range(1):\n",
    "                if decoder_input[j].item() == 1:\n",
    "                    done[j] = True\n",
    "                if not done[j]:\n",
    "                    decoded_words[j].append(decoder_input[j].item())\n",
    "                else:\n",
    "                    decoded_words[j].append(2)\n",
    "            start_input = [decoder_input.item()]\n",
    "            #do some processing here to convert words into tensor for loss calculation\n",
    "\n",
    "        for k in range(1):\n",
    "            sentence=\"\"\n",
    "            for i in decoded_words[k]:\n",
    "                sentence+= abstract_vocab.get_word(i) + \" \"\n",
    "            print(sentence)\n",
    "        for i in range(1):\n",
    "            sentence=\"\"\n",
    "            for i in abstract[i]:\n",
    "                sentence+= abstract_vocab.get_word(i.item()) + \" \"\n",
    "            print(sentence)\n",
    "        #print((decoded_loss))\n",
    "        return decoded_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(text_vocab), num_layer=2, hidden_dim=256, device=device)\n",
    "encoder = encoder.to(device)\n",
    "decoder = Decoder(len(abstract_vocab), num_layer=2, hidden_dim=256)\n",
    "decoder = decoder.to(device)\n",
    "# abstract, text = next(iter(train_loader))\n",
    "# abstract = abstract.to(device)\n",
    "# text = text.to(device)\n",
    "model = Model(encoder, decoder, 256)\n",
    "model = model.to(device)\n",
    "#out1 = model(abstract, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "~~1 - Complete model definition~~ <br>\n",
    "~~2 - fix word vocab~~ <br>\n",
    "~~3 - Define Attention model and combine with Decoder~~ <br>\n",
    "    ~~1 - Adjust to allow for batch ~~<br>\n",
    "4 - trace through program to see where it starts to have the same tensor <br>\n",
    "~~5 - use mask to hide paddings~~ switch on off to see difference<br>\n",
    "~~6 - Switch from GRU to LSTM~~ swap to see difference<br>\n",
    "7 - Add training script to train <br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "compared inspired cpu u shell shell shell pathway pathway pathway pathway pathway case case goal goal direct absence arguments arguments arguments validate side arguments arguments simple matter scalability scalability cpu cpu cpu schemes compare shell treatment access access access access access access hence sheftel cpu distributed treatment treatment computer attribute attribute calculations related mode mode compare treatment mode field cpu cpu leptonic detection shell shell shell studied access subsequent access access access access access access hence sheftel distributed single single induced induced cpu accuracy accuracy accuracy lower deviation deviation dynamics stable stable shell shell shell successfully access access access access \n",
      "we propose a mathematical model for cholera with treatment through quarantine the model is shown to be both <unk> and <unk> well <unk> in particular we prove that all solutions of the model are positive and bounded and that every solution with initial conditions in a certain meaningful set remains in that set for all time the existence of unique <unk> free and <unk> equilibrium points is proved and the basic <unk> number is <unk> then we study the local asymptotic stability of these equilibrium points an optimal control problem is proposed and analyzed whose goal is to obtain a successful treatment through quarantine we provide the optimal quarantine <unk> for the minimization of the number of <unk> individuals and <unk> <unk> as well as the <unk> associated with the quarantine finally a numerical simulation of the cholera <unk> in the <unk> of <unk> <unk> in <unk> is carried out <unk> the usefulness of the model and its analysis <end> \n",
      "embedded:  torch.Size([1, 5488, 256])\n",
      "embedded:  torch.Size([1, 1, 1404928])\n",
      "treatment treatment <unk> treatment treatment treatment credibility <unk> <unk> depending supervision treatment treatment treatment <unk> treatment treatment treatment credibility <unk> treatment treatment treatment <unk> treatment treatment treatment credibility <unk> <unk> depending supervision treatment treatment treatment <unk> treatment treatment treatment credibility <unk> treatment treatment treatment <unk> treatment treatment treatment credibility <unk> <unk> depending supervision treatment treatment treatment <unk> treatment treatment treatment credibility <unk> treatment treatment treatment <unk> treatment treatment treatment credibility <unk> <unk> depending supervision treatment treatment treatment <unk> treatment treatment treatment credibility <unk> treatment treatment treatment <unk> treatment treatment treatment credibility <unk> <unk> depending supervision treatment treatment treatment <unk> treatment \n",
      "in theories with discrete abelian gauge groups requiring that black holes be able to <unk> their charge as they <unk> leads to an upper bound on the <unk> of a charged <unk> mass and the cutoff scale above which the effective description of the theory <unk> <unk> this <unk> that a non trivial version of the weak gravity conjecture wgc may also apply to gauge symmetries that are discrete despite there being no associated <unk> field therefore <unk> the conjecture beyond the <unk> that gravity is the <unk> <unk> here we take a step towards making this <unk> more precise by <unk> mathbb z n and mathbb z 2 n gauge symmetries <unk> via theories of spontaneous symmetry breaking we show that <unk> the wgc to a dual description of an abelian higgs model leads to constraints that allow us to <unk> but not <unk> existing bounds on discrete symmetries based on black <unk> arguments in this <unk> considering the effect of discrete hair on black holes naturally identifies the cutoff of the effective theory with the scale of spontaneous symmetry breaking and provides a mechanism through which discrete hair can be <unk> without <unk> the gravitational <unk> we explore the possible implications of these arguments for understanding the <unk> of the weak scale compared to m <unk> <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a \n",
      "non local self similarity nss is a <unk> prior of natural images for image denoising most of existing denoising methods employ similar patches which is a <unk> level nss prior in this paper we take one step forward by introducing a pixel level nss prior i e <unk> similar pixels across a non local region this is motivated by the fact that finding <unk> similar pixels is more feasible than similar patches in natural images which can be used to enhance image denoising performance with the introduced pixel level nss prior we propose an accurate noise level estimation method and then develop a <unk> image denoising method based on the <unk> <unk> <unk> and <unk> filtering techniques experiments on benchmark datasets demonstrate that the proposed method achieves much better performance than state of the art methods on real world image denoising the code will be <unk> <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "we present a projection based numerical integration technique to deal with embedded interface in finite element fe framework the element cut by an embedded interface is <unk> as a cut cell we recognize elemental matrices of a cut cell can be <unk> from the elemental matrices of its sub divided cells via projection at matrix level these sub divided cells are termed as integration cells the proposed technique <unk> following characteristics 1 no <unk> in fe formulation and <unk> <unk> 2 consistency with the derivation of fe formulation in variational principle it can be considered as a re projection of the <unk> of equation system in the test function space or a reduced order modeling <unk> technique these characteristics significantly improves its scalability <unk> to implementation and robustness to deal with problems involving embedded <unk> in fe framework numerical examples e g <unk> induced <unk> <unk> rotation free <unk> and <unk> body contact in which the proposed technique is implemented to integrate the variational form of <unk> <unk> equations in cut cells are presented <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "the reaction rate probability integral is extended from <unk> <unk> approach to a more general approach by using the pathway model introduced by mathai mathai a m <unk> a pathway to matrix <unk> gamma and normal <unk> linear algebra and its applications <unk> <unk> <unk> the extended thermonuclear reaction rate is obtained in closed form via a <unk> g function and the so obtained g function is represented as a solution of a homogeneous linear <unk> equation a physical model for the <unk> process in a fusion plasma compressed and <unk> driven spherical shock wave is used for evaluating the fusion energy integral by integrating the extended thermonuclear reaction rate integral over the temperature the result obtained is compared with the standard fusion yield obtained by haubold and john in 1981 haubold h <unk> and john r w 1981 analytical representation of the thermonuclear reaction rate and fusion energy production in a spherical plasma shock wave plasma physics 23 <unk> <unk> an <unk> for the pathway parameter is also given <end> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "imitation learning holds the <unk> to address challenging robotic tasks such as autonomous navigation it however requires a human <unk> to <unk> the training process and <unk> correct control <unk> to <unk> without feedback which is always <unk> to error and <unk> to <unk> human <unk> and avoid <unk> <unk> of data in the robotic autonomous navigation with imitation learning this paper <unk> a novel semi supervised imitation learning solution based on a multi <unk> design this solution includes a suboptimal sensor policy based on sensor fusion to automatically label states <unk> by a robot to avoid human supervision during training in addition a <unk> policy is developed to <unk> the adversarial affect of learning too much from the suboptimal sensor policy this solution allows the robot to learn a navigation policy in a self supervised manner with extensive experiments in <unk> environments this solution can achieve near human performance in most of the tasks and even <unk> human performance in case of <unk> events such as <unk> <unk> or human operation errors to best of our <unk> this is the first work that <unk> sensor fusion and imitation learning to <unk> robotic autonomous navigation in the real world without human supervision <end> \n",
      "embedded:  torch.Size([1, 5219, 256])\n",
      "embedded:  torch.Size([1, 1, 1336064])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "by controlling the state of neuronal populations <unk> <unk> affect behaviour a key neuromodulation mechanism is the <unk> of neuronal <unk> via the modulation of ion channel expression this type of neuromodulation is <unk> studied via conductance based models but those models are computationally challenging for large scale network simulations needed in population studies this paper studies the modulation properties of the multi quadratic integrate and fire <unk> model a <unk> of the classical quadratic integrate and fire <unk> model the model is shown to combine the computational <unk> of integrate and fire modelling and the <unk> <unk> of conductance based modelling it is therefore a good candidate for <unk> computational studies of neuromodulation in large networks <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "density <unk> theory dft has become the quasi standard for <unk> <unk> simulations for a wide range of applications while the intrinsic cubic scaling of dft was for a long time limiting the accessible system size to some <unk> atoms the recent progress with respect to linear scaling dft methods has <unk> to tackle problems that are larger by many orders of <unk> however as these linear scaling methods were developed for <unk> they can not in general be <unk> applied to <unk> as a finite temperature is needed to <unk> locality of the density matrix in this paper we show that <unk> finite electronic temperature is employed the linear scaling version of the <unk> code is able to exploit this locality to provide a computational treatment that scales linearly with respect to the number of atoms of a <unk> system we provide prototype examples based on bulk <unk> which plays a key role in finding <unk> and long <unk> materials for fusion <unk> we <unk> that such an approach might <unk> in <unk> the <unk> towards novel approaches for <unk> the electronic structure of such materials in particular when large <unk> are required <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "we address the question on how weak perturbations that are quite <unk> in small many body systems can lead to decoherence and hence to <unk> when they <unk> as the system size <unk> this question is at the <unk> of solid state <unk> there an <unk> local polarization <unk> all over due to spin spin interactions that <unk> the total spin projection leading to an <unk> of the polarization in principle this quantum dynamics can be <unk> by changing the <unk> of the hamiltonian however the <unk> is usually perturbed by non reversible interactions that <unk> as a decoherence source the <unk> of the local <unk> recovered <unk> the <unk> <unk> le here evaluated in a series of closed n spin systems with all to all interactions the most remarkable regime of the le decay occurs when the perturbation <unk> <unk> effective interactions <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "this paper presents the first derivation of the quadratic action for curvature perturbations zeta within the framework of cuscuton gravity we study the scalar cosmological perturbations <unk> by a canonical single scalar field in the presence of cuscuton field we identify zeta as <unk> curvature with respect to the source field and we show that it <unk> its conservation <unk> on <unk> horizon scales the result provides an explicit proof that cuscuton modification of gravity around <unk> <unk> <unk> walker <unk> metric is <unk> free we also investigate the potential development of other <unk> in cuscuton models we find that in a large class of these models there is no generic instability problem <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "we discuss an efficient numerical scheme for the <unk> filtering of <unk> quantum stochastic master equations we show that the <unk> quantum <unk> is robust and may be used for feedback based on <unk> measurements the proposed numerical scheme is <unk> to approximation which can be used to further reduce the computational <unk> associated with <unk> quantum trajectories and may allow real time quantum filtering we provide a two qubit example where feedback control of entanglement may be within the scope of current experimental systems <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "we investigate some issues that are relevant for the derivation of experimental limits on the parameters of canonical noncommutative <unk> by <unk> a simple <unk> <unk> type model in canonical noncommutative spacetime with soft supersymmetry breaking we explore the implications of ultraviolet supersymmetry on low energy phenomenology the fact that new physics in the ultraviolet can modify low energy predictions affects significantly the derivation of limits on the <unk> parameters based on low energy data these are in an appropriate sense here <unk> conditional limits we also find that some standard techniques for an effective low energy description of theories with non locality at short distance scales are only applicable in a regime where theories in canonical noncommutative spacetime <unk> any <unk> because of the strong <unk> to unknown <unk> physics it <unk> useful to combine high energy data from <unk> with the more <unk> available low energy data <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "we study a coupled dark energy dark matter model in which the energy momentum exchange is proportional to the <unk> expansion rate the <unk> of its perturbation is required by gauge <unk> we derive the linear perturbation equations for the gauge invariant energy density contrast and <unk> of the coupled fluids and we determine the initial conditions the <unk> turn out to be adiabatic for dark energy when <unk> adiabatic initial conditions for all the standard fluids we perform a full monte carlo markov <unk> <unk> analysis of the model using <unk> 7 <unk> data <end> <pad> <pad> <pad> <pad> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "the the the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "few body systems with large scattering length have universal properties that do not <unk> on the details of their interactions at short <unk> we study the universal bound state properties of the four <unk> system with large scattering length in an effective quantum <unk> approach we compute the four body <unk> energies using the <unk> equations for positive and negative scattering length moreover we study the correlation between three and four body energies and present a generalized <unk> <unk> for the four body system these results are useful for understanding the cluster structure of <unk> and for the <unk> of weakly bound <unk> with <unk> atoms close to a <unk> resonance <end> \n",
      "embedded:  torch.Size([1, 6170, 256])\n",
      "embedded:  torch.Size([1, 1, 1579520])\n",
      "the the the the the the the the the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "we give a proof of the <unk> of the <unk> magnetic duality on one side and <unk> conservation of the tree level <unk> on the other side within general models of nonlinear <unk> using modified <unk> rules derived from generalized normal ordered lagrangian we discuss the <unk> of the above two properties of the theory also at <unk> <unk> as an <unk> we present two explicit examples namely we find the generalized normal ordered lagrangian for the <unk> <unk> theory and derive a semi closed expression for the lagrangian of the <unk> <unk> model in terms of the weak field expansion with explicitly known coefficients from its normal ordered form <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "the fast <unk> mass <unk> cme from 23 <unk> <unk> <unk> attention due to its extremely short transit time from <unk> to 1 au of less than <unk> h in situ data from stereo a <unk> the <unk> of a fast forward shock with a speed of more than <unk> km s 1 followed by a magnetic structure <unk> with almost <unk> km s 1 we investigate the propagation behavior of the cme shock and magnetic structure with the aim to <unk> the short transit time and high impact speed as derived from in situ data we carefully <unk> the kinematics of the cme using the <unk> <unk> shell model and obtain a maximum speed of <unk> pm <unk> km s 1 for the cme shock and of <unk> pm <unk> km s 1 for its magnetic structure based on the kinematics the <unk> based model <unk> <unk> the <unk> data <unk> well to successfully simulate the cme shock we find that the <unk> flow speed should be of average value close to the slow <unk> <unk> speed 450 km s 1 and the initial shock speed at a distance of <unk> r <unk> should not <unk> <unk> <unk> km s 1 <unk> it would <unk> much too early at stereo a <end> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "we address the problem of <unk> domain image retrieval considering the following practical application given a user <unk> <unk> a clothing image our goal is to <unk> the same or attribute similar clothing items from online shopping <unk> this is a challenging problem due to the large <unk> between online shopping images usually <unk> in <unk> <unk> pose background conditions and user photos <unk> in <unk> conditions to address this problem we propose a dual attribute aware <unk> network darn for retrieval feature learning more specifically darn consists of two sub networks one for each domain whose retrieval feature representations are driven by semantic attribute learning we show that this attribute guided learning is a key factor for retrieval accuracy improvement in addition to further <unk> with the nature of the retrieval problem we <unk> a <unk> visual similarity constraint for learning to rank across the two sub networks <unk> contribution of our work is a large scale dataset which makes the network learning feasible we exploit <unk> review websites to <unk> a large set of online shopping images and corresponding offline user photos with fine <unk> clothing <unk> i e around 450 000 online shopping images and about <unk> 000 exact offline <unk> images of those online ones all these images are <unk> from real world <unk> websites <unk> the diversity of the data <unk> which makes this dataset unique and rare in the <unk> community we extensively evaluate the retrieval performance of networks in different <unk> the <unk> <unk> retrieval accuracy is <unk> when using the proposed darn other than the current popular solution using pre trained cnn features only 0 <unk> <unk> 0 <unk> <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the <unk> the the the <unk> the the <unk> the the <unk> the the <unk> the <unk> the <unk> the <unk> the <unk> the <unk> the <unk> the <unk> the <unk> the <unk> the <unk> the <unk> the <unk> <unk> the <unk> <unk> the <unk> <unk> the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "this paper addresses <unk> summarization of videos in a unified manner in particular we propose a framework for multi <unk> summarization for <unk> <unk> <unk> and entity summarization summarization at the level of <unk> like objects scenes humans and <unk> in the video we investigate several summarization models which capture <unk> of diversity <unk> representation and importance and <unk> the utility of these different models depending on the application while most of the prior work on <unk> summarization approaches has <unk> <unk> several models and learning weighted mixtures we focus on the <unk> of different models and <unk> and how they apply to different domains we also provide implementation details on summarization systems and the different <unk> involved we <unk> that the study from this paper will give insights into practitioners to appropriately <unk> the <unk> summarization models for the problems at <unk> <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "we the the the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "a cavity <unk> implementation of the non adiabatic holonomic quantum computation in decoherence free <unk> is proposed with nitrogen vacancy centers coupled <unk> to the <unk> <unk> mode of a <unk> cavity where a universal set of quantum gates can be realized on the qubits in our implementation with the <unk> of the appropriate driving fields the quantum evolution is <unk> to the cavity field state which is only <unk> <unk> the implemented non adiabatic <unk> utilizing optical transitions in the lambda type of three level configuration of the nitrogen vacancy centers can be used to construct a universal set of quantum gates on the encoded <unk> qubits therefore our scheme <unk> up the <unk> of <unk> universal holonomic quantum computation with cavity <unk> interaction on solid state spins characterized by long coherence times <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "we the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "humans can easily recognize the importance of people in social event images and they always focus on the most important individuals however learning to learn the relation between people in an image and <unk> the most important person based on this relation remains <unk> in this work we propose a deep importance relation network point that combines both relation modeling and feature learning in particular we infer two types of interaction modules the person person interaction module that learns the interaction between people and the event person interaction module that learns to describe how a person is involved in the event <unk> in an image we then estimate the importance relations among people from both interactions and <unk> the relation feature from the importance relations in this way point automatically learns several types of relation features in parallel and we <unk> these relation features and the <unk> feature to form the importance feature for important people classification extensive experimental results show that our method is effective for important people detection and <unk> the <unk> of learning to learn relations for important people detection <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "we <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "in this paper we propose a new method to enhance a mapping mu cdot of a parallel <unk> computational tasks to the processing <unk> pes of a parallel computer the idea behind our method <unk> is to enhance such a mapping by <unk> on the observation that many <unk> take the form of a partial cube this class of graphs includes all <unk> and cubic <unk> any such <unk> with even <unk> in each dimension all <unk> and all <unk> following previous work we represent the parallel application and the parallel computer by graphs g a v a e a and g p v p e p g p being a partial cube allows us to label its vertices the pes by bitvectors such that the cost of <unk> one <unk> of information between two vertices u p and v p of g p <unk> to the <unk> distance between the labels of u p and v p by transferring these bitvectors from v p to v a via mu 1 cdot and <unk> them to be unique on v a we can enhance mu cdot by <unk> labels of v a in a new way pairs of <unk> labels are local wrt the pes but not wrt g a moreover <unk> of the bitvectors <unk> give rise to a <unk> of <unk> on the pes <end> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "we <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "machine learning is used in a number of <unk> related applications such as biometric user authentication speaker identification <unk> a type of <unk> <unk> attack against machine learning called poisoning attack works by injecting <unk> <unk> data points in the training data so as to <unk> the false positive rate of the classifier in the <unk> of the biometric authentication this means that more <unk> will be classified as <unk> user and in case of speaker identification system user a will be classified user b in this paper we examine poisoning attack against svm and introduce <unk> a method to <unk> the svm classifier from the poisoning attack the basic idea of our method is to identify the poisoned data points injected by the <unk> and filter them out our method is light weight and can be easily integrated into existing systems experimental results show that it works very well in filtering out the poisoned data <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "we <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "new physics signals containing <unk> or more b <unk> jets but without <unk> or leptons could <unk> be <unk> within the current 8 tev lhc data set without <unk> meaningful constraints from any of the existing lhc searches at either atlas or cms this work provides several examples of simple motivated models that yield final states containing many b jets to study the potential for <unk> new physics in these high b jet multiplicity channels this paper focuses on a natural supersymmetry scenario where each of the pair produced <unk> decays to an on shell <unk> which subsequently decays via an <unk> motivated r parity violating coupling this gives rise to an <unk> jet final state containing six b quarks although no public measurements exist estimates <unk> that the standard model <unk> in high b jet multiplicity channels should be very small to <unk> the background uncertainty an <unk> method is presented that <unk> two different techniques to <unk> <unk> or to discover new physics in high b jet multiplicity final states <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "we <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "recent observations of <unk> <unk> <unk> new <unk> on its formation scenario <unk> formation and a role of <unk> <unk> should be considered in revised numerical models of the compact group <unk> of group <unk> to <unk> are estimated from <unk> measurements several effects <unk> to observed redshifts and a new effect is <unk> to be the result of the gravitational interaction between photons and constant magnetic fields <unk> gravitational waves the energy carried by these waves is <unk> as redshifts of photons cosmological simulations data are used to prove the significant contribution of our effect <end> <pad> <pad> <pad> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n",
      "we <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "inspired by the study of mild transient <unk> in the speed of sound of the adiabatic mode during <unk> we search for a <unk> <unk> feature <unk> in cosmic microwave background and large scale structure formation observables we find some common <unk> patterns both in the planck <unk> temperature temperature power spectrum and the <unk> galaxy spectrum by performing independent searches with these two data sets we find a <unk> in the most significant mode previously found by <unk> et al 2013 by using only planck data furthermore the joint data analysis shows that the <unk> frequency of the feature <unk> better constrained and the amplitude <unk> <unk> from zero unlike <unk> was observed using only planck data besides the parameter estimation we also discuss the bayesian evidence <end> \n",
      "embedded:  torch.Size([1, 5000, 256])\n",
      "embedded:  torch.Size([1, 1, 1280000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 83>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid Epoch [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m             \u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, current_eval_loss))\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_points, eval_loss_points\n\u001b[1;32m---> 83\u001b[0m train_loss, eval_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, valid_loader, model)\u001b[0m\n\u001b[0;32m     15\u001b[0m abstract \u001b[38;5;241m=\u001b[39m abstract\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]): \u001b[38;5;66;03m# max length for abstract\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, abstract, text)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#print(decoder_input)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdecoder_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     58\u001b[0m         done[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done[j]:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(train_loader, valid_loader, model):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    epoch_size = 10\n",
    "    loss_points = []\n",
    "    eval_loss_points = []\n",
    "    best_loss = 10000\n",
    "\n",
    "    for epoch in range(epoch_size):\n",
    "        \n",
    "        model.train()\n",
    "        loss_avg = []\n",
    "        for i, (abstract, text) in enumerate(train_loader):\n",
    "            # send batch data to device\n",
    "            abstract = abstract.to(device)\n",
    "            text = text.to(device)\n",
    "\n",
    "            \n",
    "            outputs = model(abstract, text).to(device)\n",
    "\n",
    "            loss = 0\n",
    "            for i in range(outputs.shape[1]): # max length for abstract\n",
    "                temp_loss = criterion(outputs[:,i,:], abstract[:,i])\n",
    "                \n",
    "                if not torch.isnan(temp_loss):\n",
    "                    loss += temp_loss\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "\n",
    "            # Optimise\n",
    "            del abstract\n",
    "            del text\n",
    "            del outputs\n",
    "            loss_avg.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            del temp_loss\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "            optimizer.step()\n",
    "            #print(loss.item())\n",
    "        current_loss = np.average(loss_avg)\n",
    "        loss_points.append(current_loss)\n",
    "\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "            .format(epoch+1, 5, current_loss))\n",
    "\n",
    "        eval_loss_avg = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for j, (abstract, text) in enumerate(valid_loader):\n",
    "                abstract = abstract.to(device)\n",
    "                text = text.to(device)\n",
    "\n",
    "                scores = model(abstract, text)\n",
    "                eval_loss = 0\n",
    "                for i in range(scores.shape[1]): # max length for abstract\n",
    "                    temp_loss = criterion(scores[:,i,:], abstract[:,i])\n",
    "                    if not torch.isnan(temp_loss):\n",
    "                        eval_loss += temp_loss\n",
    "                    else:\n",
    "                        break\n",
    "                eval_loss_avg.append(eval_loss.item())\n",
    "                del abstract\n",
    "                del text\n",
    "                del scores\n",
    "                del temp_loss\n",
    "                del eval_loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        current_eval_loss = np.average(eval_loss_avg)\n",
    "        eval_loss_points.append(current_eval_loss)\n",
    "        if (current_eval_loss < best_loss):\n",
    "            best_loss = current_eval_loss\n",
    "            torch.save(model.state_dict(), 'best_decoder.pth')\n",
    "            print(\"Best eval loss updated!\")\n",
    "\n",
    "        print('Valid Epoch [{}/{}], Loss: {:.4f}'\n",
    "            .format(epoch+1, 5, current_eval_loss))\n",
    "    return loss_points, eval_loss_points\n",
    "train_loss, eval_loss = train(train_loader, valid_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_loss\u001b[49m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(eval_loss)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(eval_loss)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train loss','Valid loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>section_names</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4650265</td>\n",
       "      <td>XGBoost: A Scalable Tree Boosting System</td>\n",
       "      <td>['tree boosting is a highly effective and wide...</td>\n",
       "      <td>['introduction', 'tree boosting in a nutshell'...</td>\n",
       "      <td>['']</td>\n",
       "      <td>[['machine learning and data - driven approach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9195903</td>\n",
       "      <td>Robust Face Alignment Using a Mixture of Invar...</td>\n",
       "      <td>['face alignment , which is the task of findin...</td>\n",
       "      <td>['introduction', 'previous work', 'our approac...</td>\n",
       "      <td>['Computer science']</td>\n",
       "      <td>[['face alignment refers to finding the pixel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119332442</td>\n",
       "      <td>Modulation instability associated nonlinear dy...</td>\n",
       "      <td>['we study pattern - forming nonlinear dynamic...</td>\n",
       "      <td>['introduction', 'modulation instability of be...</td>\n",
       "      <td>['Physics']</td>\n",
       "      <td>[['modulation instability ( mi ) is one of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13494452</td>\n",
       "      <td>Free evolution on algebras with two states</td>\n",
       "      <td>['the key result in the paper concerns two tra...</td>\n",
       "      <td>['introduction', 'preliminaries', 'polynomials...</td>\n",
       "      <td>['Mathematics']</td>\n",
       "      <td>[['in a series of papers belinschi and nica in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119269876</td>\n",
       "      <td>Light Dilaton at Fixed Points and Ultra Light ...</td>\n",
       "      <td>['we investigate the infrared dynamics of a no...</td>\n",
       "      <td>['introduction', 'a comment on the large nn an...</td>\n",
       "      <td>['Physics']</td>\n",
       "      <td>[['understanding strong dynamics constitutes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140794</th>\n",
       "      <td>12157610</td>\n",
       "      <td>Minimal and Maximal Operator Spaces and Operat...</td>\n",
       "      <td>['we examine k - minimal and k - maximal opera...</td>\n",
       "      <td>['introduction', 'quantum information theory p...</td>\n",
       "      <td>['Mathematics']</td>\n",
       "      <td>[['a primary goal of this paper is to formally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140795</th>\n",
       "      <td>14690185</td>\n",
       "      <td>AN OBSTRUCTION TO ASYMPTOTIC SEMISTABILITY AND...</td>\n",
       "      <td>['in this paper , we consider an obstruction t...</td>\n",
       "      <td>['introduction', 'statement of results', 'an o...</td>\n",
       "      <td>['Mathematics']</td>\n",
       "      <td>[['for a polarized algebraic manifold inlinefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140796</th>\n",
       "      <td>15296646</td>\n",
       "      <td>Direct Detection of Neutralino Dark Matter and...</td>\n",
       "      <td>['we compare predictions for the spin - indepe...</td>\n",
       "      <td>['introduction', 'msugra', 'more general model...</td>\n",
       "      <td>['Physics']</td>\n",
       "      <td>[['the minimal supersymmetric standard model (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140797</th>\n",
       "      <td>119576690</td>\n",
       "      <td>PCA by Optimisation of Symmetric Functions has...</td>\n",
       "      <td>['principal component analysis ( pca ) finds t...</td>\n",
       "      <td>['introduction', 'pca by determinant optimisat...</td>\n",
       "      <td>['Mathematics']</td>\n",
       "      <td>[['let inlineform0 be a data matrix , with row...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140798</th>\n",
       "      <td>119301470</td>\n",
       "      <td>Turbulent fluxes of entropy and internal energ...</td>\n",
       "      <td>['we derive equations for the mean entropy and...</td>\n",
       "      <td>['introduction', 'turbulent convective flux of...</td>\n",
       "      <td>['Physics']</td>\n",
       "      <td>[['temperature stratified turbulence ( e.g. , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140799 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_id                                              title  \\\n",
       "0         4650265           XGBoost: A Scalable Tree Boosting System   \n",
       "1         9195903  Robust Face Alignment Using a Mixture of Invar...   \n",
       "2       119332442  Modulation instability associated nonlinear dy...   \n",
       "3        13494452         Free evolution on algebras with two states   \n",
       "4       119269876  Light Dilaton at Fixed Points and Ultra Light ...   \n",
       "...           ...                                                ...   \n",
       "140794   12157610  Minimal and Maximal Operator Spaces and Operat...   \n",
       "140795   14690185  AN OBSTRUCTION TO ASYMPTOTIC SEMISTABILITY AND...   \n",
       "140796   15296646  Direct Detection of Neutralino Dark Matter and...   \n",
       "140797  119576690  PCA by Optimisation of Symmetric Functions has...   \n",
       "140798  119301470  Turbulent fluxes of entropy and internal energ...   \n",
       "\n",
       "                                                 abstract  \\\n",
       "0       ['tree boosting is a highly effective and wide...   \n",
       "1       ['face alignment , which is the task of findin...   \n",
       "2       ['we study pattern - forming nonlinear dynamic...   \n",
       "3       ['the key result in the paper concerns two tra...   \n",
       "4       ['we investigate the infrared dynamics of a no...   \n",
       "...                                                   ...   \n",
       "140794  ['we examine k - minimal and k - maximal opera...   \n",
       "140795  ['in this paper , we consider an obstruction t...   \n",
       "140796  ['we compare predictions for the spin - indepe...   \n",
       "140797  ['principal component analysis ( pca ) finds t...   \n",
       "140798  ['we derive equations for the mean entropy and...   \n",
       "\n",
       "                                            section_names  \\\n",
       "0       ['introduction', 'tree boosting in a nutshell'...   \n",
       "1       ['introduction', 'previous work', 'our approac...   \n",
       "2       ['introduction', 'modulation instability of be...   \n",
       "3       ['introduction', 'preliminaries', 'polynomials...   \n",
       "4       ['introduction', 'a comment on the large nn an...   \n",
       "...                                                   ...   \n",
       "140794  ['introduction', 'quantum information theory p...   \n",
       "140795  ['introduction', 'statement of results', 'an o...   \n",
       "140796  ['introduction', 'msugra', 'more general model...   \n",
       "140797  ['introduction', 'pca by determinant optimisat...   \n",
       "140798  ['introduction', 'turbulent convective flux of...   \n",
       "\n",
       "                      domain  \\\n",
       "0                       ['']   \n",
       "1       ['Computer science']   \n",
       "2                ['Physics']   \n",
       "3            ['Mathematics']   \n",
       "4                ['Physics']   \n",
       "...                      ...   \n",
       "140794       ['Mathematics']   \n",
       "140795       ['Mathematics']   \n",
       "140796           ['Physics']   \n",
       "140797       ['Mathematics']   \n",
       "140798           ['Physics']   \n",
       "\n",
       "                                                     text  \n",
       "0       [['machine learning and data - driven approach...  \n",
       "1       [['face alignment refers to finding the pixel ...  \n",
       "2       [['modulation instability ( mi ) is one of the...  \n",
       "3       [['in a series of papers belinschi and nica in...  \n",
       "4       [['understanding strong dynamics constitutes a...  \n",
       "...                                                   ...  \n",
       "140794  [['a primary goal of this paper is to formally...  \n",
       "140795  [['for a polarized algebraic manifold inlinefo...  \n",
       "140796  [['the minimal supersymmetric standard model (...  \n",
       "140797  [['let inlineform0 be a data matrix , with row...  \n",
       "140798  [['temperature stratified turbulence ( e.g. , ...  \n",
       "\n",
       "[140799 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\\'machine learning and data - driven approaches are becoming very important in many areas .\\', \\'smart spam classifiers protect our email by learning from massive amounts of spam data and user feedback ; advertising systems learn to match the right ads with the right context ; fraud detection systems protect banks from malicious attackers ; anomaly event detection systems help experimental physicists to find events that lead to new physics .\\', \\'there are two important factors that drive these successful applications : usage of effective ( statistical ) models that capture the complex data dependencies and scalable learning systems that learn the model of interest from large datasets .\\', \\'among the machine learning methods used in practice , gradient tree boosting   is one technique that shines in many applications .\\', \\'tree boosting has been shown to give state - of - the - art results on many standard classification benchmarks   .\\', \\'lambdamart   , a variant of tree boosting for ranking , achieves state - of - the - art result for ranking problems .\\', \\'besides being used as a stand - alone predictor , it is also incorporated into real - world production pipelines for ad click through rate prediction   .\\', \\'finally , it is the de - facto choice of ensemble method and is used in challenges such as the netflix prize   .\\', \\'in this paper , we describe xgboost , a scalable machine learning system for tree boosting .\\', \\'the system is available as an open source package .\\', \\'the impact of the system has been widely recognized in a number of machine learning and data mining challenges .\\', \\'take the challenges hosted by the machine learning competition site kaggle for example .\\', \"among the 29 challenge winning solutions published at kaggle \\'s blog during 2015 , 17 solutions used xgboost .\", \\'among these solutions , eight solely used xgboost to train the model , while most others combined xgboost with neural nets in ensembles .\\', \\'for comparison , the second most popular method , deep neural nets , was used in 11 solutions .\\', \\'the success of the system was also witnessed in kddcup 2015 , where xgboost was used by every winning team in the top-10 .\\', \\'moreover , the winning teams reported that ensemble methods outperform a well - configured xgboost by only a small amount   .\\', \\'these results demonstrate that our system gives state - of - the - art results on a wide range of problems .\\', \\'examples of the problems in these winning solutions include : store sales prediction ; high energy physics event classification ; web text classification ; customer behavior prediction ; motion detection ; ad click through rate prediction ; malware classification ; product categorization ; hazard risk prediction ; massive online course dropout rate prediction .\\', \\'while domain dependent data analysis and feature engineering play an important role in these solutions , the fact that xgboost is the consensus choice of learner shows the impact and importance of our system and tree boosting .\\', \\'the most important factor behind the success of xgboost is its scalability in all scenarios .\\', \\'the system runs more than ten times faster than existing popular solutions on a single machine and scales to billions of examples in distributed or memory - limited settings .\\', \\'the scalability of xgboost is due to several important systems and algorithmic optimizations .\\', \\'these innovations include : a novel tree learning algorithm is for handling sparse data ; a theoretically justified weighted quantile sketch procedure enables handling instance weights in approximate tree learning .\\', \\'parallel and distributed computing makes learning faster which enables quicker model exploration .\\', \\'more importantly , xgboost exploits out - of - core computation and enables data scientists to process hundred millions of examples on a desktop .\\', \\'finally , it is even more exciting to combine these techniques to make an end - to - end system that scales to even larger data with the least amount of cluster resources .\\', \\'the major contributions of this paper is listed as follows :\\', \\'while there are some existing works on parallel tree boosting the directions such as out - of - core computation , cache - aware and sparsity - aware learning have not been explored .\\', \\'more importantly , an end - to - end system that combines all of these aspects gives a novel solution for real - world use - cases .\\', \\'this enables data scientists as well as researchers to build powerful variants of tree boosting algorithms   .\\', \\'besides these major contributions , we also make additional improvements in proposing a regularized learning objective , which we will include for completeness .\\', \\'the remainder of the paper is organized as follows .\\', \\'we will first review tree boosting and introduce a regularized objective in sec .\\', \\'secref2 .\\', \\'we then describe the split finding methods in sec .\\', \\'secref3 as well as the system design in sec .\\', \\'secref4 , including experimental results when relevant to provide quantitative support for each optimization we describe .\\', \\'related work is discussed in sec .\\', \\'secref5 .\\', \\'detailed end - to - end evaluations are included in sec .\\', \\'secref6 .\\', \\'finally we conclude the paper in sec .\\', \\'secref7 .\\'], [\\'we review gradient tree boosting algorithms in this section .\\', \\'the derivation follows from the same idea in existing literatures in gradient boosting .\\', \\'specicially the second order method is originated from friedman et al .   .\\', \\'we make minor improvements in the reguralized objective , which were found helpful in practice .\\'], [\\'for a given data set with inlineform0 examples and inlineform1 features inlineform2 ( inlineform3 ) , a tree ensemble model ( shown in fig .\\', \\'figref11\\', \\') uses inlineform4 additive functions to predict the output .\\', \\'displayform0\\', \\'where inlineform5 is the space of regression trees ( also known as cart ) .\\', \\'here inlineform6 represents the structure of each tree that maps an example to the corresponding leaf index .\\', \\'inlineform7 is the number of leaves in the tree .\\', \\'each inlineform8 corresponds to an independent tree structure inlineform9 and leaf weights inlineform10 .\\', \\'unlike decision trees , each regression tree contains a continuous score on each of the leaf , we use inlineform11 to represent score on inlineform12 -th leaf .\\', \\'for a given example , we will use the decision rules in the trees ( given by inlineform13 ) to classify it into the leaves and calculate the final prediction by summing up the score in the corresponding leaves ( given by inlineform14 ) .\\', \\'to learn the set of functions used in the model , we minimize the following regularized objective .\\', \\'displayform0\\', \\'here inlineform15 is a differentiable convex loss function that measures the difference between the prediction inlineform16 and the target inlineform17 .\\', \\'the second term inlineform18 penalizes the complexity of the model ( i.e. , the regression tree functions ) .\\', \\'the additional regularization term helps to smooth the final learnt weights to avoid over - fitting .\\', \\'intuitively , the regularized objective will tend to select a model employing simple and predictive functions .\\', \\'a similar regularization technique has been used in regularized greedy forest ( rgf )   model .\\', \\'our objective and the corresponding learning algorithm is simpler than rgf and easier to parallelize .\\', \\'when the regularization parameter is set to zero , the objective falls back to the traditional gradient tree boosting .\\'], [\\'the tree ensemble model in eq .\\', \\'( eqref10 ) includes functions as parameters and can not be optimized using traditional optimization methods in euclidean space .\\', \\'instead , the model is trained in an additive manner .\\', \\'formally , let inlineform19 be the prediction of the inlineform20 -th instance at the inlineform21 -th iteration , we will need to add inlineform22 to minimize the following objective .\\', \\'inlineform23\\', \\'this means we greedily add the inlineform24 that most improves our model according to eq .\\', \\'( eqref10 ) .\\', \\'second - order approximation can be used to quickly optimize the objective in the general setting   .\\', \\'inlineform25\\', \\'where inlineform26 and inlineform27 are first and second\\', \\'order gradient statistics on the loss function .\\', \\'we can remove the constant terms to obtain the following simplified objective at step inlineform28 .\\', \\'displayform0\\', \\'define inlineform29 as the instance set of leaf inlineform30 .\\', \\'we can rewrite eq ( eqref13 ) by expanding inlineform31 as follows displayform0\\', \\'for a fixed structure inlineform32 , we can compute the optimal weight inlineform33 of leaf inlineform34 by displayform0\\', \\'and calculate the corresponding optimal value by displayform0\\', \\'eq ( eqref16 ) can be used as a scoring function to measure the quality of a tree structure inlineform35 .\\', \\'this score is like the impurity score for evaluating decision trees , except that it is derived for a wider range of objective functions .\\', \\'fig .\\', \\'figref17 illustrates how this score can be calculated .\\', \\'normally it is impossible to enumerate all the possible tree structures inlineform36 .\\', \\'a greedy algorithm that starts from a single leaf and iteratively adds branches to the tree is used instead .\\', \\'assume that inlineform37 and inlineform38 are the instance sets of left and right nodes after the split .\\', \\'lettting inlineform39 , then the loss reduction after the split is given by displayform0\\', \\'this formula is usually used in practice for evaluating the split candidates .\\'], [\\'besides the regularized objective mentioned in sec .\\', \\'secref8 , two additional techniques are used to further prevent over - fitting .\\', \\'the first technique is shrinkage introduced by friedman   .\\', \\'shrinkage scales newly added weights by a factor\\', \\'inlineform40\\', \\'after each step of tree boosting .\\', \\'similar to a learning rate in tochastic optimization , shrinkage reduces the influence of each individual tree and leaves space for future trees to improve the model .\\', \\'the second technique is column ( feature ) subsampling .\\', \\'this technique is used in randomforest it is implemented in a commercial software treenet for gradient boosting , but is not implemented in existing opensource packages .\\', \\'according to user feedback , using column sub - sampling prevents over - fitting even more so than the traditional row sub - sampling ( which is also supported ) .\\', \\'the usage of column sub - samples also speeds up computations of the parallel algorithm described later .\\'], [\\'[ t ] exact greedy algorithm for split finding inlineform41 , instance set of current node inlineform42 , feature dimension\\', \\'  inlineform43\\', \\'  inlineform44 , inlineform45\\', \\'  inlineform46 to inlineform47 inlineform48\\', \\'  inlineform49 in sorted ( inlineform50 , by inlineform51 ) inlineform52\\', \\'  inlineform53\\', \\'  inlineform54\\', \\'  split with max score\\', \\'one of the key problems in tree learning is to find the best split as indicated by eq ( eqref18 ) .\\', \\'in order to do so , a split finding algorithm enumerates over all the possible splits on all the features .\\', \\'we call this the exact greedy algorithm .\\', \\'most existing single machine tree boosting implementations , such as scikit - learn   ,\\', \"r \\'s gbm   as well as the single machine version of xgboost support the exact greedy algorithm .\", \\'the exact greedy algorithm is shown in alg .\\', \\'secref21 .\\', \\'it is computationally demanding to enumerate all the possible splits for continuous features .\\', \\'in order to do so efficiently , the algorithm must first sort the data according to feature values and visit the data in sorted order to accumulate the gradient statistics for the structure score in eq ( eqref18 ) .\\'], [\\'[ t ] approximate algorithm for split finding inlineform55 to inlineform56 propose inlineform57 by percentiles on feature inlineform58 .\\', \\'proposal can be done per tree ( global ) , or per split(local ) .\\', \\'inlineform59\\', \\'to inlineform60 inlineform61 inlineform62 follow same step as in previous section to find max score only among proposed splits .\\', \\'the exact greedy algorithm is very powerful since it enumerates over all possible splitting points greedily .\\', \\'however , it is impossible to efficiently do so when the data does not fit entirely into memory .\\', \\'same problem also arises in the distributed setting .\\', \\'to support effective gradient tree boosting in these two settings , an approximate algorithm is needed .\\', \\'we summarize an approximate framework , which resembles the ideas proposed in past literatures in alg .\\', \\'secref22 .\\', \\'to summarize , the algorithm first proposes candidate splitting points according to percentiles of feature distribution ( a specific criteria will be given in sec . secref24 ) .\\', \\'the algorithm then maps the continuous features into buckets split by these candidate points , aggregates the statistics and finds the best solution among proposals based on the aggregated statistics .\\', \\'there are two variants of the algorithm , depending on when the proposal is given .\\', \\'the global variant proposes all the candidate splits during the initial phase of tree construction , and uses the same proposals for split finding at all levels .\\', \\'the local variant re - proposes after each split .\\', \\'the global method requires less proposal steps than the local method .\\', \\'however , usually more candidate points are needed for the global proposal because candidates are not refined after each split .\\', \\'the local proposal refines the candidates after splits , and can potentially be more appropriate for deeper trees .\\', \\'a comparison of different algorithms on a higgs boson dataset is given by fig .\\', \\'figref23 .\\', \\'we find that the local proposal indeed requires fewer candidates .\\', \\'the global proposal can be as accurate as the local one given enough candidates .\\', \\'most existing approximate algorithms for distributed tree learning also follow this framework .\\', \\'notably , it is also possible to directly construct approximate histograms of gradient statistics   .\\', \\'it is also possible to use other variants of binning strategies instead of quantile   .\\', \\'quantile strategy benefit from being distributable and recomputable , which we will detail in next subsection .\\', \\'from fig .\\', \\'figref23 , we also find that the quantile strategy can get the same accuracy as exact greedy given reasonable approximation level .\\', \\'our system efficiently supports exact greedy for the single machine setting , as well as approximate algorithm with both local and global\\', \\'proposal methods for all settings .\\', \\'users can freely choose between the methods according to their needs .\\'], [\\'one important step in the approximate algorithm is to propose candidate split points .\\', \\'usually percentiles of a feature are used to make candidates distribute evenly on the data .\\', \\'formally , let multi - set inlineform63 represent the inlineform64 -th feature values and second order gradient statistics of each training instances .\\', \\'we can define a rank functions inlineform65 as displayform0\\', \\'which represents the proportion of instances whose feature value inlineform66 is smaller than inlineform67 .\\', \\'the goal is to find candidate split points inlineform68 ,\\', \\'such that displayform0\\', \\'  here inlineform69 is an approximation factor .\\', \\'intuitively , this means that there is roughly inlineform70 candidate points .\\', \\'here each data point is weighted by inlineform71 .\\', \\'to see why inlineform72 represents the weight , we can rewrite eq ( eqref13 ) as inlineform73\\', \\'which is exactly weighted squared loss with labels inlineform74 and weights inlineform75 .\\', \\'for large datasets , it is non - trivial to find candidate splits that satisfy the criteria .\\', \\'when every instance has equal weights , an existing algorithm called quantile sketch   ,   solves the problem .\\', \\'however , there is no existing quantile sketch for the weighted datasets .\\', \\'therefore , most existing approximate algorithms either resorted to sorting on a random subset of data which have a chance of failure or heuristics that do not have theoretical guarantee .\\', \\'to solve this problem , we introduced a novel distributed weighted quantile sketch algorithm that can handle weighted data with a provable theoretical guarantee .\\', \\'the general idea is to propose a data structure that supports merge and prune operations , with each operation proven to maintain a certain accuracy level .\\', \\'a detailed description of the algorithm as well as proofs are given in the appendix .\\'], [\\'[ ! t ] sparsity - aware split finding inlineform76 , instance set of current node inlineform77 inlineform78 , feature dimension also applies to the approximate setting , only collect statistics of non - missing entries into buckets\\', \\'  inlineform79\\', \\'  inlineform80 , inlineform81\\', \\'  inlineform82 to inlineform83 //\\', \\'enumerate missing value goto\\', \\'right\\', \\'  inlineform84\\', \\'  inlineform85 in sorted ( inlineform86 , ascent order by inlineform87 ) inlineform88\\', \\'  inlineform89\\', \\'  inlineform90\\', \\'  //\\', \\'enumerate missing value goto left\\', \\'  inlineform91\\', \\'  inlineform92 in sorted ( inlineform93 , descent order by inlineform94 ) inlineform95\\', \\'  inlineform96\\', \\'  inlineform97\\', \\'  split and default directions with max gain\\', \\'in many real - world problems , it is quite common for the input inlineform98 to be sparse .\\', \\'there are multiple possible causes for sparsity : 1 ) presence of missing values in the data ; 2 ) frequent zero entries in the statistics ; and , 3 ) artifacts of feature engineering such as one - hot encoding .\\', \\'it is important to make the algorithm aware of the sparsity pattern in the data .\\', \\'in order to do so , we propose to add a default direction in each tree node , which is shown in fig .\\', \\'figref28 .\\', \\'when a value is missing in the sparse matrix inlineform99 , the instance is classified into the default direction .\\', \\'there are two choices of default direction in each branch .\\', \\'the optimal default directions are learnt from the data .\\', \\'the algorithm is shown in alg .\\', \\'secref27 .\\', \\'the key improvement is to only visit the non - missing entries\\', \\'inlineform100 .\\', \\'the presented algorithm treats the non - presence as a missing value and learns the best direction to handle missing values .\\', \\'the same algorithm can also be applied when the non - presence corresponds to a user specified value by limiting the enumeration only to consistent solutions .\\', \\'to the best of our knowledge , most existing tree learning algorithms are either only optimized for dense data , or need specific procedures to handle limited cases such as categorical encoding .\\', \\'xgboost handles all sparsity patterns in a unified way .\\', \\'more importantly , our method exploits the sparsity to make computation complexity linear to number of non - missing entries in the input .\\', \\'fig .\\', \\'figref29 shows the comparison of sparsity aware and a naive implementation on an allstate-10k dataset ( description of dataset given in sec .\\', \\'secref6 ) .\\', \\'we find that the sparsity aware algorithm runs 50 times faster than the naive version .\\', \\'this confirms the importance of the sparsity aware algorithm .\\'], [\\'the most time consuming part of tree learning is to get the data into sorted order .\\', \\'in order to reduce the cost of sorting , we propose to store the data in in - memory units , which we called block .\\', \\'data in each block is stored in the compressed column ( csc ) format , with each column sorted by the corresponding feature value .\\', \\'this input data layout only needs to be computed once before training , and can be reused in later iterations .\\', \\'in the exact greedy algorithm , we store the entire dataset in a single block and run the split search algorithm by linearly scanning over the pre - sorted entries .\\', \\'we do the split finding of all leaves collectively , so one scan over the block will collect the statistics of the split candidates in all leaf branches .\\', \\'fig .\\', \\'figref30 shows how we transform a dataset into the format and find the optimal split using the block structure .\\', \\'the block structure also helps when using the approximate algorithms .\\', \\'multiple blocks can be used in this case , with each block corresponding to subset of rows in the dataset .\\', \\'different blocks can be distributed across machines , or stored on disk in the out - of - core setting .\\', \\'using the sorted structure , the quantile finding step becomes a linear scan over the sorted columns .\\', \\'this is especially valuable for local proposal algorithms , where candidates are generated frequently at each branch .\\', \\'the binary search in histogram aggregation also becomes a linear time merge style algorithm .\\', \\'collecting statistics for each column can be parallelized , giving us a parallel algorithm for split finding .\\', \\'importantly , the column block structure also supports column subsampling , as it is easy to select a subset of columns in a block .\\', \\'time complexity analysis let inlineform101 be the maximum depth of the tree and\\', \\'inlineform102 be total number of trees .\\', \\'for the exact greedy algorithm , the time complexity of original spase\\', \\'aware algorithm is inlineform103 .\\', \\'here we use inlineform104 to denote number of non - missing entries in the training data .\\', \\'on the other hand , tree boosting on the block structure only cost inlineform105 .\\', \\'here inlineform106 is the one time preprocessing cost that can be amortized .\\', \\'this analysis shows that the block structure helps to save an additional inlineform107 factor , which is significant when inlineform108 is large .\\', \\'for the approximate algorithm , the time complexity of original algorithm with binary search is inlineform109 .\\', \\'here inlineform110 is the number of proposal candidates in the dataset .\\', \\'while inlineform111 is usually between 32 and 100 , the log factor still introduces overhead .\\', \\'using the block structure , we can reduce the time to inlineform112 , where inlineform113 is the maximum number of rows in each block .\\', \\'again we can save the additional inlineform114 factor in computation .\\'], [\\'while the proposed block structure helps optimize the computation complexity of split finding , the new algorithm requires indirect fetches of gradient statistics by row index , since these values are accessed in order of feature .\\', \\'this is a non - continuous memory access .\\', \\'a naive implementation of split enumeration introduces immediate read / write dependency between the accumulation and the non - continuous memory fetch operation ( see fig . figref38 ) .\\', \\'this slows down split finding when the gradient statistics do not fit into cpu cache and cache miss\\', \\'occur .\\', \\'for the exact greedy algorithm , we can alleviate the problem by a cache - aware prefetching algorithm .\\', \\'specifically , we allocate an internal buffer in each thread , fetch the gradient statistics into it , and then perform accumulation in a mini - batch manner .\\', \\'this prefetching changes the direct read / write dependency to a longer dependency and helps to reduce the runtime overhead when number of rows in the is large .\\', \\'figure figref31 gives the comparison of cache - aware vs. non cache - aware algorithm on the the higgs and the allstate dataset .\\', \\'we find that cache - aware implementation of the exact greedy algorithm runs twice as fast as the naive version when the dataset is large .\\', \\'for approximate algorithms , we solve the problem by choosing a correct block size .\\', \\'we define the block size to be maximum number of examples in contained in a block , as this reflects the cache storage cost of gradient statistics .\\', \\'choosing an overly small block size results in small workload for each thread and leads to inefficient parallelization .\\', \\'on the other hand , overly large blocks result in cache misses , as the gradient statistics do not fit into the cpu cache .\\', \\'a good choice of block size balances these two factors .\\', \\'we compared various choices of block size on two data sets .\\', \\'the results are given in fig .\\', \\'figref39 .\\', \\'this result validates our discussion and shows that choosing inlineform115 examples per block balances the cache property and parallelization .\\'], [\"one goal of our system is to fully utilize a machine \\'s resources to achieve scalable learning .\", \\'besides processors and memory , it is important to utilize disk space to handle data that does not fit into main memory .\\', \\'to enable out - of - core computation , we divide the data into multiple blocks and store each block on disk .\\', \\'during computation , it is important to use an independent thread to pre - fetch the block into a main memory buffer , so computation can happen in concurrence with disk reading .\\', \\'however , this does not entirely solve the problem since the disk reading takes most of the computation time .\\', \\'it is important to reduce the overhead and increase the throughput of disk io .\\', \\'we mainly use two techniques to improve the out - of - core computation .\\', \\'block compression\\', \\'the first technique we use is block compression .\\', \\'the block is compressed by columns , and decompressed on the fly by an independent thread when loading into main memory .\\', \\'this helps to trade some of the computation in decompression with the disk reading cost .\\', \\'we use a general purpose compression algorithm for compressing the features values .\\', \\'for the row index , we substract the row index by the begining index of the block and use a 16bit integer to store each offset .\\', \\'this requires inlineform116 examples per block , which is confirmed to be a good setting .\\', \\'in most of the dataset we tested , we achieve roughly a 26 % to 29 % compression ratio .\\', \\'block sharding the second technique is to shard the data onto multiple disks in an alternative manner .\\', \\'a pre - fetcher thread is assigned to each disk and fetches the data into an in - memory buffer .\\', \\'the training thread then alternatively reads the data from each buffer .\\', \\'this helps to increase the throughput of disk reading when multiple disks are available .\\'], [\\'our system implements gradient boosting   , which performs additive optimization in functional space .\\', \\'gradient tree boosting has been successfully used in classification   , learning to rank   , structured prediction   as well as other fields .\\', \\'xgboost incorporates a regularized model to prevent overfitting .\\', \\'this this resembles previous work on regularized greedy forest   , but simplifies the objective and algorithm for parallelization .\\', \\'column sampling is a simple but effective technique borrowed from randomforest   .\\', \\'while sparsity - aware learning is essential in other types of models such as linear models   , few works on tree learning have considered this topic in a principled way .\\', \\'the algorithm proposed in this paper is the first unified approach to handle all kinds of sparsity patterns .\\', \\'there are several existing works on parallelizing tree learning   .\\', \\'most of these algorithms fall into the approximate framework described in this paper .\\', \\'notably , it is also possible to partition data by columns   and apply the exact greedy algorithm .\\', \\'this is also supported in our framework , and the techniques such as cache - aware pre - fecthing can be used to benefit this type of algorithm .\\', \\'while most existing works focus on the algorithmic aspect of parallelization , our work improves in two unexplored system directions : out - of - core computation and cache - aware learning .\\', \\'this gives us insights on how the system and the algorithm can be jointly optimized and provides an end - to - end system that can handle large scale problems with very limited computing resources .\\', \\'we also summarize the comparison between our system and existing opensource implementations in table tabref42 .\\', \\'quantile summary ( without weights ) is a classical problem in the database community   .\\', \\'however , the approximate tree boosting algorithm reveals a more general problem – finding quantiles on weighted data .\\', \\'to the best of our knowledge , the weighted quantile sketch proposed in this paper is the first method to solve this problem .\\', \\'the weighted quantile summary is also not specific to the tree learning and can benefit other applications in data science and machine learning in the future .\\'], [\\'we implemented xgboost as an open source package .\\', \\'the package is portable and reusable .\\', \\'it supports various weighted classification and rank objective functions , as well as\\', \\'user defined objective function .\\', \\'it is available in popular languages such as python , r , julia and integrates naturally with language native data science pipelines such as scikit - learn .\\', \\'the distributed version is built on top of the rabit library for allreduce .\\', \\'the portability of xgboost makes it available in many ecosystems , instead of only being tied to a specific platform .\\', \\'the distributed xgboost runs natively on hadoop , mpi sun grid engine .\\', \\'recently , we also enable distributed xgboost on jvm bigdata stacks such as flink and spark .\\', \\'the distributed version has also been integrated into cloud platform tianchi of alibaba .\\', \\'we believe that there will be more integrations in the future .\\'], [\\'we used four datasets in our experiments .\\', \\'a summary of these datasets is given in table tabref49 .\\', \\'in some of the experiments , we use a randomly selected subset of the data either due to slow baselines or to demonstrate the performance of the algorithm with varying dataset size .\\', \\'we use a suffix to denote the size in these cases .\\', \\'for example allstate-10k means a subset of the allstate dataset with 10k instances .\\', \\'the first dataset we use is the allstate insurance claim dataset .\\', \\'the task is to predict the likelihood and cost of an insurance claim given different risk factors .\\', \\'in the experiment , we simplified the task to only predict the likelihood of an insurance claim .\\', \\'this dataset is used to evaluate the impact of sparsity - aware algorithm in sec .\\', \\'secref27 .\\', \\'most of the sparse features in this data come from one - hot encoding .\\', \\'we randomly select 10 m instances as training set and use the rest as evaluation set .\\', \\'the second dataset is the higgs boson dataset from high energy physics .\\', \\'the data was produced using monte carlo simulations of physics events .\\', \\'it contains 21 kinematic properties measured by the particle detectors in the accelerator .\\', \\'it also contains seven additional derived physics quantities of the particles .\\', \\'the task is to classify whether an event corresponds to the higgs boson .\\', \\'we randomly select 10 m instances as training set and use the rest as evaluation set .\\', \\'the third dataset is the yahoo !\\', \\'learning to rank challenge dataset   , which is one of the most commonly used benchmarks in learning to rank algorithms .\\', \\'the dataset contains 20k web search queries , with each query corresponding to a list of around 22 documents .\\', \\'the task is to rank the documents according to relevance of the query .\\', \\'we use the official train test split in our experiment .\\', \\'the last dataset is the criteo terabyte click log dataset .\\', \\'we use this dataset to evaluate the scaling property of the system in the out - of - core and the distributed settings .\\', \\'the data contains 13 integer features and 26 i d features of user , item and advertiser information .\\', \\'since a tree based model is better at handling continuous features , we preprocess the data by calculating the statistics of average ctr and count of i d features on the first ten days , replacing the i d features by the corresponding count statistics during the next ten days for training .\\', \\'the training set after preprocessing contains 1.7 billion instances with 67 features ( 13 integer , 26 average ctr statistics and 26 counts ) .\\', \\'the entire dataset is more than one terabyte in libsvm format .\\', \\'we use the first three datasets for the single machine parallel setting , and the last dataset for the distributed and out - of - core settings .\\', \\'all the single machine experiments are conducted on a dell poweredge r420 with two eight - core intel xeon ( e5 - 2470 )\\', \\'( 2.3ghz ) and 64 gb of memory .\\', \\'if not specified , all the experiments are run using all the available cores in the machine .\\', \\'the machine settings of the distributed and the out - of - core experiments will be described in the corresponding section .\\', \\'in all the experiments , we boost trees with a common setting of maximum depth equals 8 , shrinkage equals 0.1 and no column subsampling unless explicitly specified .\\', \\'we can find similar results when we use other settings of maximum depth .\\'], [\\'in this section , we evaluate the performance of xgboost on a single machine using the exact greedy algorithm on higgs-1 m data , by comparing it against two other commonly used exact greedy tree boosting implementations .\\', \\'since scikit - learn only handles non - sparse input , we choose the dense higgs dataset for a fair comparison .\\', \\'we use the 1 m subset to make scikit - learn finish running in reasonable time .\\', \"among the methods in comparison , r \\'s gbm uses a greedy approach that only expands one branch of a tree , which makes it faster but can result in lower accuracy , while both scikit - learn and xgboost learn a full tree .\", \\'the results are shown in table tabref54 .\\', \"both xgboost and scikit - learn give better performance than r \\'s gbm , while xgboost runs more than 10x faster than scikit - learn .\", \\'in this experiment , we also find column subsamples gives slightly worse performance than using all the features .\\', \\'this could due to the fact that there are few important features in this dataset and we can benefit from greedily select from all the features .\\'], [\\'we next evaluate the performance of xgboost on the learning to rank problem .\\', \\'we compare against pgbrt   , the best previously pubished system on this task .\\', \\'xgboost runs exact greedy algorithm , while pgbrt only support an approximate algorithm .\\', \\'the results are shown in table tabref57 and fig .\\', \\'figref56 .\\', \\'we find that xgboost runs faster .\\', \\'interestingly , subsampling columns not only reduces running time , and but also gives a bit higher performance for this problem .\\', \\'this could due to the fact that the subsampling helps prevent overfitting , which is observed by many of the users .\\'], [\\'we also evaluate our system in the out - of - core setting on the criteo data .\\', \\'we conducted the experiment on one aws c3.8xlarge machine ( 32 vcores , two 320 gb ssd , 60 gb ram ) .\\', \\'the results are shown in figure figref58 .\\', \\'we can find that compression helps to speed up computation by factor of three , and sharding into two disks further gives 2x speedup .\\', \\'for this type of experiment , it is important to use a very large dataset to drain the system file cache for a real out - of - core setting .\\', \\'this is indeed our setup .\\', \\'we can observe a transition point when the system runs out of file cache .\\', \\'note that the transition in the final method is less dramatic .\\', \\'this is due to larger disk throughput and better utilization of computation resources .\\', \\'our final method is able to process 1.7 billion examples on a single machine .\\'], [\\'finally , we evaluate the system in the distributed setting .\\', \\'we set up a yarn cluster on ec2 with m3.2xlarge machines , which is a very common choice for clusters .\\', \\'each machine contains 8 virtual cores ,\\', \\'30 gb of ram and two 80 gb ssd local disks .\\', \\'the dataset is stored on aws s3 instead of hdfs to avoid purchasing persistent storage .\\', \\'we first compare our system against two production - level distributed systems : spark mllib   and h2o .\\', \\'we use 32 m3.2xlarge machines and test the performance of the systems with various input size .\\', \\'both of the baseline systems are in - memory analytics frameworks that need to store the data in ram , while xgboost can switch to out - of - core setting when it runs out of memory .\\', \\'the results are shown in fig .\\', \\'figref59 .\\', \\'we can find that xgboost runs faster than the baseline systems .\\', \\'more importantly , it is able to take advantage of out - of - core computing and smoothly scale to all 1.7 billion examples with the given limited computing resources .\\', \\'the baseline systems are only able to handle subset of the data with the given resources .\\', \\'this experiment shows the advantage to bring all the system improvement together and solve a real - world scale problem .\\', \\'we also evaluate the scaling property of xgboost by varying the number of machines .\\', \\'the results are shown in fig .\\', \\'figref62 .\\', \"we can find xgboost \\'s performance scales linearly as we add more machines .\", \\'importantly , xgboost is able to handle the entire 1.7 billion data with only four machines .\\', \"this shows the system \\'s potential to handle even larger data .\"], [\\'in this paper , we described the lessons we learnt when building xgboost , a scalable tree boosting system that is widely used by data scientists and provides state - of - the - art results on many problems .\\', \\'we proposed a novel sparsity aware algorithm for handling sparse data and a theoretically justified weighted quantile sketch for approximate learning .\\', \\'our experience shows that cache access patterns , data compression and sharding are essential elements for building a scalable end - to - end system for tree boosting .\\', \\'these lessons can be applied to other machine learning systems as well .\\', \\'by combining these insights , xgboost is able to solve real - world scale problems using a minimal amount of resources .\\'], [\\'  we would like to thank tyler b. johnson , marco tulio ribeiro , sameer singh , arvind krishnamurthy for their valuable feedback .\\', \\'we also sincerely thank tong\\', \\'he , bing xu , michael benesty , yuan tang , hongliang liu , qiang kou , nan zhu and all other contributors in the xgboost community .\\', \\'this work was supported in part by onr ( pecase ) n000141010672 , nsf iis 1258741 and the terraswarm research center sponsored by marco and darpa .\\'], [\\'given an input multi - set inlineform118 such that inlineform119 .\\', \\'each inlineform120 corresponds to a position of the point and inlineform121 is the weight of the point .\\', \\'assume we have a total order inlineform122 defined on inlineform123 .\\', \\'let us define two rank functions\\', \\'inlineform124 displayform0\\', \\'  displayform0\\', \\'we should note that since inlineform125 is defined to be a multiset of the points .\\', \\'it can contain multiple record with exactly same position inlineform126 and weight inlineform127 .\\', \\'we also define another weight function\\', \\'inlineform128 as displayform0\\', \\'finally , we also define the weight of multi - set inlineform129 to be the sum of weights of all the points in the set displayform0\\', \\'our task is given a series of input inlineform130 , to estimate inlineform131 and inlineform132 for inlineform133 as well as finding points with specific rank .\\', \\'given these notations , we define quantile summary of weighted examples as follows :\\', \\'definition 8.1 quantile summary of weighted data\\', \\'a quantile summary for inlineform134 is defined to be tuple\\', \\'inlineform135 , where inlineform136 is selected from the points in inlineform137 ( i.e. inlineform138 ) with the following properties :\\', \\'1 ) inlineform139 , and inlineform140 and inlineform141 are minimum and maximum point in inlineform142 : inlineform143\\', \\'2 ) inlineform144 , inlineform145 and inlineform146 are functions in inlineform147 , that satisfies displayform0\\', \\'the equality sign holds for maximum and minimum point ( inlineform148 , inlineform149 and inlineform150 for inlineform151 ) .\\', \\'finally , the function value must also satisfy the following constraints displayform0\\', \\'since these functions are only defined on inlineform152 , it is suffice to use inlineform153 record to store the summary .\\', \\'specifically , we need to remember each inlineform154 and the corresponding function values of each inlineform155 .\\', \\'definition 8.2 extension of function domains\\', \\'given a quantile summary inlineform156 defined in definition uid73 , the domain of inlineform157 ,\\', \\'inlineform158 and inlineform159 were defined only in inlineform160 .\\', \\'we extend the definition of these functions to inlineform161 as follows\\', \\'when inlineform162 : displayform0\\', \\'when inlineform163 : displayform0\\', \\'when inlineform164 for some inlineform165 : displayform0\\', \\'lemma 8.1 extended constraint\\', \\'the extended definition of inlineform166 , inlineform167 , inlineform168 satisfies the following constraints\\', \\'displayform0\\', \\'  displayform0\\', \\'the only non - trivial part is to prove the case when inlineform169 :\\', \\'inlineform170\\', \\'  inlineform171\\', \\'this proves eq .\\', \\'( eqref81 ) .\\', \\'furthermore , we can verify that inlineform172\\', \\'  inlineform173\\', \\'  inlineform174\\', \\'using these facts and transitivity of inlineform175 relation , we can prove eq .\\', \\'( eqref82 )\\', \\'we should note that the extension is based on the ground case defined in inlineform176 , and we do not require extra space to store the summary in order to use the extended definition .\\', \\'we are now ready to introduce the definition of inlineform177 -approximate quantile summary .\\', \\'definition 8.3 inlineform178 -approximate quantile summary\\', \\'given a quantile summary inlineform179 , we call it is\\', \\'inlineform180 -approximate summary if for any inlineform181 displayform0\\', \\'we use this definition since we know that inlineform182 and inlineform183 .\\', \\'eq .\\', \\'( eqref84 ) means the we can get estimation of inlineform184 and inlineform185 by error of at most inlineform186 .\\', \\'lemma\\', \\'8.2 quantile summary inlineform187 is an inlineform188 -approximate summary if and only if the following two condition holds displayform0\\', \\'  displayform0\\', \\'  the key is again consider inlineform189 inlineform190\\', \\'this means the condition in eq .\\', \\'( eqref87 ) plus eq .\\', \\'( eqref86 ) can give us eq .\\', \\'( eqref84 )\\', \\'property of extended function in this section , we have introduced the extension of function inlineform191 to inlineform192 .\\', \\'the key theme discussed in this section is the relation of constraints on the original function and constraints on the extended function .\\', \\'lemma uid80 and uid85 show that the constraints on the original function can lead to in more general constraints on the extended function .\\', \\'this is a very useful property which will be used in the proofs in later sections .\\'], [\\'given a small multi - set inlineform193 , we can construct initial summary inlineform194 , with inlineform195 to the set of all values in inlineform196 ( inlineform197 ) , and inlineform198 defined to be displayform0\\', \\'the constructed summary is 0-approximate summary , since it can answer all the queries accurately .\\', \\'the constructed summary can be feed into future operations described in the latter sections .\\'], [\\'in this section , we define how we can merge the two summaries together .\\', \\'assume we have inlineform199 and\\', \\'inlineform200 quantile summary of two dataset inlineform201 and inlineform202 .\\', \\'let inlineform203 , and define the merged summary inlineform204 as follows .\\', \\'displayform0\\', \\'the points in inlineform205 are combination of points in inlineform206\\', \\'and inlineform207 .\\', \\'and the function inlineform208 are defined to be displayform0\\', \\'  displayform0\\', \\'  displayform0\\', \\'here we use functions defined on inlineform209 on the left sides of equalities and use the extended function definitions on the right sides .\\', \\'due to additive nature of inlineform210 , inlineform211\\', \\'and inlineform212 , which can be formally written as displayform0\\', \\'and the extended constraint property in lemma uid80 , we can verify that inlineform213 satisfies all the constraints in definition\\', \\'uid73 .\\', \\'therefore it is a valid quantile summary .\\', \\'lemma 8.3\\', \\'the combined quantile summary satisfies displayform0\\', \\'  displayform0\\', \\'  displayform0\\', \\'for all inlineform214\\', \\'this can be obtained by straight - forward application of definition uid76 .\\', \\'theorem 8.1 if inlineform215 is inlineform216 -approximate summary , and inlineform217 is inlineform218 -approximate summary .\\', \\'then the merged summary inlineform219 is inlineform220 -approximate summary .\\', \\'for any inlineform221 , we have inlineform222\\', \\'here the first inequality is due to lemma uid96 .\\'], [\\'[ t ] query function\\', \\'inlineform223\\', \\'inlineform224 :\\', \\'inlineform225 inlineform226 where inlineform227 inlineform228\\', \\'inlineform229\\', \\'inlineform230 inlineform231 find inlineform232 such that\\', \\'inlineform233\\', \\'  inlineform234\\', \\'inlineform235\\', \\'inlineform236\\', \\'before we start discussing the prune operation , we first introduce a query function inlineform237 .\\', \\'the definition of function is shown in algorithm secref101 .\\', \\'for a given rank inlineform238 , the function returns a inlineform239 whose rank is close to inlineform240 .\\', \\'this property is formally described in the following lemma .\\', \\'lemma 8.4 for a given inlineform241 -approximate summary inlineform242 , inlineform243 satisfies the following property displayform0\\', \\'we need to discuss four possible cases\\', \\'  inlineform244 and inlineform245 .\\', \\'note that the rank information for inlineform246 is accurate\\', \\'( inlineform247 , inlineform248 ) , we have inlineform249\\', \\'  inlineform250 and inlineform251 , then inlineform252\\', \\'  inlineform253 in the general case , then inlineform254\\', \\'  inlineform255 in the general case inlineform256\\', \\'now we are ready to introduce the prune operation .\\', \\'given a quantile summary inlineform257 with inlineform258 elements , and a memory budget inlineform259 .\\', \\'the prune operation creates another summary inlineform260 with inlineform261 , where inlineform262 are selected by query the original summary\\', \\'such that\\', \\'inlineform263\\', \\'the definition of inlineform264 in inlineform265 is copied from original summary inlineform266 , by restricting input domain from inlineform267 to inlineform268 .\\', \\'there could be duplicated entries in the inlineform269 .\\', \\'these duplicated entries can be safely removed to further reduce the memory cost .\\', \\'since all the elements in inlineform270 comes from inlineform271 , we can verify that inlineform272 satisfies all the constraints in definition uid73 and is a valid quantile summary .\\', \\'theorem 8.2 let inlineform273 be the summary pruned from an inlineform274 -approximate quantile summary inlineform275 with inlineform276 memory budget .\\', \\'then inlineform277 is a inlineform278 -approximate summary .\\', \\'we only need to prove the property in eq .\\', \\'( eqref87 ) for inlineform279 .\\', \\'using lemma uid102 , we have inlineform280\\', \\'combining these inequalities gives inlineform281\\']]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_lengths(df):\n",
    "    ratio = []\n",
    "    for i,row in df.iterrows():\n",
    "        article = len(row[\"article\"].split())\n",
    "        highlight = len(row[\"highlights\"].split())\n",
    "        if (i==137538):\n",
    "            print(row[\"article\"])\n",
    "            print(\"---------------------\")\n",
    "            print(row[\"highlights\"])\n",
    "        ratio.append(highlight/article)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downton Abbey's famously grim butler, Mr Bates .\n",
      "---------------------\n",
      "And now for the good news . . . Following a particularly grim week, here’s a compendium of some of the world’s most comforting headlines: .\n",
      "Supermodel Smiles On Catwalk .\n",
      "Jack Russell Dog Welcomes Stranger .\n",
      "Child At Funfair ‘Delighted’ By Goldfish .\n",
      "Katie Price Breasts ‘Roughly Same Size As Last Week’ Say Experts .\n",
      "Teenager Looks Up From Phone, Greets Parent .\n",
      "Political Pundits Agree To Stop Discussing Hung Parliament For Next Three Months .\n",
      "Diner Finishes His Curly Kale .\n",
      "Pensioner Looks Great In Party Hat .\n",
      "Celebrity Fails To Compare Life To Roller-coaster .\n",
      "Pet Hamster Repays Child’s Affection .\n",
      "‘Cheer Up, It May Never Happen’ — Downton’s Mr Bates Enjoys Belly-laugh .\n",
      "Style Journalist Fails To Employ The Word ‘Iconic’\n",
      "Sally Bercow Goes Out On Town, Retains Dignity .\n",
      "Entire Windfarm Operates According To Plan .\n",
      "Miley Cyrus Feels A Bit Chilly, Opts For Extra Layer .\n"
     ]
    }
   ],
   "source": [
    "ratio = get_df_lengths(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18686868686868688,\n",
       " 0.09693877551020408,\n",
       " 0.0853960396039604,\n",
       " 0.09981167608286252,\n",
       " 0.11551724137931034,\n",
       " 0.12574850299401197,\n",
       " 0.03099730458221024,\n",
       " 0.08695652173913043,\n",
       " 0.09688013136288999,\n",
       " 0.06306306306306306,\n",
       " 0.09338235294117647,\n",
       " 0.09428129829984544,\n",
       " 0.04805914972273567,\n",
       " 0.14903846153846154,\n",
       " 0.05941845764854614,\n",
       " 0.12058212058212059,\n",
       " 0.03619909502262444,\n",
       " 0.05114029025570145,\n",
       " 0.14392059553349876,\n",
       " 0.09248554913294797,\n",
       " 0.11290322580645161,\n",
       " 0.06223175965665236,\n",
       " 0.025252525252525252,\n",
       " 0.0670807453416149,\n",
       " 0.07357357357357357,\n",
       " 0.059931506849315065,\n",
       " 0.0497335701598579,\n",
       " 0.04749512036434613,\n",
       " 0.22916666666666666,\n",
       " 0.12189616252821671,\n",
       " 0.10119840213049268,\n",
       " 0.04323094425483504,\n",
       " 0.09049773755656108,\n",
       " 0.022063208109719738,\n",
       " 0.10561797752808989,\n",
       " 0.16293929712460065,\n",
       " 0.058163265306122446,\n",
       " 0.11014492753623188,\n",
       " 0.04020979020979021,\n",
       " 0.13213213213213212,\n",
       " 0.1079734219269103,\n",
       " 0.05200945626477541,\n",
       " 0.07241379310344828,\n",
       " 0.07616707616707617,\n",
       " 0.09510869565217392,\n",
       " 0.11284722222222222,\n",
       " 0.13166144200626959,\n",
       " 0.08482142857142858,\n",
       " 0.07086614173228346,\n",
       " 0.03248099516240498,\n",
       " 0.1076555023923445,\n",
       " 0.08943089430894309,\n",
       " 0.07090103397341212,\n",
       " 0.07272727272727272,\n",
       " 0.03939393939393939,\n",
       " 0.06487341772151899,\n",
       " 0.0389321468298109,\n",
       " 0.076163610719323,\n",
       " 0.055842812823164424,\n",
       " 0.13648293963254593,\n",
       " 0.040634291377601585,\n",
       " 0.07153284671532846,\n",
       " 0.20555555555555555,\n",
       " 0.09803921568627451,\n",
       " 0.024691358024691357,\n",
       " 0.05551149881046788,\n",
       " 0.07025411061285501,\n",
       " 0.08278145695364239,\n",
       " 0.052083333333333336,\n",
       " 0.13564668769716087,\n",
       " 0.07599118942731277,\n",
       " 0.10480349344978165,\n",
       " 0.116600790513834,\n",
       " 0.05077262693156733,\n",
       " 0.056676272814601344,\n",
       " 0.07973421926910298,\n",
       " 0.10470588235294118,\n",
       " 0.08161512027491409,\n",
       " 0.02046204620462046,\n",
       " 0.050808314087759814,\n",
       " 0.14105793450881612,\n",
       " 0.04881656804733728,\n",
       " 0.13653136531365315,\n",
       " 0.12142038946162657,\n",
       " 0.07822085889570553,\n",
       " 0.06643356643356643,\n",
       " 0.10251450676982592,\n",
       " 0.046255506607929514,\n",
       " 0.015037593984962405,\n",
       " 0.05555555555555555,\n",
       " 0.04645161290322581,\n",
       " 0.18543046357615894,\n",
       " 0.13921901528013583,\n",
       " 0.11219512195121951,\n",
       " 0.09090909090909091,\n",
       " 0.03052805280528053,\n",
       " 0.15471698113207547,\n",
       " 0.19631901840490798,\n",
       " 0.14532019704433496,\n",
       " 0.03944315545243619,\n",
       " 0.1456953642384106,\n",
       " 0.0974264705882353,\n",
       " 0.037383177570093455,\n",
       " 0.08912655971479501,\n",
       " 0.09859154929577464,\n",
       " 0.14320388349514562,\n",
       " 0.03433835845896147,\n",
       " 0.04825090470446321,\n",
       " 0.07600950118764846,\n",
       " 0.04100946372239748,\n",
       " 0.16829268292682928,\n",
       " 0.05714285714285714,\n",
       " 0.09340659340659341,\n",
       " 0.08695652173913043,\n",
       " 0.10645724258289703,\n",
       " 0.07947019867549669,\n",
       " 0.16831683168316833,\n",
       " 0.044534412955465584,\n",
       " 0.11504424778761062,\n",
       " 0.03903477643718949,\n",
       " 0.2391304347826087,\n",
       " 0.15202702702702703,\n",
       " 0.1890547263681592,\n",
       " 0.13882863340563992,\n",
       " 0.17880794701986755,\n",
       " 0.04878048780487805,\n",
       " 0.09742120343839542,\n",
       " 0.03532008830022075,\n",
       " 0.07425742574257425,\n",
       " 0.07449856733524356,\n",
       " 0.056838365896980464,\n",
       " 0.08280254777070063,\n",
       " 0.03932151117964534,\n",
       " 0.1945031712473573,\n",
       " 0.06229860365198711,\n",
       " 0.08353221957040573,\n",
       " 0.07523510971786834,\n",
       " 0.18796992481203006,\n",
       " 0.06351351351351352,\n",
       " 0.14285714285714285,\n",
       " 0.09662921348314607,\n",
       " 0.12324929971988796,\n",
       " 0.05623471882640587,\n",
       " 0.234375,\n",
       " 0.09444444444444444,\n",
       " 0.032407407407407406,\n",
       " 0.07636887608069164,\n",
       " 0.06053268765133172,\n",
       " 0.08009708737864078,\n",
       " 0.06,\n",
       " 0.11635220125786164,\n",
       " 0.060221870047543584,\n",
       " 0.06155632984901278,\n",
       " 0.18719211822660098,\n",
       " 0.04461942257217848,\n",
       " 0.05394190871369295,\n",
       " 0.056768558951965066,\n",
       " 0.03225806451612903,\n",
       " 0.07341269841269842,\n",
       " 0.10112359550561797,\n",
       " 0.060203283815480846,\n",
       " 0.2037037037037037,\n",
       " 0.1276595744680851,\n",
       " 0.12788632326820604,\n",
       " 0.2,\n",
       " 0.09971509971509972,\n",
       " 0.04984423676012461,\n",
       " 0.11871227364185111,\n",
       " 0.01904761904761905,\n",
       " 0.04932735426008968,\n",
       " 0.053504144687264506,\n",
       " 0.0832072617246596,\n",
       " 0.08320950965824665,\n",
       " 0.04810126582278481,\n",
       " 0.10554371002132196,\n",
       " 0.06913183279742766,\n",
       " 0.08857808857808858,\n",
       " 0.059431524547803614,\n",
       " 0.09165687426556991,\n",
       " 0.06701030927835051,\n",
       " 0.08695652173913043,\n",
       " 0.06235912847483095,\n",
       " 0.07456140350877193,\n",
       " 0.14363143631436315,\n",
       " 0.125,\n",
       " 0.04173354735152488,\n",
       " 0.06611570247933884,\n",
       " 0.06885758998435054,\n",
       " 0.15011037527593818,\n",
       " 0.09720176730486009,\n",
       " 0.07507987220447285,\n",
       " 0.0717628705148206,\n",
       " 0.16521739130434782,\n",
       " 0.037996545768566495,\n",
       " 0.06902086677367576,\n",
       " 0.04112554112554113,\n",
       " 0.0913978494623656,\n",
       " 0.08588957055214724,\n",
       " 0.05970149253731343,\n",
       " 0.13984674329501914,\n",
       " 0.10829103214890017,\n",
       " 0.05786618444846293,\n",
       " 0.04661654135338346,\n",
       " 0.09927360774818401,\n",
       " 0.16085271317829458,\n",
       " 0.1273996509598604,\n",
       " 0.08108108108108109,\n",
       " 0.04157043879907621,\n",
       " 0.06840077071290944,\n",
       " 0.07026143790849673,\n",
       " 0.0411522633744856,\n",
       " 0.164,\n",
       " 0.05119047619047619,\n",
       " 0.06608695652173913,\n",
       " 0.07699619771863118,\n",
       " 0.08085808580858085,\n",
       " 0.06997455470737914,\n",
       " 0.15955056179775282,\n",
       " 0.05714285714285714,\n",
       " 0.10047846889952153,\n",
       " 0.07373271889400922,\n",
       " 0.05414551607445008,\n",
       " 0.008733624454148471,\n",
       " 0.12394957983193278,\n",
       " 0.17329545454545456,\n",
       " 0.2087912087912088,\n",
       " 0.09565217391304348,\n",
       " 0.06958762886597938,\n",
       " 0.08367768595041322,\n",
       " 0.0691358024691358,\n",
       " 0.0763239875389408,\n",
       " 0.09655172413793103,\n",
       " 0.06625441696113074,\n",
       " 0.06693440428380187,\n",
       " 0.10655737704918032,\n",
       " 0.11219512195121951,\n",
       " 0.09037328094302555,\n",
       " 0.07575757575757576,\n",
       " 0.03664302600472813,\n",
       " 0.10256410256410256,\n",
       " 0.12464589235127478,\n",
       " 0.0979689366786141,\n",
       " 0.05172413793103448,\n",
       " 0.08235294117647059,\n",
       " 0.07782101167315175,\n",
       " 0.1488095238095238,\n",
       " 0.18202247191011237,\n",
       " 0.08676599474145487,\n",
       " 0.11483253588516747,\n",
       " 0.10223642172523961,\n",
       " 0.11604095563139932,\n",
       " 0.12738853503184713,\n",
       " 0.0519653564290473,\n",
       " 0.06904231625835189,\n",
       " 0.13846153846153847,\n",
       " 0.18591549295774648,\n",
       " 0.020308692120227456,\n",
       " 0.05737704918032787,\n",
       " 0.08393285371702638,\n",
       " 0.10299003322259136,\n",
       " 0.048355899419729204,\n",
       " 0.06459627329192547,\n",
       " 0.11424100156494522,\n",
       " 0.024193548387096774,\n",
       " 0.0975609756097561,\n",
       " 0.15333333333333332,\n",
       " 0.09608540925266904,\n",
       " 0.17092034029389017,\n",
       " 0.05166051660516605,\n",
       " 0.10471698113207548,\n",
       " 0.07809110629067245,\n",
       " 0.08520710059171598,\n",
       " 0.09193245778611632,\n",
       " 0.10311284046692606,\n",
       " 0.09090909090909091,\n",
       " 0.14883720930232558,\n",
       " 0.08088235294117647,\n",
       " 0.045507584597432905,\n",
       " 0.046052631578947366,\n",
       " 0.09009009009009009,\n",
       " 0.11670480549199085,\n",
       " 0.03005780346820809,\n",
       " 0.08553654743390357,\n",
       " 0.05997693194925029,\n",
       " 0.0670807453416149,\n",
       " 0.04106280193236715,\n",
       " 0.10588235294117647,\n",
       " 0.16037735849056603,\n",
       " 0.0759493670886076,\n",
       " 0.11869436201780416,\n",
       " 0.1223021582733813,\n",
       " 0.26666666666666666,\n",
       " 0.2898550724637681,\n",
       " 0.07357357357357357,\n",
       " 0.05303030303030303,\n",
       " 0.05490549054905491,\n",
       " 0.05207413945278023,\n",
       " 0.06724782067247821,\n",
       " 0.36153846153846153,\n",
       " 0.036180904522613064,\n",
       " 0.06134969325153374,\n",
       " 0.047619047619047616,\n",
       " 0.08560311284046693,\n",
       " 0.08156606851549755,\n",
       " 0.02901178603807797,\n",
       " 0.035961272475795295,\n",
       " 0.08086785009861933,\n",
       " 0.09921671018276762,\n",
       " 0.040369088811995385,\n",
       " 0.059149722735674676,\n",
       " 0.04540023894862605,\n",
       " 0.04688763136620857,\n",
       " 0.166270783847981,\n",
       " 0.08656330749354005,\n",
       " 0.060240963855421686,\n",
       " 0.10644257703081232,\n",
       " 0.037340619307832425,\n",
       " 0.09921671018276762,\n",
       " 0.05891238670694864,\n",
       " 0.10904255319148937,\n",
       " 0.17073170731707318,\n",
       " 0.18666666666666668,\n",
       " 0.09259259259259259,\n",
       " 0.03859174001354096,\n",
       " 0.06770833333333333,\n",
       " 0.09104367135455219,\n",
       " 0.12474849094567404,\n",
       " 0.08368794326241134,\n",
       " 0.06765327695560254,\n",
       " 0.056179775280898875,\n",
       " 0.07162921348314606,\n",
       " 0.05367231638418079,\n",
       " 0.05183585313174946,\n",
       " 0.048167539267015703,\n",
       " 0.273972602739726,\n",
       " 0.07095709570957096,\n",
       " 0.03206106870229008,\n",
       " 0.10206896551724139,\n",
       " 0.1075050709939148,\n",
       " 0.12534059945504086,\n",
       " 0.0920353982300885,\n",
       " 0.02771855010660981,\n",
       " 0.048426150121065374,\n",
       " 0.043519394512771994,\n",
       " 0.05791505791505792,\n",
       " 0.23076923076923078,\n",
       " 0.0613107822410148,\n",
       " 0.07434052757793765,\n",
       " 0.15932203389830507,\n",
       " 0.07052186177715092,\n",
       " 0.2041343669250646,\n",
       " 0.04607046070460705,\n",
       " 0.05872756933115824,\n",
       " 0.12738853503184713,\n",
       " 0.05829596412556054,\n",
       " 0.06920415224913495,\n",
       " 0.04477611940298507,\n",
       " 0.13424947145877378,\n",
       " 0.05675459632294165,\n",
       " 0.06629834254143646,\n",
       " 0.10256410256410256,\n",
       " 0.08875739644970414,\n",
       " 0.09014675052410902,\n",
       " 0.3271604938271605,\n",
       " 0.07034220532319392,\n",
       " 0.06652126499454744,\n",
       " 0.041237113402061855,\n",
       " 0.04993252361673414,\n",
       " 0.15960912052117263,\n",
       " 0.091324200913242,\n",
       " 0.11802232854864433,\n",
       " 0.09508196721311475,\n",
       " 0.10588235294117647,\n",
       " 0.052884615384615384,\n",
       " 0.05718270571827057,\n",
       " 0.05714285714285714,\n",
       " 0.055499495459132187,\n",
       " 0.1065891472868217,\n",
       " 0.0733162830349531,\n",
       " 0.07380457380457381,\n",
       " 0.11406844106463879,\n",
       " 0.33035714285714285,\n",
       " 0.14527845036319612,\n",
       " 0.16901408450704225,\n",
       " 0.24380165289256198,\n",
       " 0.10848126232741617,\n",
       " 0.05804749340369393,\n",
       " 0.08589951377633712,\n",
       " 0.07491289198606271,\n",
       " 0.12853470437017994,\n",
       " 0.0723589001447178,\n",
       " 0.2524752475247525,\n",
       " 0.1488469601677149,\n",
       " 0.09897610921501707,\n",
       " 0.07055630936227951,\n",
       " 0.20209059233449478,\n",
       " 0.10271041369472182,\n",
       " 0.10571428571428572,\n",
       " 0.03608847497089639,\n",
       " 0.11737089201877934,\n",
       " 0.11405295315682282,\n",
       " 0.09456740442655935,\n",
       " 0.09621993127147767,\n",
       " 0.3602941176470588,\n",
       " 0.1267605633802817,\n",
       " 0.0429769392033543,\n",
       " 0.07565011820330969,\n",
       " 0.038551401869158876,\n",
       " 0.08615384615384615,\n",
       " 0.07150837988826815,\n",
       " 0.08223062381852551,\n",
       " 0.14982164090368608,\n",
       " 0.029369627507163324,\n",
       " 0.033112582781456956,\n",
       " 0.10031347962382445,\n",
       " 0.1011826544021025,\n",
       " 0.07894736842105263,\n",
       " 0.055357142857142855,\n",
       " 0.06459948320413436,\n",
       " 0.06315789473684211,\n",
       " 0.02710843373493976,\n",
       " 0.1324200913242009,\n",
       " 0.11764705882352941,\n",
       " 0.12080536912751678,\n",
       " 0.03130016051364366,\n",
       " 0.03763440860215054,\n",
       " 0.04847645429362881,\n",
       " 0.07920792079207921,\n",
       " 0.05359565807327001,\n",
       " 0.10403120936280884,\n",
       " 0.05480682839173405,\n",
       " 0.09808102345415778,\n",
       " 0.07326732673267326,\n",
       " 0.03838383838383838,\n",
       " 0.2125,\n",
       " 0.05549263873159683,\n",
       " 0.0362400906002265,\n",
       " 0.1309823677581864,\n",
       " 0.15633423180592992,\n",
       " 0.039819684447783624,\n",
       " 0.09118086696562033,\n",
       " 0.10242587601078167,\n",
       " 0.019776440240756664,\n",
       " 0.08,\n",
       " 0.057757644394110984,\n",
       " 0.2265193370165746,\n",
       " 0.061389337641357025,\n",
       " 0.05756578947368421,\n",
       " 0.05492730210016155,\n",
       " 0.06306306306306306,\n",
       " 0.08139534883720931,\n",
       " 0.049738219895287955,\n",
       " 0.08648648648648649,\n",
       " 0.14380530973451328,\n",
       " 0.06914212548015365,\n",
       " 0.1388888888888889,\n",
       " 0.11083333333333334,\n",
       " 0.2,\n",
       " 0.0603448275862069,\n",
       " 0.07327586206896551,\n",
       " 0.10139860139860139,\n",
       " 0.1038374717832957,\n",
       " 0.06684491978609626,\n",
       " 0.0691358024691358,\n",
       " 0.25,\n",
       " 0.07015306122448979,\n",
       " 0.07659115426105717,\n",
       " 0.13550135501355012,\n",
       " 0.0636042402826855,\n",
       " 0.21710526315789475,\n",
       " 0.07033639143730887,\n",
       " 0.08263305322128851,\n",
       " 0.0919175911251981,\n",
       " 0.075,\n",
       " 0.038525963149078725,\n",
       " 0.12052117263843648,\n",
       " 0.11048951048951049,\n",
       " 0.05963302752293578,\n",
       " 0.10740740740740741,\n",
       " 0.11789772727272728,\n",
       " 0.060240963855421686,\n",
       " 0.0407433881343817,\n",
       " 0.041627246925260174,\n",
       " 0.15808823529411764,\n",
       " 0.11166253101736973,\n",
       " 0.06772908366533864,\n",
       " 0.08506944444444445,\n",
       " 0.07095046854082998,\n",
       " 0.04728877679697352,\n",
       " 0.17490494296577946,\n",
       " 0.08294209702660407,\n",
       " 0.08908045977011494,\n",
       " 0.16805324459234608,\n",
       " 0.0458984375,\n",
       " 0.05166846071044134,\n",
       " 0.09281437125748503,\n",
       " 0.03209876543209877,\n",
       " 0.029005524861878452,\n",
       " 0.16981132075471697,\n",
       " 0.13747228381374724,\n",
       " 0.06181015452538632,\n",
       " 0.0828125,\n",
       " 0.04259438528557599,\n",
       " 0.06320541760722348,\n",
       " 0.05023364485981308,\n",
       " 0.13043478260869565,\n",
       " 0.04129263913824058,\n",
       " 0.03210382513661202,\n",
       " 0.09502262443438914,\n",
       " 0.0817490494296578,\n",
       " 0.08041958041958042,\n",
       " 0.11497730711043873,\n",
       " 0.05150753768844221,\n",
       " 0.0880281690140845,\n",
       " 0.04938271604938271,\n",
       " 0.0787518573551263,\n",
       " 0.0691114245416079,\n",
       " 0.1892744479495268,\n",
       " 0.09115281501340483,\n",
       " 0.11182519280205655,\n",
       " 0.08177570093457943,\n",
       " 0.08284023668639054,\n",
       " 0.04160688665710186,\n",
       " 0.20276497695852536,\n",
       " 0.13267813267813267,\n",
       " 0.05907172995780591,\n",
       " 0.1188118811881188,\n",
       " 0.05218617771509168,\n",
       " 0.06437291897891231,\n",
       " 0.08298755186721991,\n",
       " 0.062169312169312166,\n",
       " 0.03648269410664172,\n",
       " 0.04399441340782123,\n",
       " 0.00946969696969697,\n",
       " 0.07003891050583658,\n",
       " 0.11948051948051948,\n",
       " 0.07916666666666666,\n",
       " 0.16417910447761194,\n",
       " 0.030303030303030304,\n",
       " 0.13984168865435356,\n",
       " 0.14482758620689656,\n",
       " 0.05089538171536286,\n",
       " 0.12290502793296089,\n",
       " 0.14512471655328799,\n",
       " 0.11716171617161716,\n",
       " 0.0641025641025641,\n",
       " 0.028045574057843997,\n",
       " 0.036585365853658534,\n",
       " 0.16441441441441443,\n",
       " 0.06732348111658457,\n",
       " 0.04564315352697095,\n",
       " 0.25316455696202533,\n",
       " 0.09577464788732394,\n",
       " 0.038293216630196934,\n",
       " 0.125,\n",
       " 0.05269320843091335,\n",
       " 0.08426966292134831,\n",
       " 0.07155963302752294,\n",
       " 0.0695266272189349,\n",
       " 0.14371980676328502,\n",
       " 0.08264462809917356,\n",
       " 0.05433186490455213,\n",
       " 0.050514499532273154,\n",
       " 0.13660245183887915,\n",
       " 0.12623762376237624,\n",
       " 0.06823821339950373,\n",
       " 0.11918604651162791,\n",
       " 0.14675767918088736,\n",
       " 0.08626198083067092,\n",
       " 0.13066666666666665,\n",
       " 0.0752212389380531,\n",
       " 0.07113821138211382,\n",
       " 0.06887755102040816,\n",
       " 0.10622710622710622,\n",
       " 0.16944444444444445,\n",
       " 0.09221902017291066,\n",
       " 0.046489563567362426,\n",
       " 0.14345991561181434,\n",
       " 0.04153354632587859,\n",
       " 0.06093189964157706,\n",
       " 0.06746987951807229,\n",
       " 0.06731946144430845,\n",
       " 0.020741671904462602,\n",
       " 0.10606060606060606,\n",
       " 0.03968253968253968,\n",
       " 0.08032128514056225,\n",
       " 0.04680365296803653,\n",
       " 0.18805309734513273,\n",
       " 0.053009883198562445,\n",
       " 0.2054794520547945,\n",
       " 0.04945904173106646,\n",
       " 0.16080402010050251,\n",
       " 0.06753246753246753,\n",
       " 0.13438735177865613,\n",
       " 0.020446096654275093,\n",
       " 0.06577480490523968,\n",
       " 0.04844290657439446,\n",
       " 0.06483516483516484,\n",
       " 0.09541984732824428,\n",
       " 0.18691588785046728,\n",
       " 0.046610169491525424,\n",
       " 0.052132701421800945,\n",
       " 0.07521367521367521,\n",
       " 0.08807588075880758,\n",
       " 0.09579439252336448,\n",
       " 0.085383502170767,\n",
       " 0.06240126382306477,\n",
       " 0.09026548672566372,\n",
       " 0.07905982905982906,\n",
       " 0.03656821378340366,\n",
       " 0.028333333333333332,\n",
       " 0.04534883720930233,\n",
       " 0.06283280085197018,\n",
       " 0.14849624060150377,\n",
       " 0.04580896686159844,\n",
       " 0.08602150537634409,\n",
       " 0.04488188976377953,\n",
       " 0.18698060941828254,\n",
       " 0.055025266704098824,\n",
       " 0.15835777126099707,\n",
       " 0.08,\n",
       " 0.18027210884353742,\n",
       " 0.04780361757105943,\n",
       " 0.14386792452830188,\n",
       " 0.061105722599418044,\n",
       " 0.15770609318996415,\n",
       " 0.1069364161849711,\n",
       " 0.11647727272727272,\n",
       " 0.09585492227979274,\n",
       " 0.11627906976744186,\n",
       " 0.062448644207066556,\n",
       " 0.0528,\n",
       " 0.15034965034965034,\n",
       " 0.07709251101321586,\n",
       " 0.061511423550087874,\n",
       " 0.03269537480063796,\n",
       " 0.18638466622604097,\n",
       " 0.225130890052356,\n",
       " 0.10285714285714286,\n",
       " 0.19705882352941176,\n",
       " 0.06477272727272727,\n",
       " 0.1301859799713877,\n",
       " 0.06,\n",
       " 0.022336769759450172,\n",
       " 0.07428040854224698,\n",
       " 0.06406685236768803,\n",
       " 0.08141592920353982,\n",
       " 0.07764390896921017,\n",
       " 0.04803073967339097,\n",
       " 0.09969788519637462,\n",
       " 0.07089947089947089,\n",
       " 0.10669456066945607,\n",
       " 0.09701492537313433,\n",
       " 0.10962566844919786,\n",
       " 0.10726072607260725,\n",
       " 0.06125574272588055,\n",
       " 0.06818181818181818,\n",
       " 0.0692167577413479,\n",
       " 0.05006418485237484,\n",
       " 0.137291280148423,\n",
       " 0.05236907730673317,\n",
       " 0.1152073732718894,\n",
       " 0.11824324324324324,\n",
       " 0.06723891273247497,\n",
       " 0.1,\n",
       " 0.04048964218455744,\n",
       " 0.028295376121463076,\n",
       " 0.05279187817258883,\n",
       " 0.07711442786069651,\n",
       " 0.11410459587955626,\n",
       " 0.07152317880794702,\n",
       " 0.05343511450381679,\n",
       " 0.04628099173553719,\n",
       " 0.1536144578313253,\n",
       " 0.04883720930232558,\n",
       " 0.11960132890365449,\n",
       " 0.14619883040935672,\n",
       " 0.1326530612244898,\n",
       " 0.05531914893617021,\n",
       " 0.08925869894099848,\n",
       " 0.1724137931034483,\n",
       " 0.0947176684881603,\n",
       " 0.06488156539649846,\n",
       " 0.17261904761904762,\n",
       " 0.0650994575045208,\n",
       " 0.03125,\n",
       " 0.040229885057471264,\n",
       " 0.08241758241758242,\n",
       " 0.060158910329171394,\n",
       " 0.04136690647482014,\n",
       " 0.1180722891566265,\n",
       " 0.10434782608695652,\n",
       " 0.06941838649155722,\n",
       " 0.18785578747628084,\n",
       " 0.06093189964157706,\n",
       " 0.15225563909774437,\n",
       " 0.09768637532133675,\n",
       " 0.02757229320780094,\n",
       " 0.045829514207149404,\n",
       " 0.070298769771529,\n",
       " 0.1414141414141414,\n",
       " 0.15593220338983052,\n",
       " 0.07360861759425494,\n",
       " 0.08806262230919765,\n",
       " 0.1032258064516129,\n",
       " 0.08142493638676845,\n",
       " 0.05476529160739687,\n",
       " 0.08296296296296296,\n",
       " 0.06363636363636363,\n",
       " 0.03896103896103896,\n",
       " 0.10158013544018059,\n",
       " 0.0821256038647343,\n",
       " 0.1366120218579235,\n",
       " 0.036677454153182305,\n",
       " 0.040983606557377046,\n",
       " 0.12637362637362637,\n",
       " 0.08595988538681948,\n",
       " 0.7333333333333333,\n",
       " 0.11706629055007052,\n",
       " 0.11437908496732026,\n",
       " 0.0652971386647102,\n",
       " 0.11666666666666667,\n",
       " 0.06283422459893048,\n",
       " 0.1411764705882353,\n",
       " 0.06862745098039216,\n",
       " 0.25210084033613445,\n",
       " 0.046680497925311204,\n",
       " 0.07644628099173553,\n",
       " 0.09335038363171355,\n",
       " 0.09573091849935317,\n",
       " 0.14685314685314685,\n",
       " 0.04878048780487805,\n",
       " 0.13488372093023257,\n",
       " 0.0631768953068592,\n",
       " 0.07330827067669173,\n",
       " 0.05889724310776942,\n",
       " 0.07702020202020202,\n",
       " 0.032825322391559206,\n",
       " 0.06504065040650407,\n",
       " 0.09868421052631579,\n",
       " 0.14950980392156862,\n",
       " 0.03524590163934426,\n",
       " 0.10764872521246459,\n",
       " 0.16129032258064516,\n",
       " 0.09359944941500344,\n",
       " 0.1724137931034483,\n",
       " 0.0959409594095941,\n",
       " 0.06864988558352403,\n",
       " 0.06402048655569782,\n",
       " 0.08076514346439957,\n",
       " 0.10432569974554708,\n",
       " 0.09950248756218906,\n",
       " 0.06351183063511831,\n",
       " 0.08130081300813008,\n",
       " 0.034050179211469536,\n",
       " 0.05710814094775213,\n",
       " 0.104,\n",
       " 0.06301824212271974,\n",
       " 0.05983545250560957,\n",
       " 0.05197505197505198,\n",
       " 0.04885057471264368,\n",
       " 0.04371584699453552,\n",
       " 0.06867469879518072,\n",
       " 0.0556792873051225,\n",
       " 0.08396946564885496,\n",
       " 0.08472803347280335,\n",
       " 0.04088586030664395,\n",
       " 0.05246422893481717,\n",
       " 0.05721716514954486,\n",
       " 0.09461663947797716,\n",
       " 0.04367201426024955,\n",
       " 0.06823027718550106,\n",
       " 0.05454545454545454,\n",
       " 0.05102040816326531,\n",
       " 0.11711711711711711,\n",
       " 0.12804878048780488,\n",
       " 0.056511056511056514,\n",
       " 0.06060606060606061,\n",
       " 0.039047619047619046,\n",
       " 0.020618556701030927,\n",
       " 0.12987012987012986,\n",
       " 0.18831168831168832,\n",
       " 0.07804232804232804,\n",
       " 0.09480122324159021,\n",
       " 0.08934707903780069,\n",
       " 0.03625730994152047,\n",
       " 0.09090909090909091,\n",
       " 0.14623655913978495,\n",
       " 0.02564102564102564,\n",
       " 0.07263922518159806,\n",
       " 0.08333333333333333,\n",
       " 0.09344490934449093,\n",
       " 0.0737527114967462,\n",
       " 0.10570469798657718,\n",
       " 0.10268562401263823,\n",
       " 0.12731481481481483,\n",
       " 0.06923950056753689,\n",
       " 0.07482993197278912,\n",
       " 0.040444091990483745,\n",
       " 0.11163895486935867,\n",
       " 0.061096136567834684,\n",
       " 0.1362126245847176,\n",
       " 0.11337868480725624,\n",
       " 0.09967845659163987,\n",
       " 0.06593406593406594,\n",
       " 0.11405835543766578,\n",
       " 0.054613935969868174,\n",
       " 0.10991957104557641,\n",
       " 0.06046511627906977,\n",
       " 0.10865561694290976,\n",
       " 0.07649253731343283,\n",
       " 0.05545286506469501,\n",
       " 0.14955640050697086,\n",
       " 0.05897887323943662,\n",
       " 0.09349593495934959,\n",
       " 0.043357933579335796,\n",
       " 0.16307692307692306,\n",
       " 0.09052631578947369,\n",
       " 0.11682242990654206,\n",
       " 0.043509789702683106,\n",
       " 0.03248811410459588,\n",
       " 0.15047021943573669,\n",
       " 0.125,\n",
       " 0.138801261829653,\n",
       " 0.06125356125356125,\n",
       " 0.15813953488372093,\n",
       " 0.10815602836879433,\n",
       " 0.1680161943319838,\n",
       " 0.02309344790547798,\n",
       " 0.13619402985074627,\n",
       " 0.03543307086614173,\n",
       " 0.05079962370649106,\n",
       " 0.05277401894451962,\n",
       " 0.1492063492063492,\n",
       " 0.06601941747572816,\n",
       " 0.04153686396677051,\n",
       " 0.08704453441295547,\n",
       " 0.0468564650059312,\n",
       " 0.061277705345501955,\n",
       " 0.07559681697612732,\n",
       " 0.08472222222222223,\n",
       " 0.10897435897435898,\n",
       " 0.12595419847328243,\n",
       " 0.09433962264150944,\n",
       " 0.020477815699658702,\n",
       " 0.17209302325581396,\n",
       " 0.07946026986506746,\n",
       " 0.04778156996587031,\n",
       " 0.12727272727272726,\n",
       " 0.08470588235294117,\n",
       " 0.05170068027210884,\n",
       " 0.034227567067530065,\n",
       " 0.1048951048951049,\n",
       " 0.03825956489122281,\n",
       " 0.06976744186046512,\n",
       " 0.04319793681495809,\n",
       " 0.16967509025270758,\n",
       " 0.09557109557109557,\n",
       " 0.04710144927536232,\n",
       " 0.14285714285714285,\n",
       " 0.06744868035190615,\n",
       " 0.06995230524642289,\n",
       " 0.08597285067873303,\n",
       " 0.09803921568627451,\n",
       " 0.028749028749028748,\n",
       " 0.09048723897911833,\n",
       " 0.043668122270742356,\n",
       " 0.07068607068607069,\n",
       " 0.05655042412818096,\n",
       " 0.060459492140266025,\n",
       " 0.06726457399103139,\n",
       " 0.09523809523809523,\n",
       " 0.2357142857142857,\n",
       " 0.04234527687296417,\n",
       " 0.15444015444015444,\n",
       " 0.26229508196721313,\n",
       " 0.19005847953216373,\n",
       " 0.15950920245398773,\n",
       " 0.0975609756097561,\n",
       " 0.03327338129496403,\n",
       " 0.037714285714285714,\n",
       " 0.1186046511627907,\n",
       " 0.1910828025477707,\n",
       " 0.08944954128440367,\n",
       " 0.24528301886792453,\n",
       " 0.16828478964401294,\n",
       " 0.052132701421800945,\n",
       " 0.07215189873417721,\n",
       " 0.12272727272727273,\n",
       " 0.060267857142857144,\n",
       " 0.01811248808388942,\n",
       " 0.041349292709466814,\n",
       " 0.1096938775510204,\n",
       " 0.09041591320072333,\n",
       " 0.07975460122699386,\n",
       " 0.08294209702660407,\n",
       " 0.02862595419847328,\n",
       " 0.07882882882882883,\n",
       " 0.21705426356589147,\n",
       " 0.0759493670886076,\n",
       " 0.18552036199095023,\n",
       " 0.04331087584215592,\n",
       " 0.05436337625178827,\n",
       " 0.11419753086419752,\n",
       " 0.06146926536731634,\n",
       " 0.1864406779661017,\n",
       " 0.13815789473684212,\n",
       " 0.01564828614008942,\n",
       " 0.04096045197740113,\n",
       " 0.04397163120567376,\n",
       " 0.0759493670886076,\n",
       " 0.02955082742316785,\n",
       " 0.09274873524451939,\n",
       " 0.11401425178147269,\n",
       " 0.10029498525073746,\n",
       " 0.12264150943396226,\n",
       " 0.10658307210031348,\n",
       " 0.10238095238095238,\n",
       " 0.03996003996003996,\n",
       " 0.19029850746268656,\n",
       " 0.17665615141955837,\n",
       " 0.058394160583941604,\n",
       " 0.03218645948945616,\n",
       " 0.14395393474088292,\n",
       " 0.12094395280235988,\n",
       " 0.03640040444893832,\n",
       " 0.035003977724741446,\n",
       " 0.13106796116504854,\n",
       " 0.0532994923857868,\n",
       " 0.03700588730025231,\n",
       " 0.06998158379373849,\n",
       " 0.06775700934579439,\n",
       " 0.08791208791208792,\n",
       " 0.08279220779220779,\n",
       " 0.07055630936227951,\n",
       " 0.14157303370786517,\n",
       " 0.1144578313253012,\n",
       " 0.04423748544819558,\n",
       " 0.09549549549549549,\n",
       " 0.054461181923522596,\n",
       " 0.10580204778156997,\n",
       " 0.07317073170731707,\n",
       " 0.14935064935064934,\n",
       " 0.15853658536585366,\n",
       " 0.19161676646706588,\n",
       " 0.11566265060240964,\n",
       " 0.020773638968481375,\n",
       " 0.1079734219269103,\n",
       " 0.06402048655569782,\n",
       " 0.03743961352657005,\n",
       " 0.056558363417569195,\n",
       " 0.12557077625570776,\n",
       " 0.0647419072615923,\n",
       " 0.10964912280701754,\n",
       " 0.03621399176954732,\n",
       " 0.1674641148325359,\n",
       " 0.016203703703703703,\n",
       " 0.14617169373549885,\n",
       " 0.08771929824561403,\n",
       " 0.07011070110701106,\n",
       " 0.027093596059113302,\n",
       " 0.10299003322259136,\n",
       " 0.06666666666666667,\n",
       " 0.053763440860215055,\n",
       " 0.0632688927943761,\n",
       " 0.08050847457627118,\n",
       " 0.08385093167701864,\n",
       " 0.05997693194925029,\n",
       " 0.04285714285714286,\n",
       " 0.01881720430107527,\n",
       " 0.16977225672877846,\n",
       " 0.011294526498696786,\n",
       " 0.053545586107091175,\n",
       " 0.12140575079872204,\n",
       " 0.021825396825396824,\n",
       " 0.16932907348242812,\n",
       " 0.07932692307692307,\n",
       " 0.07851239669421488,\n",
       " 0.07560137457044673,\n",
       " 0.039525691699604744,\n",
       " 0.2635135135135135,\n",
       " 0.05357142857142857,\n",
       " 0.44339622641509435,\n",
       " 0.07049608355091384,\n",
       " 0.06104129263913824,\n",
       " 0.07559055118110236,\n",
       " 0.14732142857142858,\n",
       " 0.07789473684210527,\n",
       " 0.09259259259259259,\n",
       " 0.08345120226308345,\n",
       " 0.1111111111111111,\n",
       " 0.07132667617689016,\n",
       " 0.04621212121212121,\n",
       " 0.057488653555219364,\n",
       " 0.11370262390670553,\n",
       " 0.06333739342265529,\n",
       " 0.07910750507099391,\n",
       " 0.07705192629815745,\n",
       " 0.07816091954022988,\n",
       " 0.12982456140350876,\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137538"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio.index(max(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sep = np.arange(len(art_len))\n",
    "\n",
    "plt.plot(ratio)\n",
    "\n",
    "plt.xlabel(\"Text Type\")\n",
    "plt.ylabel(\"Number words\")\n",
    "plt.title(\"Article length vs highlight length\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            False\n",
       "article       False\n",
       "highlights    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring, all highlight:article ratio being more than 1.0 means the summary text is producing more text than the original text, this defeats the purpose of the model, therefore all data with a ratio of more than or equal to 1.0 will be omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset modification/Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(224), \n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),   # using ImageNet norms\n",
    "                         (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model improvement/Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Finalisation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5623M_CW1_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
